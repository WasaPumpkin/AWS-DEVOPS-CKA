<!DOCTYPE html>
<html lang="en">

<head>
  <title>Search in Questions</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 20px;
      background-color: #f5f5f5;
    }

    .container {
      background: #fff;
      padding: 20px;
      border-radius: 10px;
      /* max-width: 1400px; */
      width: 100%;
      margin: 0 auto;
    }

    .search-container {
      margin-bottom: 20px;
      width: 100%;
      max-width: 1900px;
      position: relative;
    }

    .search-bar {
      width: 100%;
      padding: 10px;
      padding-right: 70px;
      /* Space for buttons */
      font-size: 16px;
      border: 1px solid #ccc;
      border-radius: 5px;
      box-sizing: border-box;
    }

    .search-buttons {
      position: absolute;
      right: 10px;
      top: 50%;
      transform: translateY(-50%);
      display: flex;
      gap: 5px;
    }

    .search-button {
      background: #ddd;
      border: none;
      border-radius: 3px;
      padding: 3px 8px;
      cursor: pointer;
      font-size: 12px;
    }

    .search-button:hover {
      background: #ccc;
    }

    .question-block {
      margin-bottom: 20px;
      padding: 15px;
      border: 1px solid #eee;
      border-radius: 5px;
    }

    .question {
      color: #333;
      margin: 0;
      font-size: 30px;
      background-color: yellow;
      padding: 10px;
    }

    img {
      width: 40%;
      height: auto;
      border-radius: 10px;
      margin: 10px;
    }

    .hidden {
      display: none;
    }

    .question-form {
      margin-top: 10px;
    }

    .question-form label {
      display: block;
      margin: 5px 0;
      padding: 10px;
      border-radius: 5px;
      background-color: #f9f9f9;
      transition: background-color 0.3s;
    }

    .correct-answer {
      font-weight: bold;
      color: green;
      background-color: #e0ffe0;
      border: 1px solid green;
    }

    .scroll-top {
      position: fixed;
      bottom: 20px;
      right: 20px;
      background: #333;
      color: white;
      border: none;
      border-radius: 50%;
      width: 50px;
      height: 50px;
      font-size: 20px;
      cursor: pointer;
      display: none;
      z-index: 99;
    }

    .scroll-top:hover {
      background: #555;
    }

    /* CSS */
  </style>
</head>

<body>
  <div class="container">
    <div class="search-container">
      <input type="text" id="search" class="search-bar" placeholder="Search questions...">
      <div class="search-buttons">
        <button class="search-button" id="clear-search">X</button>
      </div>
    </div>
    <div class="question-block">
      <h1 class="question">
        A company wants to migrate its content sharing web application hosted on Amazon EC2 to a serverless
        architecture. The company currently deploys changes to its application by creating a new Auto Scaling group of
        EC2 instances and a new Elastic Load Balancer, and then shifting the traffic away using an Amazon Route 53
        weighted routing policy.
        For its new serverless application, the company is planning to use Amazon API Gateway and AWS Lambda. The
        company will need to update its deployment processes to work with the new application. It will also need to
        retain the ability to test new features on a small number of users before rolling the features out to the entire
        user base.
        Which deployment strategy will meet these requirements?
      </h1>
      <form class="question-form">
        <label for="optionA">A. Use AWS CDK to deploy API Gateway and Lambda functions. When code needs to be changed,
          update the AWS CloudFormation stack and deploy the new version of the APIs and Lambda functions. Use a Route
          53 failover routing policy for the canary release strategy.</label>
        <label for="optionB" class="correct-answer">B. Use AWS CloudFormation to deploy API Gateway and Lambda functions
          using Lambda function versions. When code needs to be changed, update the CloudFormation stack with the new
          Lambda code and update the API versions using a canary release strategy. Promote the new version when testing
          is complete. ✓✓</label>
        <label for="optionC">C. Use AWS Elastic Beanstalk to deploy API Gateway and Lambda functions. When code needs to
          be changed, deploy a new version of the API and Lambda functions. Shift traffic gradually using an Elastic
          Beanstalk blue/green deployment.</label>
        <label for="optionD">D. Use AWS OpsWorks to deploy API Gateway in the service layer and Lambda functions in a
          custom layer. When code needs to be changed, use OpsWorks to perform a blue/green deployment and shift traffic
          gradually.</label>
      </form>
    </div>
    <div class="question-block">
      <h1 class="question">
        A company's application is currently deployed to a single AWS Region. Recently, the company opened a new office
        on a different continent. The users in the new office are experiencing high latency. The company's application
        runs on Amazon EC2 instances behind an Application Load Balancer (ALB) and uses Amazon
        DynamoDB as the database layer. The instances run in an EC2 Auto Scaling group across multiple Availability
        Zones. A DevOps Engineer is tasked with minimizing application response times and improving availability for
        users in both Regions.
        Which combination of actions should be taken to address the latency issues? (Choose three.)
      </h1>
      <form class="question-form">
        <label for="optionA">A. Create a new DynamoDB table in the new Region with cross-Region replication
          enabled.</label>
        <label for="optionB">B. Create new ALB and Auto Scaling group global resources and configure the new ALB to
          direct traffic to the new Auto Scaling group.</label>
        <label for="optionC" class="correct-answer">C. Create new ALB and Auto Scaling group resources in the new Region
          and configure the new ALB to direct traffic to the new Auto Scaling group. ✓✓</label>
        <label for="optionD" class="correct-answer">D. Create Amazon Route 53 records, health checks, and latency-based
          routing policies to route to the ALB. ✓✓</label>
        <label for="optionE">E. Create Amazon Route 53 aliases, health checks, and failover routing policies to route to
          the ALB.</label>
        <label for="optionF" class="correct-answer">F. Convert the DynamoDB table to a global table. ✓✓</label>
      </form>
    </div>
    <div class="question-block">
      <h1 class="question">
        A DevOps engineer used an AWS CloudFormation custom resource to set up AD Connector. The AWS Lambda function
        executed and created AD Connector, but
        CloudFormation is not transitioning from CREATE_IN_PROGRESS to CREATE_COMPLETE.
        Which action should the engineer take to resolve this issue?
      </h1>
      <form class="question-form">
        <label for="optionA">A. Ensure the Lambda function code has exited successfully.</label>
        <label for="optionB" class="correct-answer">B. Ensure the Lambda function code returns a response to the
          pre-signed URL. ✓✓</label>
        <label for="optionC">C. Ensure the Lambda function IAM role has cloudformation:UpdateStack permissions for the
          stack ARN.</label>
        <label for="optionD">D. Ensure the Lambda function IAM role has ds:ConnectDirectory permissions for the AWS
          account.</label>
      </form>
    </div>
    <div class="question-block">
      <h1 class="question">
        A company plans to stop using Amazon EC2 key pairs for SSH access, and instead plans to use AWS Systems Manager
        Session Manager. To further enhance security, access to Session Manager must take place over a private network
        only.
        Which combinations of actions will accomplish this? (Choose two.)
      </h1>
      <form class="question-form">
        <label for="optionA">A. Allow inbound access to TCP port 22 in all associated EC2 security groups from the VPC
          CIDR range.</label>
        <label for="optionB" class="correct-answer">B. Attach an IAM policy with the necessary Systems Manager
          permissions to the existing IAM instance profile. ✓✓</label>
        <label for="optionC" class="correct-answer">C. Create a VPC endpoint for Systems Manager in the desired Region.
          ✓✓</label>
        <label for="optionD">D. Deploy a new EC2 instance that will act as a bastion host to the rest of the EC2
          instance fleet.</label>
        <label for="optionE">E. Remove any default routes in the associated route tables.</label>
      </form>
    </div>
    <div class="question-block">
      <h1 class="question">
        A company runs an application with an Amazon EC2 and on-premises configuration. A DevOps Engineer needs to
        standardize patching across both environments. Company policy dictates that patching only happens during
        non-business hours.
        Which combination of actions will meet these requirements? (Choose three.)
      </h1>
      <form class="question-form">
        <label for="optionA" class="correct-answer">A. Add the physical machines into AWS Systems Manager using Systems
          Manager Hybrid Activations. ✓✓</label>
        <label for="optionB" class="correct-answer">B. Attach an IAM role to the EC2 instances, allowing them to be
          managed by AWS Systems Manager. ✓✓</label>
        <label for="optionC">C. Create IAM access keys for the on-premises machines to interact with AWS Systems
          Manager.</label>
        <label for="optionD">D. Execute an AWS Systems Manager Automation document to patch the systems every
          hour.</label>
        <label for="optionE">E. Use Amazon CloudWatch Events scheduled events to schedule a patch window.</label>
        <label for="optionF" class="correct-answer">F. Use AWS Systems Manager Maintenance Windows to schedule a patch
          window. ✓✓</label>
      </form>
    </div>
    <div class="question-block">
      <h1 class="question">
        Which one of the following components should not influence an organization’s security policy?
      </h1>
      <form class="question-form">
        <label for="optionA">A. Business objectives</label>
        <label for="optionB">B. Regulatory requirements</label>
        <label for="optionC">C. Risk</label>
        <label for="optionD">D. Cost–benefit analysis</label>
        <label for="optionE" class="correct-answer">E. Current firewall limitations &#x2713;&#x2713;</label>
      </form>
    </div>
    <form class="question-form">
      <h1 class="question">Consider the following statements about the AAA architecture:</h1>
      <p>I. Authentication deals with the question “Who is the user?”</p>
      <p>II. Authorization addresses the question “What is the user allowed to do?”</p>
      <p>III. Accountability answers the question “What did the user do?”</p>
      <h1 class="question">Which of the following is correct?</h1>
      <label for="optionA">A. Only I is correct.</label>
      <label for="optionB">B. Only II is correct.</label>
      <label for="optionC">C. I, II, and III are correct.</label>
      <label for="optionD" class="correct-answer">D. I and II are correct. &#x2713;&#x2713;</label>
      <label for="optionE">E. II and III are correct.</label>
    </form>
    <form class="question-form">
      <h1 class="question">What is the difference between denial-of-service (DoS) and distributed denial-of-service
        (DDoS) attacks?</h1>
      <label for="optionA">A. DDoS attacks have many targets, whereas DoS attacks have only one each.</label>
      <label for="optionB">B. DDoS attacks target multiple networks, whereas DoS attacks target a single
        network.</label>
      <label for="optionC" class="correct-answer">C. DDoS attacks have many sources, whereas DoS attacks have only one
        each. &#x2713;&#x2713;</label>
      <label for="optionD">D. DDoS attacks target multiple layers of the OSI model and DoS attacks only one.</label>
      <label for="optionE">E. DDoS attacks are synonymous with DoS attacks</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following options is incorrect?</h1>
      <label for="optionA">A. A firewall is a security system aimed at isolating specific areas of the network and delimiting domains of trust.</label>
      <label for="optionB">B. Generally speaking, the web application firewall (WAF) is a specialized security element that acts as a full-reverse proxy, protecting applications that are accessed through HTTP.</label>
      <label for="optionC" class="correct-answer">C. Whereas intrusion prevention system (IPS) devices handle only copies of the packets and are mainly concerned with monitoring and alerting tasks, intrusion detection system (IDS) solutions are deployed inline in the traffic flow and have the inherent design goal of avoiding actual damage to systems. &#x2713;&#x2713;</label>
      <label for="optionD">D. Security information and event management (SIEM) solutions are designed to collect security-related logs as well as flow information generated by systems (at the host or the application level), networking devices, and dedicated defense elements such as firewalls, IPSs, IDSs, and antivirus software.</label>
    </form>
    <form class="question-form">
      <h1 class="question">In the standard shared responsibility model, AWS is responsible for which of the following options?</h1>
      <label for="optionA">A. Regions, availability zones, and data encryption</label>
      <label for="optionB">B. Hardware, firewall configuration, and hypervisor software</label>
      <label for="optionC" class="correct-answer">C. Hypervisor software, regions, and availability zones &#x2713;&#x2713;</label>
      <label for="optionD">D. Network traffic protection and identity and access management</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which AWS service allows you to generate compliance reports that enable you to evaluate the AWS security controls and posture?</h1>
      <label for="optionA">A. AWS Trusted Advisor</label>
      <label for="optionB">B. AWS Well-Architected Tool</label>
      <label for="optionC" class="correct-answer">C. AWS Artifact &#x2713;&#x2713;</label>
      <label for="optionD">D. Amazon Inspector</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following contains a definition that is not a pillar from the AWS Well-Architected Framework?</h1>
      <label for="optionA">A. Security and operational excellence</label>
      <label for="optionB">B. Reliability and performance efficiency</label>
      <label for="optionC" class="correct-answer">C. Cost optimization and availability &#x2713;&#x2713;</label>
      <label for="optionD">D. Security and performance efficiency</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following services provides a set of APIs that control access to your resources on the AWS Cloud?</h1>
      <label for="optionA">A. AWS AAA</label>
      <label for="optionB" class="correct-answer">B. AWS IAM &#x2713;&#x2713;</label>
      <label for="optionC">C. AWS Authenticator</label>
      <label for="optionD">D. AWS AD</label>
    </form>
    <form class="question-form">
      <h1 class="question">Regarding AWS IAM principals, which option is not correct?</h1>
      <label for="optionA">A. A principal is an IAM entity that has permission to interact with resources in the AWS Cloud.</label>
      <label for="optionB" class="correct-answer">B. They can only be permanent. &#x2713;&#x2713;</label>
      <label for="optionC">C. They can represent a human user, a resource, or an application.</label>
      <label for="optionD">D. They have three types: root users, IAM users, and roles.</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following is not a recommendation for protecting your root user credentials?</h1>
      <label for="optionA">A. Use a strong password to help protect account-level access to the management console.</label>
      <label for="optionB">B. Enable MFA on your AWS root user account.</label>
      <label for="optionC">C. Do not create an access key for programmatic access to your root user account unless such a procedure is mandatory.</label>
      <label for="optionD" class="correct-answer">D. If you must maintain an access key to your root user account, you should never rotate it using the AWS Console. &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">In AWS Config, which option is not correct?</h1>
      <label for="optionA">A. The main goal of AWS Config is to record configuration and the changes of the resources.</label>
      <label for="optionB">B. AWS Config Rules can decide if a change is good or bad and if it needs to execute an action.</label>
      <label for="optionC" class="correct-answer">C. AWS Config cannot integrate with external resources like on-premises servers and applications. &#x2713;&#x2713;</label>
      <label for="optionD">D. AWS Config can provide configuration history files, configuration snapshots, and configuration streams.</label>
    </form>
    <form class="question-form">
      <h1 class="question">AWS CloudTrail is the service in charge of keeping records of API calls to the AWS Cloud. Which option is not a type of AWS CloudTrail event?</h1>
      <label for="optionA">A. Management</label>
      <label for="optionB">B. Insights</label>
      <label for="optionC">C. Data</label>
      <label for="optionD" class="correct-answer">D. Control &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">In Amazon VPCs, which of the following is not correct?</h1>
      <label for="optionA">A. VPC is the acronym of Virtual Private Cloud.</label>
      <label for="optionB">B. VPCs do not extend beyond an AWS region.</label>
      <label for="optionC" class="correct-answer">C. You can deploy only private IP addresses from RFC 1918 within VPCs. &#x2713;&#x2713;</label>
      <label for="optionD">D. You can configure your VPC to not share hardware with other AWS accounts.</label>
    </form>
    <form class="question-form">
      <h1 class="question">In NAT gateways, which option is not correct?</h1>
      <label for="optionA">A. NAT gateways are always positioned in public subnets.</label>
      <label for="optionB">B. Route table configuration is usually required to direct traffic to these devices.</label>
      <label for="optionC" class="correct-answer">C. NAT gateways are highly available by default. &#x2713;&#x2713;</label>
      <label for="optionD">D. Amazon CloudWatch automatically monitors traffic flowing through NAT gateways</label>
    </form>
    <form class="question-form">
      <h1 class="question">In security groups, which option is not correct?</h1>
      <label for="optionA">A. Security groups only have allow (permit) rules.</label>
      <label for="optionB">B. The default security group allows all inbound communications from resources that are associated to the same security group.</label>
      <label for="optionC" class="correct-answer">C. You cannot have more than one security group associated to an instance’s ENI. &#x2713;&#x2713;</label>
      <label for="optionD">D. The default security group allows all outbound communications to any destination.</label>
    </form>
    <form class="question-form">
      <h1 class="question">In network ACLs, which option is not correct?</h1>
      <label for="optionA">A. They can be considered an additional layer of traffic filtering to security groups.</label>
      <label for="optionB">B. Network ACLs have allow and deny rules.</label>
      <label for="optionC" class="correct-answer">C. The default network ACL has only one inbound rule, denying all traffic from all protocols, all port ranges, from any source. &#x2713;&#x2713;</label>
      <label for="optionD">D. A subnet can be associated with only one network ACL at a time.</label>
    </form>
    <form class="question-form">
      <h1 class="question">In AWS KMS, which option is not correct?</h1>
      <label for="optionA">A. KMS can integrate with Amazon S3 and Amazon EBS.</label>
      <label for="optionB" class="correct-answer">B. KMS can be used to generate SSH access keys for Amazon EC2 instances. &#x2713;&#x2713;</label>
      <label for="optionC">C. KMS is considered multitenant, not a dedicated hardware security module.</label>
      <label for="optionD">D. KMS can be used to provide data-at-rest encryption for RDS, Aurora, DynamoDB, and Redshift databases</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which option is not correct in regard to AWS KMS customer master keys?</h1>
      <label for="optionA">A. A CMK is a 256-bit AES for symmetric keys.</label>
      <label for="optionB">B. A CMK has a key ID, an alias, and an ARN (Amazon Resource Name).</label>
      <label for="optionC" class="correct-answer">C. A CMK can also use IAM users, IAM groups, and IAM roles. . &#x2713;&#x2713;</label>
      <label for="optionD">D. A CMK has two policies roles: key administrators and key users</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following actions is not recommended when an Amazon EC2 instance is compromised by malware?</h1>
      <label for="optionA">A. Take a snapshot of the EBS volume at the time of the incident.</label>
      <label for="optionB" class="correct-answer">B. Change its security group accordingly and reattach any IAM role attached to the instance. &#x2713;&#x2713;</label>
      <label for="optionC">C. Tag the instance as compromised together with an AWS IAM policy that explicitly restricts all operations related to the instance, the incident response, and forensics teams.</label>
      <label for="optionD">D. When the incident forensics team wants to analyze the instance, they should deploy it into a totally isolated environment—ideally a private subnet.</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following actions is recommended when temporary credentials from an Amazon EC2 instance are inadvertently made public?</h1>
      <label for="optionA" class="correct-answer">A. You should assume that the access key was compromised and revoke it immediately. &#x2713;&#x2713;</label>
      <label for="optionB">B. You should try to locate where the key was exposed and inform AWS.</label>
      <label for="optionC">C. You should not reevaluate the IAM roles attached to the instance.</label>
      <label for="optionD">D. You should avoid rotating your key</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following options may not be considered a security automation trigger?</h1>
      <label for="optionA">A. Unsafe configurations from AWS Config or Amazon Inspector</label>
      <label for="optionB">B. AWS Security Hub findings</label>
      <label for="optionC" class="correct-answer">C. Systems Manager Automation documents &#x2713;&#x2713;</label>
      <label for="optionD">D. Event from Amazon CloudWatch Events</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following options may not be considered a security automation response task?</h1>
      <label for="optionA">A. An AWS Lambda function can use AWS APIs to change security groups or network ACLs.</label>
      <label for="optionB">B. A Systems Manager Automation document execution run.</label>
      <label for="optionC">C. Systems Manager Run Command can be used to execute commands to multiple hosts.</label>
      <label for="optionD" class="correct-answer">D. Apply a thorough forensic analysis in an isolated instance. &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following options may not be considered a security troubleshooting tool for security in AWS Cloud environments?</h1>
      <label for="optionA">A. AWS CloudTrail</label>
      <label for="optionB">B. Amazon CloudWatch Logs</label>
      <label for="optionC" class="correct-answer">C. AWS Key Management Service &#x2713;&#x2713;</label>
      <label for="optionD">D. Amazon EventBridge</label>
    </form>
    <form class="question-form">
      <h1 class="question">Right after you correctly deploy VPC peering between two VPCs (A and B), inter-VPC traffic is still not happening. What is the most probable cause?</h1>
      <label for="optionA">A. The peering must be configured as transitive.</label>
      <label for="optionB" class="correct-answer">B. The route tables are not configured. &#x2713;&#x2713;</label>
      <label for="optionC">C. You need a shared VPC.</label>
      <label for="optionD">D. You need to configure a routing protocol</label>
    </form>
    <form class="question-form">
      <h1 class="question">A good mental exercise for your future cloud security design can start with the analysis of how AWS native security services and features (as well as third-party security solutions) can replace your traditional security controls. Which of the options is not a valid mapping between traditional security controls and potential AWS security controls?</h1>
      <label for="optionA">A. Network segregation (such as firewall rules and router access control lists) and security groups and network ACLs, Web Application Firewall (WAF)</label>
      <label for="optionB">B. Data encryption at rest and Amazon S3 server-side encryption, Amazon EBS encryption, Amazon RDS encryption, and other AWS KMS-enabled encryption features</label>
      <label for="optionC" class="correct-answer">C. Monitor intrusion and implementing security controls at the operating system level versus Amazon GuardDuty &#x2713;&#x2713;</label>
      <label for="optionD">D. Role-based access control (RBAC) versus AWS IAM, Active Directory integration through IAM groups, temporary security credentials, AWS Organizations</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company has two VPCs that are located in the us-west-2 Region within the same AWS account. The company needs to allow network traffic between these VPCs. Approximately 500 GB of data transfer will occur between the VPCs each month.</h1>
      <h1 class="question">What is the MOST cost-effective solution to connect these VPCs?</h1>
      <label for="optionA">A. Implement AWS Transit Gateway to connect the VPCs. Update the route tables of each VPC to use the transit gateway for inter-VPC communication.</label>
      <label for="optionB">B. Implement an AWS Site-to-Site VPN tunnel between the VPCs. Update the route tables of each VPC to use the VPN tunnel for inter-VPC communication.</label>
      <label for="optionC" class="correct-answer">C. Set up a VPC peering connection between the VPCs. Update the route tables of each VPC to use the VPC peering connection for inter-VPC communication. &#x2713;&#x2713;</label>
      <label for="optionD">D. Set up a 1 GB AWS Direct Connect connection between the VPCs. Update the route tables of each VPC to use the Direct Connect connection for inter-VPC communication.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company has a VPC in the us-west-1 Region and another VPC in the ap-southeast-2 Region. Network engineers set up an AWS Direct Connect connection from their data center to the us-east-1 Region. They create a private virtual interface (VIF) that references a Direct Connect gateway, which is then connected to virtual private gateways in both VPCs. When the setup is complete, the engineers cannot access resources in us-west-1 from ap-southeast-2.</h1>
      <h1 class="question">What should the network engineers do to resolve this issue?</h1>
      <label for="optionA">A. Add the subnet range for the VPCs in us-west-1 and ap-southeast-2 to the route tables for both VPCs. Add the Direct Connect gateway as a target.</label>
      <label for="optionB">B. Configure the Direct Connect gateway to route traffic between the VPCs in ap-southeast-2 and us-west-2.</label>
      <label for="optionC" class="correct-answer">C. Establish a VPC peering connection between the VPCs in ap-southeast-2 and us-west-2. Add the subnet ranges to the routing tables. &#x2713;&#x2713;</label>
      <label for="optionD">D. Create static routes in each VPC that point to the destination VPC with the virtual private gateway as the route target.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company needs to architect a hybrid DNS solution. This solution will use an Amazon Route 53 private hosted zone for the domain cloud.example.com for the resources stored within VPCs.</h1>
      <h1 class="question">The company has the following DNS resolution requirements:</h1>
      <ul>
        <li>On-premises systems should be able to resolve and connect to cloud.example.com.</li>
        <li>All VPCs should be able to resolve cloud.example.com.</li>
      </ul>
      <h1 class="question">There is already an AWS Direct Connect connection between the on-premises corporate network and AWS Transit Gateway.</h1>
      <h1 class="question">Which architecture should the company use to meet these requirements with the HIGHEST performance?</h1>
      <label for="optionA" class="correct-answer">A. Associate the private hosted zone to all the VPCs. Create a Route 53 inbound resolver in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver. &#x2713;&#x2713;</label>
      <label for="optionB">B. Associate the private hosted zone to all the VPCs. Deploy an Amazon EC2 conditional forwarder in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the conditional forwarder.</label>
      <label for="optionC">C. Associate the private hosted zone to the shared services VPC. Create a Route 53 outbound resolver in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the outbound resolver.</label>
      <label for="optionD">D. Associate the private hosted zone to the shared services VPC. Create a Route 53 inbound resolver in the shared services VPC. Attach the shared services VPC to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company is providing weather data over a REST-based API to several customers. The API is hosted by Amazon API Gateway and is integrated with different AWS Lambda functions for each API operation. The company uses Amazon Route 53 for DNS and has created a resource record of weather.example.com. The company stores data for the API in Amazon DynamoDB tables. The company needs a solution that will give the API the ability to fail over to a different AWS Region.</h1>
      <h1 class="question">Which solution will meet these requirements?</h1>
      <label for="optionA">A. Deploy a new set of Lambda functions in a new Region. Update the API Gateway API to use an edge-optimized API endpoint with Lambda functions from both Regions as targets. Convert the DynamoDB tables to global tables.</label>
      <label for="optionB">B. Deploy a new API Gateway API and Lambda functions in another Region. Change the Route 53 DNS record to a multivalue answer. Add both API Gateway APIs to the answer. Enable target health monitoring. Convert the DynamoDB tables to global tables.</label>
      <label for="optionC" class="correct-answer">C. Deploy a new API Gateway API and Lambda functions in another Region. Change the Route 53 DNS record to a failover record. Enable target health monitoring. Convert the DynamoDB tables to global tables. &#x2713;&#x2713;</label>
      <label for="optionD">D. Deploy a new API Gateway API in a new Region. Change the Lambda functions to global functions. Change the Route 53 DNS record to a multivalue answer. Add both API Gateway APIs to the answer. Enable target health monitoring. Convert the DynamoDB tables to global tables.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company uses AWS Organizations with a single OU named Production to manage multiple accounts. All accounts are members of the Production OU. Administrators use deny list SCPs in the root of the organization to manage access to restricted services.</h1>
      <h1 class="question">The company recently acquired a new business unit and invited the new unit’s existing AWS account to the organization. Once onboarded, the administrators of the new business unit discovered that they are not able to update existing AWS Config rules to meet the company’s policies.</h1>
      <h1 class="question">Which option will allow administrators to make changes and continue to enforce the current policies without introducing additional long-term maintenance?</h1>
      <label for="optionA">A. Remove the organization’s root SCPs that limit access to AWS Config. Create AWS Service Catalog products for the company’s standard AWS Config rules and deploy them throughout the organization, including the new account.</label>
      <label for="optionB">B. Create a temporary OU named Onboarding for the new account. Apply an SCP to the Onboarding OU to allow AWS Config actions. Move the new account to the Production OU when adjustments to AWS Config are complete.</label>
      <label for="optionC">C. Convert the organization’s root SCPs from deny list SCPs to allow list SCPs to allow the required services only. Temporarily apply an SCP to the organization’s root that allows AWS Config actions for principals only in the new account.</label>
      <label for="optionD" class="correct-answer">D. Create a temporary OU named Onboarding for the new account. Apply an SCP to the Onboarding OU to allow AWS Config actions. Move the organization’s root SCP to the Production OU. Move the new account to the Production OU when adjustments to AWS Config are complete. &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company is running a two-tier web-based application in an on-premises data center. The application layer consists of a single server running a stateful application. The application connects to a PostgreSQL database running on a separate server. The application’s user base is expected to grow significantly, so the company is migrating the application and database to AWS. The solution will use Amazon Aurora PostgreSQL, Amazon EC2 Auto Scaling, and Elastic Load Balancing.</h1>
      <h1 class="question">Which solution will provide a consistent user experience that will allow the application and database tiers to scale?</h1>
      <label for="optionA">A. Enable Aurora Auto Scaling for Aurora Replicas. Use a Network Load Balancer with the least outstanding requests routing algorithm and sticky sessions enabled.</label>
      <label for="optionB">B. Enable Aurora Auto Scaling for Aurora writers. Use an Application Load Balancer with the round robin routing algorithm and sticky sessions enabled.</label>
      <label for="optionC" class="correct-answer">C. Enable Aurora Auto Scaling for Aurora Replicas. Use an Application Load Balancer with the round robin routing and sticky sessions enabled. &#x2713;&#x2713;</label>
      <label for="optionD">D. Enable Aurora Scaling for Aurora writers. Use a Network Load Balancer with the least outstanding requests routing algorithm and sticky sessions enabled</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company uses a service to collect metadata from applications that the company hosts on premises. Consumer devices such as TVs and internet radios access the applications. Many older devices do not support certain HTTP headers and exhibit errors when these headers are present in responses. The company has configured an on-premises load balancer to remove the unsupported headers from responses sent to older devices, which the company identified by the User-Agent headers.</h1>
      <h1 class="question">The company wants to migrate the service to AWS, adopt serverless technologies, and retain the ability to support the older devices. The company has already migrated the applications into a set of AWS Lambda functions.</h1>
      <h1 class="question">Which solution will meet these requirements?</h1>
      
      <label for="optionA">A. Create an Amazon CloudFront distribution for the metadata service. Create an Application Load Balancer (ALB). Configure the CloudFront distribution to forward requests to the ALB. Configure the ALB to invoke the correct Lambda function for each type of request. Create a CloudFront function to remove the problematic headers based on the value of the User-Agent header.</label>
      
      <label for="optionB">B. Create an Amazon API Gateway REST API for the metadata service. Configure API Gateway to invoke the correct Lambda function for each type of request. Modify the default gateway responses to remove the problematic headers based on the value of the User-Agent header.</label>
      
      <label for="optionC">C. Create an Amazon API Gateway HTTP API for the metadata service. Configure API Gateway to invoke the correct Lambda function for each type of request. Create a response mapping template to remove the problematic headers based on the value of the User-Agent. Associate the response data mapping with the HTTP API.</label>
      
      <label for="optionD" class="correct-answer">D. Create an Amazon CloudFront distribution for the metadata service. Create an Application Load Balancer (ALB). Configure the CloudFront distribution to forward requests to the ALB. Configure the ALB to invoke the correct Lambda function for each type of request. Create a Lambda@Edge function that will remove the problematic headers in response to viewer requests based on the value of the User-Agent header. &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">A retail company needs to provide a series of data files to another company, which is its business partner. These files are saved in an Amazon S3 bucket under Account A, which belongs to the retail company. The business partner company wants one of its IAM users, User_DataProcessor, to access the files from its own AWS account (Account B).</h1>
      <h1 class="question">Which combination of steps must the companies take so that User_DataProcessor can access the S3 bucket successfully? (Choose two.)</h1>
    
      <label for="optionA">A. Turn on the cross-origin resource sharing (CORS) feature for the S3 bucket in Account A.</label>
    
      <label for="optionB">B. In Account A, set the S3 bucket policy to the following:
        <pre>
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Principal": {
            "AWS": "arn:aws:iam::AccountB-ID:root"
          },
          "Action": "s3:GetObject",
          "Resource": "arn:aws:s3:::bucket-name/*"
        }
      ]
    }
        </pre>
      </label>
    
      <label for="optionC" class="correct-answer">C. In Account A, set the S3 bucket policy to the following:
        <pre>
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Principal": {
            "AWS": "arn:aws:iam::AccountB-ID:user/User_DataProcessor"
          },
          "Action": "s3:GetObject",
          "Resource": "arn:aws:s3:::bucket-name/*"
        }
      ]
    }
        </pre>
        &#x2713;&#x2713;
      </label>
    
      <label for="optionD">D. In Account B, set the permissions of User_DataProcessor to the following:
        <pre>
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Action": "s3:GetObject",
          "Resource": "arn:aws:s3:::bucket-name/*"
        }
      ]
    }
        </pre>
      </label>
    
      <label for="optionE" class="correct-answer">E. In Account B, set the permissions of User_DataProcessor to the following:
        <pre>
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Action": "s3:GetObject",
          "Resource": "arn:aws:s3:::AccountA-ID:bucket-name/*"
        }
      ]
    }
        </pre>
        &#x2713;&#x2713;
      </label>
    </form>
    <form class="question-form">
      <h1 class="question">A company is running a traditional web application on Amazon EC2 instances. The company needs to refactor the application as microservices that run on containers. Separate versions of the application exist in two distinct environments: production and testing. Load for the application is variable, but the minimum load and the maximum load are known. A solutions architect needs to design the updated application with a serverless architecture that minimizes operational complexity.</h1>
      <h1 class="question">Which solution will meet these requirements MOST cost-effectively?</h1>
    
      <label for="optionA">A. Upload the container images to AWS Lambda as functions. Configure a concurrency limit for the associated Lambda functions to handle the expected peak load. Configure two separate Lambda integrations within Amazon API Gateway: one for production and one for testing.</label>
    
      <label for="optionB" class="correct-answer">B. Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Container Service (Amazon ECS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the ECS clusters. &#x2713;&#x2713;</label>
    
      <label for="optionC">C. Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Kubernetes Service (Amazon EKS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the EKS clusters.</label>
    
      <label for="optionD">D. Upload the container images to AWS Elastic Beanstalk. In Elastic Beanstalk, create separate environments and deployments for production and testing. Configure two separate Application Load Balancers to direct traffic to the Elastic Beanstalk deployments.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company has a multi-tier web application that runs on a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB). The instances are in an Auto Scaling group. The ALB and the Auto Scaling group are replicated in a backup AWS Region. The minimum value and the maximum value for the Auto Scaling group are set to zero. An Amazon RDS Multi-AZ DB instance stores the application’s data. The DB instance has a read replica in the backup Region. The application presents an endpoint to end users by using an Amazon Route 53 record.</h1>
      <h1 class="question">The company needs to reduce its RTO to less than 15 minutes by giving the application the ability to automatically fail over to the backup Region. The company does not have a large enough budget for an active-active strategy.</h1>
      <h1 class="question">What should a solutions architect recommend to meet these requirements?</h1>
    
      <label for="optionA">A. Reconfigure the application’s Route 53 record with a latency-based routing policy that load balances traffic between the two ALBs. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Create an Amazon CloudWatch alarm that is based on the HTTPCode_Target_5XX_Count metric for the ALB in the primary Region. Configure the CloudWatch alarm to invoke the Lambda function.</label>
    
      <label for="optionB" class="correct-answer">B. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Configure Route 53 with a health check that monitors the web application and sends an Amazon Simple Notification Service (Amazon SNS) notification to the Lambda function when the health check status is unhealthy. Update the application’s Route 53 record with a failover policy that routes traffic to the ALB in the backup Region when a health check failure occurs. &#x2713;&#x2713;</label>
    
      <label for="optionC">C. Configure the Auto Scaling group in the backup Region to have the same values as the Auto Scaling group in the primary Region. Reconfigure the application’s Route 53 record with a latency-based routing policy that load balances traffic between the two ALBs. Remove the read replica. Replace the read replica with a standalone RDS DB instance. Configure Cross-Region Replication between the RDS DB instances by using snapshots and Amazon S3.</label>
    
      <label for="optionD">D. Configure an endpoint in AWS Global Accelerator with the two ALBs as equal weighted targets. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Create an Amazon CloudWatch alarm that is based on the HTTPCode_Target_5XX_Count metric for the ALB in the primary Region. Configure the CloudWatch alarm to invoke the Lambda function.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company is hosting a critical application on a single Amazon EC2 instance. The application uses an Amazon ElastiCache for Redis single-node cluster for an in-memory data store. The application uses an Amazon RDS for MariaDB DB instance for a relational database. For the application to function, each piece of the infrastructure must be healthy and must be in an active state.</h1>
      <h1 class="question">A solutions architect needs to improve the application's architecture so that the infrastructure can automatically recover from failure with the least possible downtime.</h1>
      <h1 class="question">Which combination of steps will meet these requirements? (Choose three.)</h1>
      <label for="optionA" class="correct-answer">A. Use an Elastic Load Balancer to distribute traffic across multiple EC2 instances. Ensure that the EC2 instances are part of an Auto Scaling group that has a minimum capacity of two instances. &#x2713;&#x2713;</label>
      <label for="optionB">B. Use an Elastic Load Balancer to distribute traffic across multiple EC2 instances. Ensure that the EC2 instances are configured in unlimited mode.</label>
      <label for="optionC">C. Modify the DB instance to create a read replica in the same Availability Zone. Promote the read replica to be the primary DB instance in failure scenarios.</label>
      <label for="optionD" class="correct-answer">D. Modify the DB instance to create a Multi-AZ deployment that extends across two Availability Zones. &#x2713;&#x2713;</label>
      <label for="optionE">E. Create a replication group for the ElastiCache for Redis cluster. Configure the cluster to use an Auto Scaling group that has a minimum capacity of two instances.</label>
      <label for="optionF" class="correct-answer">F. Create a replication group for the ElastiCache for Redis cluster. Enable Multi-AZ on the cluster. &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">A retail company is operating its ecommerce application on AWS. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The company uses an Amazon RDS DB instance as the database backend. Amazon CloudFront is configured with one origin that points to the ALB. Static content is cached. Amazon Route 53 is used to host all public zones.</h1>
      <h1 class="question">After an update of the application, the ALB occasionally returns a 502 status code (Bad Gateway) error. The root cause is malformed HTTP headers that are returned to the ALB. The webpage returns successfully when a solutions architect reloads the webpage immediately after the error occurs.</h1>
      <h1 class="question">While the company is working on the problem, the solutions architect needs to provide a custom error page instead of the standard ALB error page to visitors.</h1>
      <h1 class="question">Which combination of steps will meet this requirement with the LEAST amount of operational overhead? (Choose two.)</h1>
    
      <label for="optionA" class="correct-answer">A. Create an Amazon S3 bucket. Configure the S3 bucket to host a static webpage. Upload the custom error pages to Amazon S3. &#x2713;&#x2713;</label>
    
      <label for="optionB">B. Create an Amazon CloudWatch alarm to invoke an AWS Lambda function if the ALB health check response Target.FailedHealthChecks is greater than 0. Configure the Lambda function to modify the forwarding rule at the ALB to point to a publicly accessible web server.</label>
    
      <label for="optionC">C. Modify the existing Amazon Route 53 records by adding health checks. Configure a fallback target if the health check fails. Modify DNS records to point to a publicly accessible webpage.</label>
    
      <label for="optionD">D. Create an Amazon CloudWatch alarm to invoke an AWS Lambda function if the ALB health check response Elb.InternalError is greater than 0. Configure the Lambda function to modify the forwarding rule at the ALB to point to a public accessible web server.</label>
    
      <label for="optionE" class="correct-answer">E. Add a custom error response by configuring a CloudFront custom error page. Modify DNS records to point to a publicly accessible web page. &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company has a mobile application that makes HTTP API calls to an Application Load Balancer (ALB). The ALB routes requests to an AWS Lambda function. Many different versions of the application are in use at any given time, including versions that are in testing by a subset of users. The version of the application is defined in the user-agent header that is sent with all requests to the API.</h1>
      <h1 class="question">After a series of recent changes to the API, the company has observed issues with the application. The company needs to gather a metric for each API operation by response code for each version of the application that is in use. A DevOps engineer has modified the Lambda function to extract the API operation name, version information from the user-agent header and response code.</h1>
      <h1 class="question">Which additional set of actions should the DevOps engineer take to gather the required metrics?</h1>
      <label for="optionA" class="correct-answer">A. Modify the Lambda function to write the API operation name, response code, and version number as a log line to an Amazon CloudWatch Logs log group. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric. &#x2713;&#x2713;</label>
      <label for="optionB">B. Modify the Lambda function to write the API operation name, response code, and version number as a log line to an Amazon CloudWatch Logs log group. Configure a CloudWatch Logs Insights query to populate CloudWatch metrics from the log lines. Specify response code and application version as dimensions for the metric.</label>
      <label for="optionC">C. Configure the ALB access logs to write to an Amazon CloudWatch Logs log group. Modify the Lambda function to respond to the ALB with the API operation name, response code, and version number as response metadata. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric.</label>
      <label for="optionD">D. Configure AWS X-Ray integration on the Lambda function. Modify the Lambda function to create an X-Ray subsegment with the API operation name, response code, and version number. Configure X-Ray insights to extract an aggregated metric for each API operation name and to publish the metric to Amazon CloudWatch. Specify response code and application version as dimensions for the metric.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company provides an application to customers. The application has an Amazon API Gateway REST API that invokes an AWS Lambda function. On initialization, the Lambda function loads a large amount of data from an Amazon DynamoDB table. The data load process results in long cold-start times of 8-10 seconds. The DynamoDB table has DynamoDB Accelerator (DAX) configured.</h1>
      <h1 class="question">Customers report that the application intermittently takes a long time to respond to requests. The application receives thousands of requests throughout the day. In the middle of the day, the application experiences 10 times more requests than at any other time of the day. Near the end of the day, the application's request volume decreases to 10% of its normal total.</h1>
      <h1 class="question">A DevOps engineer needs to reduce the latency of the Lambda function at all times of the day.</h1>
      <h1 class="question">Which solution will meet these requirements?</h1>
      <label for="optionA">A. Configure provisioned concurrency on the Lambda function with a concurrency value of 1. Delete the DAX cluster for the DynamoDB table.</label>
      <label for="optionB">B. Configure reserved concurrency on the Lambda function with a concurrency value of 0.</label>
      <label for="optionC" class="correct-answer">C. Configure provisioned concurrency on the Lambda function. Configure AWS Application Auto Scaling on the Lambda function with provisioned concurrency values set to a minimum of 1 and a maximum of 100. &#x2713;&#x2713;</label>
      <label for="optionD">D. Configure reserved concurrency on the Lambda function. Configure AWS Application Auto Scaling on the API Gateway API with a reserved concurrency maximum value of 100.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company is adopting AWS CodeDeploy to automate its application deployments for a Java-Apache Tomcat application with an Apache Webserver. The development team started with a proof of concept, created a deployment group for a developer environment, and performed functional tests within the application. After completion, the team will create additional deployment groups for staging and production.</h1>
      <h1 class="question">The current log level is configured within the Apache settings, but the team wants to change this configuration dynamically when the deployment occurs, so that they can set different log level configurations depending on the deployment group without having a different application revision for each group.</h1>
      <h1 class="question">How can these requirements be met with the LEAST management overhead and without requiring different script versions for each deployment group?</h1>
    
      <label for="optionA">A. Tag the Amazon EC2 instances depending on the deployment group. Then place a script into the application revision that calls the metadata service and the EC2 API to identify which deployment group the instance is part of. Use this information to configure the log level settings. Reference the script as part of the AfterInstall lifecycle hook in the appspec.yml file.</label>
      <label for="optionB" class="correct-answer">B. Create a script that uses the CodeDeploy environment variable DEPLOYMENT_GROUP_NAME to identify which deployment group the instance is part of. Use this information to configure the log level settings. Reference this script as part of the BeforeInstall lifecycle hook in the appspec.yml file. &#x2713;&#x2713;</label>
      <label for="optionC">C. Create a CodeDeploy custom environment variable for each environment. Then place a script into the application revision that checks this environment variable to identify which deployment group the instance is part of. Use this information to configure the log level settings. Reference this script as part of the ValidateService lifecycle hook in the appspec.yml file.</label>
      <label for="optionD">D. Create a script that uses the CodeDeploy environment variable DEPLOYMENT_GROUP_ID to identify which deployment group the instance is part of to configure the log level settings. Reference this script as part of the Install lifecycle hook in the appspec.yml file.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company requires its developers to tag all Amazon Elastic Block Store (Amazon EBS) volumes in an account to indicate a desired backup frequency. This requirement includes EBS volumes that do not require backups. The company uses custom tags named Backup_Frequency that have values of none, daily, or weekly that correspond to the desired backup frequency. An audit finds that developers are occasionally not tagging the EBS volumes.</h1>
      <h1 class="question">A DevOps engineer needs to ensure that all EBS volumes always have the Backup_Frequency tag so that the company can perform backups at least weekly unless a different value is specified.</h1>
      <h1 class="question">Which solution will meet these requirements?</h1>
    
      <label for="optionA">A. Set up AWS Config in the account. Create a custom rule that returns a compliance failure for all Amazon EC2 resources that do not have a Backup_Frequency tag applied. Configure a remediation action that uses a custom AWS Systems Manager Automation runbook to apply the Backup_Frequency tag with a value of weekly.</label>
    
      <label for="optionB" class="correct-answer">B. Set up AWS Config in the account. Use a managed rule that returns a compliance failure for EC2::Volume resources that do not have a Backup_Frequency tag applied. Configure a remediation action that uses a custom AWS Systems Manager Automation runbook to apply the Backup_Frequency tag with a value of weekly. &#x2713;&#x2713;</label>
    
      <label for="optionC">C. Turn on AWS CloudTrail in the account. Create an Amazon EventBridge rule that reacts to EBS CreateVolume events. Configure a custom AWS Systems Manager Automation runbook to apply the Backup_Frequency tag with a value of weekly. Specify the runbook as the target of the rule.</label>
    
      <label for="optionD">D. Turn on AWS CloudTrail in the account. Create an Amazon EventBridge rule that reacts to EBS CreateVolume events or EBS ModifyVolume events. Configure a custom AWS Systems Manager Automation runbook to apply the Backup_Frequency tag with a value of weekly. Specify the runbook as the target of the rule.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company is using an Amazon Aurora cluster as the data store for its application. The Aurora cluster is configured with a single DB instance. The application performs read and write operations on the database by using the cluster's instance endpoint.</h1>
      <h1 class="question">The company has scheduled an update to be applied to the cluster during an upcoming maintenance window. The cluster must remain available with the least possible interruption during the maintenance window.</h1>
      <h1 class="question">What should a DevOps engineer do to meet these requirements?</h1>
      <label for="optionA" class="correct-answer">A. Add a reader instance to the Aurora cluster. Update the application to use the Aurora cluster endpoint for write operations. Update the Aurora cluster's reader endpoint for reads. &#x2713;&#x2713;</label>
      <label for="optionB">B. Add a reader instance to the Aurora cluster. Create a custom ANY endpoint for the cluster. Update the application to use the Aurora cluster's custom ANY endpoint for read and write operations.</label>
      <label for="optionC">C. Turn on the Multi-AZ option on the Aurora cluster. Update the application to use the Aurora cluster endpoint for write operations. Update the Aurora cluster’s reader endpoint for reads.</label>
      <label for="optionD">D. Turn on the Multi-AZ option on the Aurora cluster. Create a custom ANY endpoint for the cluster. Update the application to use the Aurora cluster's custom ANY endpoint for read and write operations</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company must encrypt all AMIs that the company shares across accounts. A DevOps engineer has access to a source account where an unencrypted custom AMI has been built. The DevOps engineer also has access to a target account where an Amazon EC2 Auto Scaling group will launch EC2 instances from the AMI. The DevOps engineer must share the AMI with the target account.</h1>
      <h1 class="question">The company has created an AWS Key Management Service (AWS KMS) key in the source account.</h1>
      <h1 class="question">Which additional steps should the DevOps engineer perform to meet the requirements? (Choose three.)</h1>
    
      <label for="optionA" class="correct-answer">A. In the source account, copy the unencrypted AMI to an encrypted AMI. Specify the KMS key in the copy action. &#x2713;&#x2713;</label>
    
      <label for="optionB">B. In the source account, copy the unencrypted AMI to an encrypted AMI. Specify the default Amazon Elastic Block Store (Amazon EBS) encryption key in the copy action.</label>
    
      <label for="optionC">C. In the source account, create a KMS grant that delegates permissions to the Auto Scaling group service-linked role in the target account.</label>
    
      <label for="optionD" class="correct-answer">D. In the source account, modify the key policy to give the target account permissions to create a grant. In the target account, create a KMS grant that delegates permissions to the Auto Scaling group service-linked role. &#x2713;&#x2713;</label>
    
      <label for="optionE">E. In the source account, share the unencrypted AMI with the target account.</label>
    
      <label for="optionF" class="correct-answer">F. In the source account, share the encrypted AMI with the target account. &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company uses AWS CodePipeline pipelines to automate releases of its application. A typical pipeline consists of three stages: build, test, and deployment. The company has been using a separate AWS CodeBuild project to run scripts for each stage. However, the company now wants to use AWS CodeDeploy to handle the deployment stage of the pipelines.</h1>
      <h1 class="question">The company has packaged the application as an RPM package and must deploy the application to a fleet of Amazon EC2 instances. The EC2 instances are in an EC2 Auto Scaling group and are launched from a common AMI.</h1>
      <h1 class="question">Which combination of steps should a DevOps engineer perform to meet these requirements? (Choose two.)</h1>
    
      <label for="optionA" class="correct-answer">A. Create a new version of the common AMI with the CodeDeploy agent installed. Update the IAM role of the EC2 instances to allow access to CodeDeploy. &#x2713;</label>
      <label for="optionB">B. Create a new version of the common AMI with the CodeDeploy agent installed. Create an AppSpec file that contains application deployment scripts and grants access to CodeDeploy.</label>
      <label for="optionC">C. Create an application in CodeDeploy. Configure an in-place deployment type. Specify the Auto Scaling group as the deployment target. Add a step to the CodePipeline pipeline to use EC2 Image Builder to create a new AMI. Configure CodeDeploy to deploy the newly created AMI.</label>
      <label for="optionD" class="correct-answer">D. Create an application in CodeDeploy. Configure an in-place deployment type. Specify the Auto Scaling group as the deployment target. Update the CodePipeline pipeline to use the CodeDeploy action to deploy the application. &#x2713;</label>
      <label for="optionE">E. Create an application in CodeDeploy. Configure an in-place deployment type. Specify the EC2 instances that are launched from the common AMI as the deployment target. Update the CodePipeline pipeline to use the CodeDeploy action to deploy the application.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company’s security team requires that all external Application Load Balancers (ALBs) and Amazon API Gateway APIs are associated with AWS WAF web ACLs. The company has hundreds of AWS accounts, all of which are included in a single organization in AWS Organizations. The company has configured AWS Config for the organization. During an audit, the company finds some externally facing ALBs that are not associated with AWS WAF web ACLs.</h1>
      <h1 class="question">Which combination of steps should a DevOps engineer take to prevent future violations? (Choose two.)</h1>
    
      <label for="optionA" class="correct-answer">A. Delegate AWS Firewall Manager to a security account. &#x2713;</label>
      <label for="optionB">B. Delegate Amazon GuardDuty to a security account.</label>
      <label for="optionC" class="correct-answer">C. Create an AWS Firewall Manager policy to attach AWS WAF web ACLs to any newly created ALBs and API Gateway APIs. &#x2713;</label>
      <label for="optionD">D. Create an Amazon GuardDuty policy to attach AWS WAF web ACLs to any newly created ALBs and API Gateway APIs.</label>
      <label for="optionE">E. Configure an AWS Config managed rule to attach AWS WAF web ACLs to any newly created ALBs and API Gateway APIs.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company uses AWS Key Management Service (AWS KMS) keys and manual key rotation to meet regulatory compliance requirements. The security team wants to be notified when any keys have not been rotated after 90 days.</h1>
      <h1 class="question">Which solution will accomplish this?</h1>
    
      <label for="optionA">A. Configure AWS KMS to publish to an Amazon Simple Notification Service (Amazon SNS) topic when keys are more than 90 days old.</label>
      <label for="optionB">B. Configure an Amazon EventBridge event to launch an AWS Lambda function to call the AWS Trusted Advisor API and publish to an Amazon Simple Notification Service (Amazon SNS) topic.</label>
      <label for="optionC" class="correct-answer">C. Develop an AWS Config custom rule that publishes to an Amazon Simple Notification Service (Amazon SNS) topic when keys are more than 90 days old. &#x2713;</label>
      <label for="optionD">D. Configure AWS Security Hub to publish to an Amazon Simple Notification Service (Amazon SNS) topic when keys are more than 90 days old.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A security review has identified that an AWS CodeBuild project is downloading a database population script from an Amazon S3 bucket using an unauthenticated request. The security team does not allow unauthenticated requests to S3 buckets for this project.</h1>
      <h1 class="question">How can this issue be corrected in the MOST secure manner?</h1>
    
      <label for="optionA">A. Add the bucket name to the AllowedBuckets section of the CodeBuild project settings. Update the build spec to use the AWS CLI to download the database population script.</label>
      <label for="optionB">B. Modify the S3 bucket settings to enable HTTPS basic authentication and specify a token. Update the build spec to use cURL to pass the token and download the database population script.</label>
      <label for="optionC" class="correct-answer">C. Remove unauthenticated access from the S3 bucket with a bucket policy. Modify the service role for the CodeBuild project to include Amazon S3 access. Use the AWS CLI to download the database population script. &#x2713;</label>
      <label for="optionD">D. Remove unauthenticated access from the S3 bucket with a bucket policy. Use the AWS CLI to download the database population script using an IAM access key and a secret access key.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company wants to ensure that their EC2 instances are secure. They want to be notified if any new vulnerabilities are discovered on their instances, and they also want an audit trail of all login activities on the instances.</h1>
      <h1 class="question">Which solution will meet these requirements?</h1>
    
      <label for="optionA">A. Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Amazon Kinesis Agent to capture system logs and deliver them to Amazon S3.</label>
      <label for="optionB">B. Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Systems Manager Agent to capture system logs and view login activity in the CloudTrail console.</label>
      <label for="optionC">C. Configure Amazon CloudWatch to detect vulnerabilities on the EC2 instances. Install the AWS Config daemon to capture system logs and view them in the AWS Config console.</label>
      <label for="optionD" class="correct-answer">D. Configure Amazon Inspector to detect vulnerabilities on the EC2 instances. Install the Amazon CloudWatch Agent to capture system logs and record them via Amazon CloudWatch Logs. &#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company has many applications. Different teams in the company developed the applications by using multiple languages and frameworks. The applications run on premises and on different servers with different operating systems. Each team has its own release protocol and process. The company wants to reduce the complexity of the release and maintenance of these applications. The company is migrating its technology stacks, including these applications, to AWS. The company wants centralized control of source code, a consistent and automatic delivery pipeline, and as few maintenance tasks as possible on the underlying infrastructure.</h1>
      <h1 class="question">What should a DevOps engineer do to meet these requirements?</h1>
    
      <label for="optionA">A. Create one AWS CodeCommit repository for all applications. Put each application's code in different branch. Merge the branches, and use AWS CodeBuild to build the applications. Use AWS CodeDeploy to deploy the applications to one centralized application server.</label>
      <label for="optionB">B. Create one AWS CodeCommit repository for each of the applications. Use AWS CodeBuild to build the applications one at a time. Use AWS CodeDeploy to deploy the applications to one centralized application server.</label>
      <label for="optionC">C. Create one AWS CodeCommit repository for each of the applications. Use AWS CodeBuild to build the applications one at a time to create one AMI for each server. Use AWS CloudFormation StackSets to automatically provision and decommission Amazon EC2 fleets by using these AMIs.</label>
      <label for="optionD" class="correct-answer">D. Create one AWS CodeCommit repository for each of the applications. Use AWS CodeBuild to build one Docker image for each application in Amazon Elastic Container Registry (Amazon ECR). Use AWS CodeDeploy to deploy the applications to Amazon Elastic Container Service (Amazon ECS) on infrastructure that AWS Fargate manages. &#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">A DevOps engineer is developing an application for a company. The application needs to persist files to Amazon S3. The application needs to upload files with different security classifications that the company defines. These classifications include confidential, private, and public. Files that have a confidential classification must not be viewable by anyone other than the user who uploaded them. The application uses the IAM role of the user to call the S3 API operations.</h1>
      <h1 class="question">The DevOps engineer has modified the application to add a DataClassification tag with the value of confidential and an Owner tag with the uploading user's ID to each confidential object that is uploaded to Amazon S3. Which set of additional steps must the DevOps engineer take to meet the company's requirements?</h1>
    
      <label for="optionA">A. Modify the S3 bucket's ACL to grant bucket-owner-read access to the uploading user's IAM role. Create an IAM policy that grants s3:GetObject operations on the S3 bucket when aws:ResourceTag/DataClassification equals confidential, and s3:ExistingObjectTag/Owner equals ${aws:userid}. Attach the policy to the IAM roles for users who require access to the S3 bucket.</label>
      
      <label for="optionB" class="correct-answer">B. Modify the S3 bucket policy to allow the s3:GetObject action when aws:ResourceTag/DataClassification equals confidential, and s3:ExistingObjectTag/Owner equals ${aws:userid}. Create an IAM policy that grants s3:GetObject operations on the S3 bucket. Attach the policy to the IAM roles for users who require access to the S3 bucket. &#x2713;</label>
      
      <label for="optionC">C. Modify the S3 bucket policy to allow the s3:GetObject action when aws:ResourceTag/DataClassification equals confidential, and aws:RequestTag/Owner equals ${aws:userid}. Create an IAM policy that grants s3:GetObject operations on the S3 bucket. Attach the policy to the IAM roles for users who require access to the S3 bucket.</label>
      
      <label for="optionD">D. Modify the S3 bucket's ACL to grant authenticated-read access when aws:ResourceTag/DataClassification equals confidential, and s3:ExistingObjectTag/Owner equals ${aws:userid}. Create an IAM policy that grants s3:GetObject operations on the S3 bucket. Attach the policy to the IAM roles for users who require access to the S3 bucket.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company has developed an AWS Lambda function that handles orders received through an API. The company is using AWS CodeDeploy to deploy the Lambda function as the final stage of a CI/CD pipeline.</h1>
      <h1 class="question">A DevOps Engineer has noticed there are intermittent failures of the ordering API for a few seconds after deployment. After some investigation, the DevOps Engineer believes the failures are due to database changes not having fully propagated before the Lambda function begins executing.</h1>
      <h1 class="question">How should the DevOps Engineer overcome this?</h1>
    
      <label for="optionA" class="correct-answer">A. Add a BeforeAllowTraffic hook to the AppSpec file that tests and waits for any necessary database changes before traffic can flow to the new version of the Lambda function. &#x2713;</label>
    
      <label for="optionB">B. Add an AfterAllowTraffic hook to the AppSpec file that forces traffic to wait for any pending database changes before allowing the new version of the Lambda function to respond.</label>
    
      <label for="optionC">C. Add a BeforeInstall hook to the AppSpec file that tests and waits for any necessary database changes before deploying the new version of the Lambda function.</label>
    
      <label for="optionD">D. Add a ValidateService hook to the AppSpec file that inspects incoming traffic and rejects the payload if dependent services, such as the database, are not yet ready.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A software company wants to automate the build process for a project where the code is stored in GitHub. When the repository is updated, source code should be compiled, tested, and pushed to Amazon S3.</h1>
      <h1 class="question">Which combination of steps would address these requirements? (Choose three.)</h1>
    
      <label for="optionA" class="correct-answer">A. Add a buildspec.yml file to the source code with build instructions. &#x2713;</label>
      <label for="optionB" class="correct-answer">B. Configure a GitHub webhook to trigger a build every time a code change is pushed to the repository. &#x2713;</label>
      <label for="optionC" class="correct-answer">C. Create an AWS CodeBuild project with GitHub as the source repository. &#x2713;</label>
      <label for="optionD">D. Create an AWS CodeDeploy application with the Amazon EC2/On-Premises compute platform.</label>
      <label for="optionE">E. Create an AWS OpsWorks deployment with the install dependencies command.</label>
      <label for="optionF">F. Provision an Amazon EC2 instance to perform the build.</label>
    </form>
    <form class="question-form">
      <h1 class="question">An online retail company based in the United States plans to expand its operations to Europe and Asia in the next six months. Its product currently runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. All data is stored in an Amazon Aurora database instance.</h1>
      <h1 class="question">When the product is deployed in multiple regions, the company wants a single product catalog across all regions, but for compliance purposes, its customer information and purchases must be kept in each region.</h1>
      <h1 class="question">How should the company meet these requirements with the LEAST amount of application changes?</h1>
    
      <label for="optionA">A. Use Amazon Redshift for the product catalog and Amazon DynamoDB tables for the customer information and purchases.</label>
      <label for="optionB">B. Use Amazon DynamoDB global tables for the product catalog and regional tables for the customer information and purchases.</label>
      <label for="optionC" class="correct-answer">C. Use Aurora with read replicas for the product catalog and additional local Aurora instances in each region for the customer information and purchases. &#x2713;</label>
      <label for="optionD">D. Use Aurora for the product catalog and Amazon DynamoDB global tables for the customer information and purchases.</label>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company wants to ensure that their EC2 instances are secure. They want to be notified if any new vulnerabilities are discovered on their instances, and they also want an audit trail of all login activities on the instances.
      </h1>
      <h1 class="question">Which solution will meet these requirements?</h1>
    
      <label for="optionA">
        A. Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Amazon Kinesis Agent to capture system logs and deliver them to Amazon S3.
      </label>
    
      <label for="optionB">
        B. Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Systems Manager Agent to capture system logs and view login activity in the CloudTrail console.
      </label>
    
      <label for="optionC">
        C. Configure Amazon CloudWatch to detect vulnerabilities on the EC2 instances. Install the AWS Config daemon to capture system logs and view them in the AWS Config console.
      </label>
    
      <label for="optionD" class="correct-answer">
        D. Configure Amazon Inspector to detect vulnerabilities on the EC2 instances. Install the Amazon CloudWatch Agent to capture system logs and record them via Amazon CloudWatch Logs. &#x2713;
      </label>
    </form>
    <form class="question-form">
      <h1 class="question">A DevOps Engineer needs to back up sensitive Amazon S3 objects that are stored within an S3 bucket with a private bucket policy using the S3 cross-region replication functionality. The objects need to be copied to a target bucket in a different AWS Region and account. Which actions should be performed to enable this replication? (Choose three.)</h1>
    
      <label for="optionA" class="correct-answer">A. Create a replication IAM role in the source account. &#x2713;</label><br>
      <label for="optionB">B. Create a replication IAM role in the target account.</label><br>
      <label for="optionC">C. Add statements to the source bucket policy allowing the replication IAM role to replicate objects.</label><br>
      <label for="optionD" class="correct-answer">D. Add statements to the target bucket policy allowing the replication IAM role to replicate objects. &#x2713;</label><br>
      <label for="optionE" class="correct-answer">E. Create a replication rule in the source bucket to enable the replication. &#x2713;</label><br>
      <label for="optionF">F. Create a replication rule in the target bucket to enable the replication.</label><br>
    </form>
    <form class="question-form">
      <h1 class="question">A company is using Amazon EC2 for various workloads. Company policy requires that instances be managed centrally to standardize configurations. These configurations include standard logging, metrics, security assessments, and weekly patching.</h1>
      <h1 class="question">How can the company meet these requirements? (Choose three.)</h1>
    
      <label for="optionA" class="correct-answer">A. Use AWS Config to ensure all EC2 instances are managed by AWS Systems Manager. &#x2713;</label><br>
      <label for="optionB">B. Use AWS Config to ensure all EC2 instances are managed by Amazon Inspector.</label><br>
      <label for="optionC" class="correct-answer">C. Use AWS Systems Manager to install and manage Amazon Inspector, Systems Manager Patch Manager, and the Amazon CloudWatch agent on all instances. &#x2713;</label><br>
      <label for="optionD">D. Use Amazon Inspector to install and manage AWS Systems Manager, Systems Manager Patch Manager, and the Amazon CloudWatch agent on all instances.</label><br>
      <label for="optionE">E. Use AWS Systems Manager maintenance windows with Systems Manager Run Command to schedule Systems Manager Patch Manager tasks. Use the Amazon CloudWatch agent to schedule Amazon Inspector assessment runs.</label><br>
      <label for="optionF" class="correct-answer">F. Use AWS Systems Manager maintenance windows with Systems Manager Run Command to schedule Systems Manager Patch Manager tasks. Use Amazon CloudWatch Events to schedule Amazon Inspector assessment runs. &#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">
        A business has an application that consists of five independent AWS Lambda functions. The DevOps Engineer has built a CI/CD pipeline using AWS CodePipeline and AWS CodeBuild that builds, tests, packages, and deploys each Lambda function in sequence. The pipeline uses an Amazon CloudWatch Events rule to ensure the pipeline execution starts as quickly as possible after a change is made to the application source code.
      </h1>
      <h1 class="question">
        After working with the pipeline for a few months, the DevOps Engineer has noticed the pipeline takes too long to complete. What should the DevOps Engineer implement to BEST improve the speed of the pipeline?
      </h1>
    
      <label for="optionA">A. Modify the CodeBuild projects within the pipeline to use a compute type with more available network throughput.</label><br>
      <label for="optionB">B. Create a custom CodeBuild execution environment that includes a symmetric multiprocessing configuration to run the builds in parallel.</label><br>
      <label for="optionC" class="correct-answer">C. Modify the CodePipeline configuration to execute actions for each Lambda function in parallel by specifying the same runOrder. &#x2713;</label><br>
      <label for="optionD">D. Modify each CodeBuild project to run within a VPC and use dedicated instances to increase throughput.</label><br>
    </form>

    <form class="question-form">
      <h1 class="question">
        A company is creating a software solution that executes a specific parallel-processing mechanism. The software can scale to tens of servers in some special scenarios. This solution uses a proprietary library that is license-based, requiring that each individual server have a single, dedicated license installed. The company has 200 licenses and is planning to run 200 server nodes concurrently at most.
      </h1>
      <h1 class="question">
        The company has requested the following features:
        <ul>
          <li>A mechanism to automate the use of the licenses at scale.</li>
          <li>Creation of a dashboard to use in the future to verify which licenses are available at any moment.</li>
        </ul>
      </h1>
      <h1 class="question">
        What is the MOST effective way to accomplish these requirements?
      </h1>
    
      <label for="optionA">A. Upload the licenses to a private Amazon S3 bucket. Create an AWS CloudFormation template with a Mappings section for the licenses. In the template, create an Auto Scaling group to launch the servers. In the user data script, acquire an available license from the Mappings section. Create an Auto Scaling lifecycle hook, then use it to update the mapping after the instance is terminated.</label><br>
    
      <label for="optionB">B. Upload the licenses to a private Amazon S3 bucket. Populate an Amazon SQS queue with the list of licenses stored in S3. Create an AWS CloudFormation template that uses an Auto Scaling group to launch the servers. In the user data script acquire an available license from SQS. Create an Auto Scaling lifecycle hook, then use it to put the license back in SQS after the instance is terminated.</label><br>
    
      <label for="optionC" class="correct-answer">C. Upload the licenses to an Amazon DynamoDB table. Create an AWS CloudFormation template that uses an Auto Scaling group to launch the servers. In the user data script, acquire an available license from the DynamoDB table. Create an Auto Scaling lifecycle hook, then use it to update the mapping after the instance is terminated . &#x2713;</label><br>
    
      <label for="optionD">D. Upload the licenses to an Amazon DynamoDB table. Create an AWS CLI script to launch the servers by using the parameter --count, with min:max instances to launch. In the user data script, acquire an available license from the DynamoDB table. Monitor each instance and, in case of failure, replace the instance, then manually update the DynamoDB table.</label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A DevOps Engineer administers an application that manages video files for a video production company. The application runs on Amazon EC2 instances behind an ELB Application Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones. Data is stored in an Amazon RDS PostgreSQL Multi-AZ DB instance, and the video files are stored in an Amazon S3 bucket. On a typical day, 50 GB of new video are added to the S3 bucket. The Engineer must implement a multi-region disaster recovery plan with the least data loss and the lowest recovery times. The current application infrastructure is already described using AWS CloudFormation.
      </h1>
      <h1 class="question">
        Which deployment option should the Engineer choose to meet the uptime and recovery objectives for the system?
      </h1>
    
      <label for="optionA">A. Launch the application from the CloudFormation template in the second region, which sets the capacity of the Auto Scaling group to 1.</label><br>
    
      <label for="optionB" class="correct-answer">
        B. Create an Amazon RDS read replica in the second region. In the second region, enable cross-region replication between the original S3 bucket and a new S3 bucket. To fail over, promote the read replica as master. Update the CloudFormation stack and increase the capacity of the Auto Scaling group. &#x2713;
      </label><br>
    
      <label for="optionC">C. Launch the application from the CloudFormation template in the second region, which sets the capacity of the Auto Scaling group to 1. Create a scheduled task to take daily Amazon RDS cross-region snapshots to the second region. In the second region, enable cross-region replication between the original S3 bucket and Amazon Glacier. In a disaster, launch a new application stack in the second region and restore the database from the most recent snapshot.</label><br>
    
      <label for="optionD">D. Launch the application from the CloudFormation template in the second region, which sets the capacity of the Auto Scaling group to 1. Use Amazon CloudWatch Events to schedule a nightly task to take a snapshot of the database, copy the snapshot to the second region, and replace the DB instance in the second region from the snapshot. In the second region, enable cross-region replication between the original S3 bucket and a new S3 bucket. To fail over, increase the capacity of the Auto Scaling group.</label><br>
    
      <label for="optionE">E. Use Amazon CloudWatch Events to schedule a nightly task to take a snapshot of the database and copy the snapshot to the second region. Create an AWS Lambda function that copies each object to a new S3 bucket in the second region in response to S3 event notifications. In the second region, launch the application from the CloudFormation template and restore the database from the most recent snapshot.</label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company has multiple AWS accounts in an organization in AWS Organizations that has all features enabled. The company’s DevOps administrator needs to improve security across all the company's AWS accounts. The administrator needs to identify the top users and roles in use across all accounts.
      </h1>
      <h1 class="question">
        Which solution will meet these requirements with the MOST operational efficiency?
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Create a new organization trail in AWS CloudTrail. Configure the trail to send log events to Amazon CloudWatch Logs. Create a CloudWatch Contributor Insights rule for the userIdentity.arn log field. View the results in CloudWatch Contributor Insights. &#x2713;
      </label><br>
    
      <label for="optionB">
        B. Create an unused access analysis for the organization by using AWS Identity and Access Management Access Analyzer. Review the analyzer results and determine if each finding has the intended level of permissions required for the workload.
      </label><br>
    
      <label for="optionC">
        C. Create a new organization trail in AWS CloudTrail. Create a table in Amazon Athena that uses partition projection. Load the Athena table with CloudTrail data. Query the Athena table to find the top users and roles.
      </label><br>
    
      <label for="optionD">
        D. Generate a Service access report for each account by using Organizations. From the results, pull the last accessed date and last accessed by account fields to find the top users and roles.
      </label><br>
    </form>

    <form class="question-form">
      <h1 class="question">
        A company manages 500 AWS accounts that are in an organization in AWS Organizations. The company discovers many unattached Amazon Elastic Block Store (Amazon EBS) volumes in all the accounts. The company wants to automatically tag the unattached EBS volumes for investigation.
      </h1>
      <h1 class="question">
        A DevOps engineer needs to deploy an AWS Lambda function to all the AWS accounts. The Lambda function must run every 30 minutes to tag all the EBS volumes that have been unattached for a period of 7 days or more.
      </h1>
      <h1 class="question">
        Which solution will meet these requirements in the MOST operationally efficient manner?
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Configure a delegated administrator account for the organization. Create an AWS CloudFormation template that contains the Lambda function and an Amazon EventBridge scheduled rule to invoke the Lambda function every 30 minutes. Use CloudFormation StackSets to deploy the CloudFormation template from the delegated administrator account to all the member accounts in the organization.. &#x2713;
      </label><br>
    
      <label for="optionB">
        B. Create a cross-account IAM role in the organization's member accounts. Attach the AWSLambda_FullAccess policy and the AWSCloudFormationFullAccess policy to the role. Create an AWS CloudFormation template that contains the Lambda function and an Amazon EventBridge scheduled rule to invoke the Lambda function every 30 minutes. Create a custom script in the organization’s management account that assumes the role and deploys the CloudFormation template to the member accounts.
      </label><br>
    
      <label for="optionC">
        C. AM role in the organization's member accounts. Attach the AWSLambda_FullAccess policy and the AWSCloudFormationFullAccess policy to the role. Create an AWS CloudFormation template that contains the Lambda function a 
      </label><br>
    
      <label for="optionD">
        D. Create a cross-account IAM role in the organization's member accounts. Attach the AmazonS3FullAccess policy and the AWSCodeDeployDeployerAccess policy to the role. Use AWS CodeDeploy to assume the role to deploy the Lambda function from the organization's management account. Configure an Amazon EventBridge scheduled rule in the member accounts to invoke the Lambda function every 30 minutes.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A DevOps engineer is planning to deploy a Ruby-based application to production. The application needs to interact with an Amazon RDS for MySQL database and should have automatic scaling and high availability. The stored data in the database is critical and should persist regardless of the state of the application stack.
      </h1>
      <h1 class="question">
        The DevOps engineer needs to set up an automated deployment strategy for the application with automatic rollbacks. The solution also must alert the application team when a deployment fails.
      </h1>
      <h1 class="question">
        Which combination of steps will meet these requirements? (Choose three.)
      </h1>
    
      <label for="optionA">
        A. Deploy the application on AWS Elastic Beanstalk. Deploy an Amazon RDS for MySQL DB instance as part of the Elastic Beanstalk configuration.
      </label><br>
    
      <label for="optionB" class="correct-answer">
        B. Deploy the application on AWS Elastic Beanstalk. Deploy a separate Amazon RDS for MySQL DB instance outside of Elastic Beanstalk. &#x2713;
      </label><br>
    
      <label for="optionC" class="correct-answer">
        C. Configure a notification email address that alerts the application team in the AWS Elastic Beanstalk configuration. &#x2713;
      </label><br>
    
      <label for="optionD">
        D. Configure an Amazon EventBridge (Amazon CloudWatch Events) rule to monitor AWS Health events. Use an Amazon Simple Notification Service (Amazon SNS) topic as a target to alert the application team.
      </label><br>
    
      <label for="optionE" class="correct-answer">
        E. Use the immutable deployment method to deploy new application versions. &#x2713;
      </label><br>
    
      <label for="optionF">
        F. Use the rolling deployment method to deploy new application versions.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        An ecommerce company is looking for ways to deploy an application on AWS that satisfies the following requirements:
      </h1>
      <ul>
        <li>Has a simple and automated application deployment process.</li>
        <li>Has minimal deployment costs while ensuring that at least half of the instances are available to receive end-user requests.</li>
        <li>If the application fails, an automated healing mechanism will replace the affected instances.</li>
      </ul>
      <h1 class="question">
        Which deployment strategy will meet these requirements?
      </h1>
    
      <label for="optionA">
        A. Create an AWS Elastic Beanstalk environment and configure it to use Auto Scaling and an Elastic Load Balancer. Use rolling deployments with a batch size of 50%.
      </label><br>
    
      <label for="optionB">
        B. Create an AWS OpsWorks stack. Configure the application layer to use rolling deployments as a deployment strategy. Add an Elastic Load Balancing layer. Enable auto healing on the application layer.
      </label><br>
    
      <label for="optionC" class="correct-answer">
        C. Use AWS CodeDeploy with Auto Scaling and an Elastic Load Balancer. Use the CodeDeployDefault.HalfAtATime deployment strategy. Enable an Elastic Load Balancing health check to report the status of the application, and set the Auto Scaling health check to ELB. &#x2713;
      </label><br>
    
      <label for="optionD">
        D. Use AWS CodeDeploy with Auto Scaling and an Elastic Load Balancer. Use a blue/green deployment strategy. Enable an Elastic Load Balancing health check to report the status of the application, and set the Auto Scaling health check to ELB.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company wants to ensure that their EC2 instances are secure. They want to be notified if any new vulnerabilities are discovered on their instances, and they also want an audit trail of all login activities on the instances.
      </h1>
      <h1 class="question">
        Which solution will meet these requirements?
      </h1>
    
      <label for="optionA">
        A. Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Amazon Kinesis Agent to capture system logs and deliver them to Amazon S3.
      </label><br>
    
      <label for="optionB">
        B. Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Systems Manager Agent to capture system logs and view login activity in the CloudTrail console.
      </label><br>
    
      <label for="optionC">
        C. Configure Amazon CloudWatch to detect vulnerabilities on the EC2 instances. Install the AWS Config daemon to capture system logs and view them in the AWS Config console.
      </label><br>
    
      <label for="optionD" class="correct-answer">
        D. Configure Amazon Inspector to detect vulnerabilities on the EC2 instances. Install the Amazon CloudWatch Agent to capture system logs and record them via Amazon CloudWatch Logs. &#x2713;
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        An online retail company based in the United States plans to expand its operations to Europe and Asia in the next six months. Its product currently runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. All data is stored in an Amazon Aurora database instance.
      </h1>
      <h1 class="question">
        When the product is deployed in multiple regions, the company wants a single product catalog across all regions, but for compliance purposes, its customer information and purchases must be kept in each region.
      </h1>
      <h1 class="question">
        How should the company meet these requirements with the LEAST amount of application changes?
      </h1>
    
      <label for="optionA">
        A. Use Amazon Redshift for the product catalog and Amazon DynamoDB tables for the customer information and purchases.
      </label><br>
    
      <label for="optionB" class="correct-answer">
        B. Use Amazon DynamoDB global tables for the product catalog and regional tables for the customer information and purchases. &#x2713;
      </label><br>
    
      <label for="optionC">
        C. Use Aurora with read replicas for the product catalog and additional local Aurora instances in each region for the customer information and purchases.
      </label><br>
    
      <label for="optionD">
        D. Use Aurora for the product catalog and Amazon DynamoDB global tables for the customer information and purchases.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company has a mobile application that makes HTTP API calls to an Application Load Balancer (ALB). The ALB routes requests to an AWS Lambda function. Many different versions of the application are in use at any given time, including versions that are in testing by a subset of users. The version of the application is defined in the user-agent header that is sent with all requests to the API.
      </h1>
      <h1 class="question">
        After a series of recent changes to the API, the company has observed issues with the application. The company needs to gather a metric for each API operation by response code for each version of the application that is in use. A DevOps engineer has modified the Lambda function to extract the API operation name, version information from the user-agent header and response code.
      </h1>
      <h1 class="question">
        Which additional set of actions should the DevOps engineer take to gather the required metrics?
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Modify the Lambda function to write the API operation name, response code, and version number as a log line to an Amazon CloudWatch Logs log group. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric. &#x2713;
      </label><br>
    
      <label for="optionB">
        B. Modify the Lambda function to write the API operation name, response code, and version number as a log line to an Amazon CloudWatch Logs log group. Configure a CloudWatch Logs Insights query to populate CloudWatch metrics from the log lines. Specify response code and application version as dimensions for the metric.
      </label><br>
    
      <label for="optionC">
        C. Configure the ALB access logs to write to an Amazon CloudWatch Logs log group. Modify the Lambda function to respond to the ALB with the API operation name, response code, and version number as response metadata. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric.
      </label><br>
    
      <label for="optionD">
        D. Configure AWS X-Ray integration on the Lambda function. Modify the Lambda function to create an X-Ray subsegment with the API operation name, response code, and version number. Configure X-Ray insights to extract an aggregated metric for each API operation name and to publish the metric to Amazon CloudWatch. Specify response code and application version as dimensions for the metric.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company has a mobile application that makes HTTP API calls to an Application Load Balancer (ALB). The ALB routes requests to an AWS Lambda function. Many different versions of the application are in use at any given time, including versions that are in testing by a subset of users. The version of the application is defined in the user-agent header that is sent with all requests to the API.
      </h1>
      <h1 class="question">
        After a series of recent changes to the API, the company has observed issues with the application. The company needs to gather a metric for each API operation by response code for each version of the application that is in use. A DevOps engineer has modified the Lambda function to extract the API operation name, version information from the user-agent header and response code.
      </h1>
      <h1 class="question">
        Which additional set of actions should the DevOps engineer take to gather the required metrics?
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Modify the Lambda function to write the API operation name, response code, and version number as a log line to an Amazon CloudWatch Logs log group. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric. &#x2713;
      </label><br>
    
      <label for="optionB">
        B. Modify the Lambda function to write the API operation name, response code, and version number as a log line to an Amazon CloudWatch Logs log group. Configure a CloudWatch Logs Insights query to populate CloudWatch metrics from the log lines. Specify response code and application version as dimensions for the metric.
      </label><br>
    
      <label for="optionC">
        C. Configure the ALB access logs to write to an Amazon CloudWatch Logs log group. Modify the Lambda function to respond to the ALB with the API operation name, response code, and version number as response metadata. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric.
      </label><br>
    
      <label for="optionD">
        D. Configure AWS X-Ray integration on the Lambda function. Modify the Lambda function to create an X-Ray subsegment with the API operation name, response code, and version number. Configure X-Ray insights to extract an aggregated metric for each API operation name and to publish the metric to Amazon CloudWatch. Specify response code and application version as dimensions for the metric.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company uses AWS Organizations to manage its AWS accounts. The organization root has a child OU named Department. The Department OU has a child OU named Engineering. The default FullAWSAccess policy is attached to the root, the Department OU, and the Engineering OU.
      </h1>
      <h1 class="question">
        The company has many AWS accounts in the Engineering OU. Each account has an administrative IAM role with the AdministratorAccess IAM policy attached. The default FullAWSAccess policy is also attached to each account.
      </h1>
      <h1 class="question">
        A DevOps engineer plans to remove the FullAWSAccess policy from the Department OU. The DevOps engineer will replace the policy with a policy that contains an Allow statement for all Amazon EC2 API operations.
      </h1>
      <h1 class="question">
        What will happen to the permissions of the administrative IAM roles as a result of this change?
      </h1>
    
      <label for="optionA">
        A. All API actions on all resources will be allowed.
      </label><br>
    
      <label for="optionB" class="correct-answer">
        B. All API actions on EC2 resources will be allowed. All other API actions will be denied. &#x2713;
      </label><br>
    
      <label for="optionC">
        C. All API actions on all resources will be denied.
      </label><br>
    
      <label for="optionD">
        D. All API actions on EC2 resources will be denied. All other API actions will be allowed.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company wants to deploy a workload on several hundred Amazon EC2 instances. The company will provision the EC2 instances in an Auto Scaling group by using a launch template.
      </h1>
      <h1 class="question">
        The workload will pull files from an Amazon S3 bucket, process the data, and put the results into a different S3 bucket. The EC2 instances must have least-privilege permissions and must use temporary security credentials.
      </h1>
      <h1 class="question">
        Which combination of steps will meet these requirements? (Select TWO.)
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Create an IAM role that has the appropriate permissions for S3 buckets. Add the IAM role to an instance profile. &#x2713;
      </label><br>
    
      <label for="optionB" class="correct-answer">
        B. Update the launch template to include the IAM instance profile. &#x2713;
      </label><br>
    
      <label for="optionC">
        C. Create an IAM user that has the appropriate permissions for Amazon S3. Generate a secret key and token.
      </label><br>
    
      <label for="optionD">
        D. Create a trust anchor and profile. Attach the IAM role to the profile.
      </label><br>
    
      <label for="optionE">
        E. Update the launch template. Modify the user data to use the new secret key and token.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company is using an Amazon Aurora cluster as the data store for its application. The Aurora cluster is configured with a single DB instance. The application performs read and write operations on the database by using the cluster's instance endpoint.
      </h1>
      <h1 class="question">
        The company has scheduled an update to be applied to the cluster during an upcoming maintenance window. The cluster must remain available with the least possible interruption during the maintenance window.
      </h1>
      <h1 class="question">
        What should a DevOps engineer do to meet these requirements?
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Add a reader instance to the Aurora cluster. Update the application to use the Aurora cluster endpoint for write operations. Update the Aurora cluster's reader endpoint for reads. &#x2713;
      </label><br>
    
      <label for="optionB">
        B. Add a reader instance to the Aurora cluster. Create a custom ANY endpoint for the cluster. Update the application to use the Aurora cluster's custom ANY endpoint for read and write operations.
      </label><br>
    
      <label for="optionC">
        C. Turn on the Multi-AZ option on the Aurora cluster. Update the application to use the Aurora cluster endpoint for write operations. Update the Aurora cluster's reader endpoint for reads.
      </label><br>
    
      <label for="optionD">
        D. Turn on the Multi-AZ option on the Aurora cluster. Create a custom ANY endpoint for the cluster. Update the application to use the Aurora cluster's custom ANY endpoint for read and write operations.
      </label><br>
    </form>

    <form class="question-form">
      <h1 class="question">
        A DevOps engineer has created an AWS CloudFormation template that deploys an application on Amazon EC2 instances. The EC2 instances run Amazon Linux. The application is deployed to the EC2 instances by using shell scripts that contain user data. The EC2 instances have an IAM instance profile that has an IAM role with the AmazonSSMManagedInstanceCore managed policy attached.
      </h1>
      <h1 class="question">
        The DevOps engineer has modified the user data in the CloudFormation template to install a new version of the application. The engineer has also applied the stack update. However, the application was not updated on the running EC2 instances. The engineer needs to ensure that the changes to the application are installed on the running EC2 instances.
      </h1>
      <h1 class="question">
        Which combination of steps will meet these requirements? (Choose two.)
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Refactor the user data command to use an AWS Systems Manager document (SSM document). Use Systems Manager State Manager to create an association between the SSM document and the EC2 instances. &#x2713;
      </label><br>
    
      <label for="optionB" class="correct-answer">
        B. Refactor the user data commands to use the cfn-init helper script. Update the user data to install and configure the cfn-hup and cfn-init helper scripts to monitor and apply the metadata changes. &#x2713;
      </label><br>
    
      <label for="optionC">
        C. Configure an EC2 launch template for the EC2 instances. Create a new EC2 Auto Scaling group. Associate the Auto Scaling group with the EC2 launch template. Use the AutoScalingScheduledAction update policy for the Auto Scaling group.
      </label><br>
    
      <label for="optionD">
        D. Refactor the user data commands to use an AWS Systems Manager document (SSM document). Add an AWS CLI command in the user data to use Systems Manager Run Command to apply the SSM document to the EC2 instances.
      </label><br>
    
      <label for="optionE">
        E. commands to use an AWS Systems Manager document (SSM document). Add an AWS CLI command in the user data to use Systems Manager Run Command to apply the SSM document to the EC2 i.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company uses several AWS CloudFormation stacks to handle the deployment of a suite of applications. The leader of the company's application development team notices that the stack deployments fail with permission errors when some team members try to deploy the stacks. However, other team members can deploy the stacks successfully.
      </h1>
      <h1 class="question">
        The team members access the account by assuming a role that has a specific set of permissions that are necessary for the job responsibilities of the team members. All team members have permissions to perform operations on the stacks.
      </h1>
      <h1 class="question">
        Which combination of steps will ensure consistent deployment of the stacks MOST securely? (Choose three.)
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Create a service role that has a composite principal that contains each service that needs the necessary permissions. Configure the role to allow the sts:AssumeRole action. &#x2713;
      </label><br>
    
      <label for="optionB" class="correct-answer">
        B. Create a service role that has cloudformation.amazonaws.com as the service principal. Configure the role to allow the sts:AssumeRole action. &#x2713;
      </label><br>
    
      <label for="optionC">
        C. For each required set of permissions, add a separate policy to the role to allow those permissions. Add the ARN of each CloudFormation stack in the resource field of each policy.
      </label><br>
    
      <label for="optionD">
        D. For each required set of permissions, add a separate policy to the role to allow those permissions. Add the ARN of each service that needs the permissions in the resource field of the corresponding policy.
      </label><br>
    
      <label for="optionE" class="correct-answer">
        E. Update each stack to use the service role. &#x2713;
      </label><br>
    
      <label for="optionF" class="correct-answer">
        F. Add a policy to each member role to allow the iam:PassRole action. Set the policy's resource field to the ARN of the service role. &#x2713;
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company wants to migrate its content sharing web application hosted on Amazon EC2 to a serverless architecture. The company currently deploys changes to its application by creating a new Auto Scaling group of EC2 instances and a new Elastic Load Balancer, and then shifting the traffic away using an Amazon Route 53 weighted routing policy.
      </h1>
      <h1 class="question">
        For its new serverless application, the company is planning to use Amazon API Gateway and AWS Lambda. The company will need to update its deployment processes to work with the new application. It will also need to retain the ability to test new features on a small number of users before rolling the features out to the entire user base.
      </h1>
      <h1 class="question">
        Which deployment strategy will meet these requirements?
      </h1>
    
      <label for="optionA">
        A. Use AWS CDK to deploy API Gateway and Lambda functions. When code needs to be changed, update the AWS CloudFormation stack and deploy the new version of the APIs and Lambda functions. Use a Route 53 failover routing policy for the canary release strategy.
      </label><br>
    
      <label for="optionB" class="correct-answer">
        B. Use AWS CloudFormation to deploy API Gateway and Lambda functions using Lambda function versions. When code needs to be changed, update the CloudFormation stack with the new Lambda code and update the API versions using a canary release strategy. Promote the new version when testing is complete. &#x2713;
      </label><br>
    
      <label for="optionC">
        C. Use AWS Elastic Beanstalk to deploy API Gateway and Lambda functions. When code needs to be changed, deploy a new version of the API and Lambda functions. Shift traffic gradually using an Elastic Beanstalk blue/green deployment.
      </label><br>
    
      <label for="optionD">
        D. Use AWS OpsWorks to deploy API Gateway in the service layer and Lambda functions in a custom layer. When code needs to be changed, use OpsWorks to perform a blue/green deployment and shift traffic gradually.
      </label><br>
    </form>
    <form class="question-form">
  <h1 class="question">
    A company needs to architect a hybrid DNS solution. This solution will use an Amazon Route 53 private hosted zone for the domain <code>cloud.example.com</code> for the resources stored within VPCs.
  </h1>
  <h1 class="question">
    The company has the following DNS resolution requirements:
    <ul>
      <li>On-premises systems should be able to resolve and connect to <code>cloud.example.com</code>.</li>
      <li>All VPCs should be able to resolve <code>cloud.example.com</code>.</li>
      <li>There is already an AWS Direct Connect connection between the on-premises corporate network and AWS Transit Gateway.</li>
    </ul>
  </h1>
  <h1 class="question">
    Which architecture should the company use to meet these requirements with the <strong>HIGHEST performance</strong>?
  </h1>

  <label for="optionA" class="correct-answer">
    A. Associate the private hosted zone to all the VPCs. Create a Route 53 inbound resolver in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for <code>cloud.example.com</code> that point to the inbound resolver. &#x2713;
  </label><br>

  <label for="optionB">
    B. Associate the private hosted zone to all the VPCs. Deploy an Amazon EC2 conditional forwarder in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for <code>cloud.example.com</code> that point to the conditional forwarder.
  </label><br>

  <label for="optionC">
    C. Associate the private hosted zone to the shared services VPC. Create a Route 53 outbound resolver in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for <code>cloud.example.com</code> that point to the outbound resolver.
  </label><br>

  <label for="optionD">
    D. Associate the private hosted zone to the shared services VPC. Create a Route 53 inbound resolver in the shared services VPC. Attach the shared services VPC to the transit gateway and create forwarding rules in the on-premises DNS server for <code>cloud.example.com</code> that point to the inbound resolver.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company is providing weather data over a REST-based API to several customers. The API is hosted by Amazon API Gateway and is integrated with different AWS Lambda functions for each API operation.
  </h1>
  <h1 class="question">
    The company uses Amazon Route 53 for DNS and has created a resource record of <code>weather.example.com</code>. The company stores data for the API in Amazon DynamoDB tables.
  </h1>
  <h1 class="question">
    The company needs a solution that will give the API the ability to fail over to a different AWS Region.
  </h1>
  <h1 class="question">
    Which solution will meet these requirements?
  </h1>

  <label for="optionA">
    A. Deploy a new set of Lambda functions in a new Region. Update the API Gateway API to use an edge-optimized API endpoint with Lambda functions from both Regions as targets. Convert the DynamoDB tables to global tables.
  </label><br>

  <label for="optionB">
    B. Deploy a new API Gateway API and Lambda functions in another Region. Change the Route 53 DNS record to a multivalue answer. Add both API Gateway APIs to the answer. Enable target health monitoring. Convert the DynamoDB tables to global tables.
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Deploy a new API Gateway API and Lambda functions in another Region. Change the Route 53 DNS record to a failover record. Enable target health monitoring. Convert the DynamoDB tables to global tables. &#x2713;
  </label><br>

  <label for="optionD">
    D. Deploy a new API Gateway API in a new Region. Change the Lambda functions to global functions. Change the Route 53 DNS record to a multivalue answer. Add both API Gateway APIs to the answer. Enable target health monitoring. Convert the DynamoDB tables to global tables.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company uses AWS Organizations with a single OU named <strong>Production</strong> to manage multiple accounts. All accounts are members of the Production OU. Administrators use deny list SCPs in the root of the organization to manage access to restricted services.
  </h1>
  <h1 class="question">
    The company recently acquired a new business unit and invited the new unit’s existing AWS account to the organization. Once onboarded, the administrators of the new business unit discovered that they are not able to update existing AWS Config rules to meet the company’s policies.
  </h1>
  <h1 class="question">
    Which option will allow administrators to make changes and continue to enforce the current policies without introducing additional long-term maintenance?
  </h1>

  <label for="optionA">
    A. Remove the organization’s root SCPs that limit access to AWS Config. Create AWS Service Catalog products for the company’s standard AWS Config rules and deploy them throughout the organization, including the new account.
  </label><br>

  <label for="optionB" class="correct-answer">
    B. Create a temporary OU named Onboarding for the new account. Apply an SCP to the Onboarding OU to allow AWS Config actions. Move the organization’s root SCP to the Production OU. Move the new account to the Production OU when adjustments to AWS Config are complete.;
  </label><br>

  <label for="optionC">
    C. Convert the organization’s root SCPs from deny list SCPs to allow list SCPs to allow the required services only. Temporarily apply an SCP to the organization’s root that allows AWS Config actions for principals only in the new account.
  </label><br>

  <label for="optionD">
    D. Create oot SCPs from deny list SCPs to allow list SCPs to allow the required services only. Temporarily apply an SCP to the organization’s root that allows AWS Config actions for principals only in the new ac complete.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company is running a two-tier web-based application in an on-premises data center. The application layer consists of a single server running a stateful application. The application connects to a PostgreSQL database running on a separate server.
  </h1>
  <h1 class="question">
    The application’s user base is expected to grow significantly, so the company is migrating the application and database to AWS. The solution will use Amazon Aurora PostgreSQL, Amazon EC2 Auto Scaling, and Elastic Load Balancing.
  </h1>
  <h1 class="question">
    Which solution will provide a consistent user experience that will allow the application and database tiers to scale?
  </h1>

  <label for="optionA">
    A. Enable Aurora Auto Scaling for Aurora Replicas. Use a Network Load Balancer with the least outstanding requests routing algorithm and sticky sessions enabled.
  </label><br>

  <label for="optionB">
    B. Enable Aurora Auto Scaling for Aurora writers. Use an Application Load Balancer with the round robin routing algorithm and sticky sessions enabled.
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Enable Aurora Auto Scaling for Aurora Replicas. Use an Application Load Balancer with the round robin routing and sticky sessions enabled. &#x2713;
  </label><br>

  <label for="optionD">
    D. Enable Aurora Scaling for Aurora writers. Use a Network Load Balancer with the least outstanding requests routing algorithm and sticky sessions enabled.
  </label><br>
</form>


<form class="question-form">
  <h1 class="question">
    A company uses a service to collect metadata from applications that the company hosts on premises. Consumer devices such as TVs and internet radios access the applications. Many older devices do not support certain HTTP headers and exhibit errors when these headers are present in responses.
  </h1>
  <h1 class="question">
    The company has configured an on-premises load balancer to remove the unsupported headers from responses sent to older devices, which the company identified by the <code>User-Agent</code> headers.
  </h1>
  <h1 class="question">
    The company wants to migrate the service to AWS, adopt serverless technologies, and retain the ability to support the older devices. The company has already migrated the applications into a set of AWS Lambda functions.
  </h1>
  <h1 class="question">
    Which solution will meet these requirements?
  </h1>

  <label for="optionA">
    A. ateway HTTP API for the metadata service. Configure API Gateway to invoke the correct Lambda function for each type of request. Create a response mapping template to remove the problr.
  </label><br>

  <label for="optionB">
    B. Create an Amazon API Gateway REST API for the metadata service. Configure API Gateway to invoke the correct Lambda function for each type of request. Modify the default gateway responses to remove the problematic headers based on the value of the <code>User-Agent</code> header.
  </label><br>

  <label for="optionC">
    C. Create an Amazon API Gateway HTTP API for the metadata service. Configure API Gateway to invoke the correct Lambda function for each type of request. Create a response mapping template to remove the problematic headers based on the value of the <code>User-Agent</code>. Associate the response data mapping with the HTTP API.
  </label><br>

  <label for="optionD" class="correct-answer">
    D. Create an Amazon CloudFront distribution for the metadata service. Create an Application Load Balancer (ALB). Configure the CloudFront distribution to forward requests to the ALB. Configure the ALB to invoke the correct Lambda function for each type of request. Create a CloudFront function to remove the problematic headers based on the value of the <code>User-Agent</code> header.;
  </label><br>
</form>

<form class="question-form">
  <h1 class="question">
    A retail company needs to provide a series of data files to another company, which is its business partner. These files are saved in an Amazon S3 bucket under Account A, which belongs to the retail company.
  </h1>
  <h1 class="question">
    The business partner company wants one of its IAM users, <code>User_DataProcessor</code>, to access the files from its own AWS account (Account B).
  </h1>
  <h1 class="question">
    Which combination of steps must the companies take so that <code>User_DataProcessor</code> can access the S3 bucket successfully? <strong>(Choose two.)</strong>
  </h1>

  <label for="optionA">
    A. Turn on the cross-origin resource sharing (CORS) feature for the S3 bucket in Account A.
  </label><br>

  <label for="optionB" class="correct-answer">
    B. In Account A, set the S3 bucket policy to the following:<br>
    <pre>{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::AccountB-ID:user/User_DataProcessor"
      },
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::bucket-name/*"
    }
  ]
}</pre> &#x2713;
  </label><br>

  <label for="optionC">
    C. In Account A, set the S3 bucket policy to the following:<br>
    <pre>{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Deny",
      "Principal": "*",
      "Action": "s3:*",
      "Resource": "*"
    }
  ]
}</pre>
  </label><br>

  <label for="optionD" class="correct-answer">
    D. In Account B, set the permissions of <code>User_DataProcessor</code> to the following:<br>
    <pre>{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::bucket-name/*"
    }
  ]
}</pre> &#x2713;
  </label><br>

  <label for="optionE">
    E. In Account B, set the permissions of <code>User_DataProcessor</code> to the following:<br>
    <pre>{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Deny",
      "Action": "s3:*",
      "Resource": "*"
    }
  ]
}</pre>
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company is running a traditional web application on Amazon EC2 instances. The company needs to refactor the application as microservices that run on containers. Separate versions of the application exist in two distinct environments: <strong>production</strong> and <strong>testing</strong>.
  </h1>
  <h1 class="question">
    Load for the application is variable, but the minimum load and the maximum load are known. A solutions architect needs to design the updated application with a <strong>serverless architecture</strong> that <strong>minimizes operational complexity</strong>.
  </h1>
  <h1 class="question">
    Which solution will meet these requirements <strong>MOST cost-effectively</strong>?
  </h1>

  <label for="optionA" class="correct-answer">
    A.  Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Container Service (Amazon ECS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the ECS clusters.
  </label><br>

  <label for="optionB">
    B. Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Kubernetes Service (Amazon EKS) clusters with the Fargate launch type to handle
  </label><br>

  <label for="optionC">
    C. Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Kubernetes Service (Amazon EKS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the EKS clusters.
  </label><br>

  <label for="optionD">
    D. Upload the container images to AWS Elastic Beanstalk. In Elastic Beanstalk, create separate environments and deployments for production and testing. Configure two separate Application Load Balancers to direct traffic to the Elastic Beanstalk deployments.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company has a multi-tier web application that runs on a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB). The instances are in an Auto Scaling group. The ALB and the Auto Scaling group are replicated in a backup AWS Region. The minimum and maximum values for the Auto Scaling group in the backup Region are set to zero.
  </h1>
  <h1 class="question">
    An Amazon RDS Multi-AZ DB instance stores the application's data. The DB instance has a read replica in the backup Region. The application presents an endpoint to end users by using an Amazon Route 53 record.
  </h1>
  <h1 class="question">
    The company needs to reduce its <strong>RTO to less than 15 minutes</strong> by giving the application the ability to <strong>automatically fail over</strong> to the backup Region. The company does <strong>not</strong> have the budget for an active-active strategy.
  </h1>
  <h1 class="question">
    What should a solutions architect recommend to meet these requirements?
  </h1>

  <label for="optionA">
    A. Reconfigure the application’s Route 53 record with a latency-based routing policy that load balances traffic between the two ALBs. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Create an Amazon CloudWatch alarm that is based on the HTTPCode_Target_5XX_Count metric for the ALB in the primary Region. Configure the CloudWatch alarm to invoke the Lambda function.
  </label><br>

  <label for="optionB" class="correct-answer">
    B. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Configure Route 53 with a health check that monitors the web application and sends an Amazon Simple Notification Service (Amazon SNS) notification to the Lambda function when the health check status is unhealthy. Update the application’s Route 53 record with a failover policy that routes traffic to the ALB in the backup Region when a health check failure occurs. &#x2713;
  </label><br>

  <label for="optionC">
    C. Configure the Auto Scaling group in the backup Region to have the same values as the Auto Scaling group in the primary Region. Reconfigure the application’s Route 53 record with a latency-based routing policy that load balances traffic between the two ALBs. Remove the read replica. Replace the read replica with a standalone RDS DB instance. Configure Cross-Region Replication between the RDS DB instances by using snapshots and Amazon S3.
  </label><br>

  <label for="optionD">
    D. Configure an endpoint in AWS Global Accelerator with the two ALBs as equal weighted targets. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Create an Amazon CloudWatch alarm that is based on the HTTPCode_Target_5XX_Count metric for the ALB in the primary Region. Configure the CloudWatch alarm to invoke the Lambda function.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company is hosting a critical application on a single Amazon EC2 instance. The application uses an Amazon ElastiCache for Redis single-node cluster for an in-memory data store. The application uses an Amazon RDS for MariaDB DB instance for a relational database. For the application to function, each piece of the infrastructure must be healthy and in an active state.
  </h1>
  <h1 class="question">
    A solutions architect needs to improve the application's architecture so that the infrastructure can automatically recover from failure with the least possible downtime.
  </h1>
  <h1 class="question">
    Which combination of steps will meet these requirements? (Choose <strong>three</strong>.)
  </h1>

  <label for="optionA" class="correct-answer">
    A. Use an Elastic Load Balancer to distribute traffic across multiple EC2 instances. Ensure that the EC2 instances are part of an Auto Scaling group that has a minimum capacity of two instances. &#x2713;
  </label><br>

  <label for="optionB">
    B. Use an Elastic Load Balancer to distribute traffic across multiple EC2 instances. Ensure that the EC2 instances are configured in unlimited mode.
  </label><br>

  <label for="optionC">
    C. Modify the DB instance to create a read replica in the same Availability Zone. Promote the read replica to be the primary DB instance in failure scenarios.
  </label><br>

  <label for="optionD" class="correct-answer">
    D. Modify the DB instance to create a Multi-AZ deployment that extends across two Availability Zones. &#x2713;
  </label><br>

  <label for="optionE">
    E. Create a replication group for the ElastiCache for Redis cluster. Configure the cluster to use an Auto Scaling group that has a minimum capacity of two instances.
  </label><br>

  <label for="optionF" class="correct-answer">
    F. Create a replication group for the ElastiCache for Redis cluster. Enable Multi-AZ on the cluster. &#x2713;
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A retail company is operating its ecommerce application on AWS. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The company uses an Amazon RDS DB instance as the database backend. Amazon CloudFront is configured with one origin that points to the ALB. Static content is cached. Amazon Route 53 is used to host all public zones.
  </h1>
  <h1 class="question">
    After an update of the application, the ALB occasionally returns a 502 status code (Bad Gateway) error. The root cause is malformed HTTP headers that are returned to the ALB. The webpage returns successfully when a solutions architect reloads the webpage immediately after the error occurs.
  </h1>
  <h1 class="question">
    While the company is working on the problem, the solutions architect needs to provide a custom error page instead of the standard ALB error page to visitors.
  </h1>
  <h1 class="question">
    Which combination of steps will meet this requirement with the <strong>LEAST amount of operational overhead</strong>? (Choose <strong>two</strong>.)
  </h1>

  <label for="optionA" class="correct-answer">
    A. Create an Amazon S3 bucket. Configure the S3 bucket to host a static webpage. Upload the custom error pages to Amazon S3. &#x2713;
  </label><br>

  <label for="optionB">
    B. Create an Amazon CloudWatch alarm to invoke an AWS Lambda function if the ALB health check response Target.FailedHealthChecks is greater than 0. Configure the Lambda function to modify the forwarding rule at the ALB to point to a publicly accessible web server.
  </label><br>

  <label for="optionC">
    C. Modify the existing Amazon Route 53 records by adding health checks. Configure a fallback target if the health check fails. Modify DNS records to point to a publicly accessible webpage.
  </label><br>

  <label for="optionD">
    D. Create an Amazon CloudWatch alarm to invoke an AWS Lambda function if the ALB health check response Elb.InternalError is greater than 0. Configure the Lambda function to modify the forwarding rule at the ALB to point to a public accessible web server.
  </label><br>

  <label for="optionE" class="correct-answer">
    E. Add a custom error response by configuring a CloudFront custom error page. Modify DNS records to point to a publicly accessible web page. &#x2713;
  </label><br>
</form>




    
    


    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
   

    <!-- git commit -am "More Questions"; git push origin main  -->

    
    
    
    
    
   






  </div>
  <button class="scroll-top" id="scrollTop">↑</button>
  </div>

  <script>
    document.addEventListener("DOMContentLoaded", function () {
      // Remove duplicate questions
      const seenQuestions = new Map(); // Using Map to store both text and element
      const questionBlocks = document.querySelectorAll(".question-block");
      const contentDiv = document.getElementById('content');

      // First pass: identify duplicates
      questionBlocks.forEach(block => {
        const questionElement = block.querySelector(".question");
        const questionText = questionElement.textContent.trim();

        if (seenQuestions.has(questionText)) {
          // If we've seen this question before, remove the entire block
          block.remove();
        } else {
          // Store the first occurrence of this question
          seenQuestions.set(questionText, block);
        }
      });

      // Initialize scroll to top button
      const scrollTopBtn = document.getElementById('scrollTop');

      window.addEventListener('scroll', function () {
        if (window.pageYOffset > 300) {
          scrollTopBtn.style.display = 'block';
        } else {
          scrollTopBtn.style.display = 'none';
        }
      });

      scrollTopBtn.addEventListener('click', function () {
        window.scrollTo({
          top: 0,
          behavior: 'smooth'
        });
      });

      // Search functionality
      const searchInput = document.getElementById('search');
      const clearSearchBtn = document.getElementById('clear-search');
      const remainingQuestionBlocks = document.querySelectorAll(".question-block"); // Get updated list after deduplication

      searchInput.addEventListener('input', function () {
        const query = searchInput.value.toLowerCase();
        remainingQuestionBlocks.forEach(block => {
          const question = block.querySelector('.question');
          if (question.textContent.toLowerCase().includes(query)) {
            block.classList.remove('hidden');
          } else {
            block.classList.add('hidden');
          }
        });
      });

      // Clear search functionality
      clearSearchBtn.addEventListener('click', function () {
        searchInput.value = '';
        remainingQuestionBlocks.forEach(block => {
          block.classList.remove('hidden');
        });
        searchInput.focus();
      });
    });
  </script>
</body>

</html>