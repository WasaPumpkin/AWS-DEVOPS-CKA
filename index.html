<!DOCTYPE html>
<html lang="en">

<head>
  <title>Search in Questions</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      margin: 0;
      padding: 20px;
      background-color: #f5f5f5;
    }

    .container {
      background: #fff;
      padding: 20px;
      border-radius: 10px;
      width: 100%;
      margin: 0 auto;
    }

    .search-container {
      margin-bottom: 20px;
      width: 100%;
      max-width: 1900px;
      position: relative;
    }

    .search-bar {
      width: 100%;
      padding: 10px;
      padding-right: 70px;
      /* Space for buttons */
      font-size: 16px;
      border: 1px solid #ccc;
      border-radius: 5px;
      box-sizing: border-box;
    }

    .search-buttons {
      position: absolute;
      right: 10px;
      top: 50%;
      transform: translateY(-50%);
      display: flex;
      gap: 5px;
    }

    .search-button {
      background: #ddd;
      border: none;
      border-radius: 3px;
      padding: 3px 8px;
      cursor: pointer;
      font-size: 12px;
    }

    .search-button:hover {
      background: #ccc;
    }

    .question-block, .question-form {
      margin-bottom: 20px;
      padding: 15px;
      border: 1px solid #eee;
      border-radius: 5px;
    }

    .question {
      color: #333;
      margin: 0;
      font-size: 30px;
      background-color: yellow;
      padding: 10px;
    }

    img {
      width: 40%;
      height: auto;
      border-radius: 10px;
      margin: 10px;
    }

    .question-form {
      margin-top: 10px;
    }
    
    /* Remove redundant styling from form if it's inside a question-block */
    .question-block .question-form {
        margin-top: 10px;
        padding: 0;
        border: none;
    }

    .question-form label {
      display: block;
      margin: 5px 0;
      padding: 10px;
      border-radius: 5px;
      background-color: #f9f9f9;
      transition: background-color 0.3s;
    }

    .correct-answer {
      font-weight: bold;
      color: green;
      background-color: #e0ffe0;
      border: 1px solid green;
    }

    .scroll-top {
      position: fixed;
      bottom: 20px;
      right: 20px;
      background: #333;
      color: white;
      border: none;
      border-radius: 50%;
      width: 50px;
      height: 50px;
      font-size: 20px;
      cursor: pointer;
      display: none;
      z-index: 99;
    }

    .scroll-top:hover {
      background: #555;
    }
  </style>
</head>

<body>
  <div class="container">
    <div class="search-container">
      <input type="text" id="search" class="search-bar" placeholder="Search questions...">
      <div class="search-buttons">
        <button class="search-button" id="clear-search">X</button>
      </div>
    </div>
<form class="question-form">
  <h1 class="question">
    Someone is creating a VPC for their application hosting. He has created two private subnets in the same availability zone and created one subnet in a separate availability zone. He wants to make a High Availability system with an internal Elastic Load Balancer.
  </h1>
  <p>Which choice is true regarding internal ELBs in this scenario? (Choose 2 answers)</p>

  <label for="optionA" class="correct-answer">A. Internal ELBs should only be launched within private subnets. ✓✓</label>
  <label for="optionB">B. Amazon ELB service does not allow subnet selection; instead it will automatically select all the available subnets of the VPC.</label>
  <label for="optionC" class="correct-answer">C. Internal ELBs can support only one subnet in each availability zone. ✓✓</label>
  <label for="optionD">D. An internal ELB can support all the subnets irrespective of their zones.</label>
</form>
<form class="question-form">
  <h1 class="question">
    Your customer is willing to consolidate their log streams (access logs, application logs, security logs, etc.) in one single system. Once consolidated, the customer wants to analyze these logs in real time based on heuristics. From time to time, the customer needs to validate heuristics, which requires going back to data samples extracted from the last 12 hours.
  </h1>
  <p>What is the best approach to meet your customer's requirements?</p>

  <label for="optionA">A. Configure Amazon CloudTrail to receive custom logs, use EMR to apply heuristics the logs</label>
  <label for="optionB">B. Send all the log events to Amazon SQS, setup an Auto Scaling group of EC2 servers to consume the logs and apply the heuristics</label>
  <label for="optionC">C. Setup an Auto Scaling group of EC2 syslogd servers, store the logs on S3, use EMR to apply heuristics on the logs</label>
  <label for="optionD" class="correct-answer">D. Send all the log events to Amazon Kinesis, develop a client process to apply heuristics on the logs. ✓✓</label>
</form>
<form class="question-form">
  <h1 class="question">
    A company is running a batch analysis every hour on their main transactional DB, running on an RDS MySQL instance, to populate their central Data Warehouse running on Redshift. During the execution of the batch, their transactional applications are very slow. When the batch completes, they need to update the top management dashboard with the new data. The dashboard is produced by another system running on-premises that is currently started when a manually-sent email notifies that an update is required. The on-premises system cannot be modified because it is managed by another team.
  </h1>
  <p>How would you optimize this scenario to solve performance issues and automate the process as much as possible?</p>

  <label for="optionA">A. Replace RDS with Redshift for the batch analysis and SNS to notify the on-premises system to update the dashboard</label>
  <label for="optionB">B. Replace RDS with Redshift for the batch analysis and SQS to send a message to the on-premises system to update the dashboard</label>
  <label for="optionC" class="correct-answer">C. Create an RDS Read Replica for the batch analysis and SNS to notify the on-premises system to update the dashboard. ✓✓</label>
  <label for="optionD">D. Create an RDS Read Replica for the batch analysis and SQS to send a message to the on-premises system to update the dashboard.</label>
</form>
<form class="question-form">
  <h1 class="question">
    A bucket owner has allowed another account's IAM users to upload or access objects in his bucket. The IAM user of Account A is trying to access an object created by the IAM user of Account B.
  </h1>
  <p>What will happen in this scenario?</p>

  <label for="optionA">A. It is not possible to give permission to multiple IAM users</label>
  <label for="optionB" class="correct-answer">B. AWS S3 will verify proper rights given by the owner of Account A, the bucket owner as well as by the IAM user B to the object ✓✓</label>
  <label for="optionC">C. The bucket policy may not be created as S3 will give error due to conflict of Access Rights</label>
  <label for="optionD">D. It is not possible that the IAM user of one account accesses objects of the other IAM user</label>
</form>
<form class="question-form">
  <h1 class="question">
    Which of the following IAM policy elements lets you specify an exception to a list of actions?
  </h1>

  <label for="optionA">A. NotException</label>
  <label for="optionB">B. ExceptionAction</label>
  <label for="optionC">C. Exception</label>
  <label for="optionD" class="correct-answer">D. NotAction ✓✓</label>
</form>
<form class="question-form">
  <h1 class="question">
    A company wants to replace its call system with a solution built using AWS managed services.
    The company call center would like the solution to receive calls, create contact flows, and scale to handle growth projections. The call center would also like the solution to use deep learning capabilities to recognize the intent of the callers and handle basic tasks, reducing the need to speak an agent. The solution should also be able to query business applications and provide relevant information back to calls as requested.
    Which services should the Solution Architect use to build this solution? (Choose three.)
  </h1>

  <label for="optionA">A. Amazon Rekognition to identify who is calling.</label>
  <label for="optionB" class="correct-answer">B. Amazon Connect to create a cloud-based contact center. ✓✓</label>
  <label for="optionC">C. Amazon Alexa for Business to build conversational interface.</label>
  <label for="optionD" class="correct-answer">D. AWS Lambda to integrate with internal systems. ✓✓</label>
  <label for="optionE" class="correct-answer">E. Amazon Lex to recognize the intent of the caller. ✓✓</label>
  <label for="optionF">F. Amazon SQS to add incoming callers to a queue.</label>
</form>
<form class="question-form">
  <h1 class="question">
    You are setting up some EBS volumes for a customer who has requested a setup which includes a RAID (redundant array of inexpensive disks). AWS has some recommendations for RAID setups. Which RAID setup is not recommended for Amazon EBS?
  </h1>

  <label for="optionA">A. RAID 1 only</label>
  <label for="optionB">B. RAID 5 only</label>
  <label for="optionC" class="correct-answer">C. RAID 5 and RAID 6 ✓✓</label>
  <label for="optionD">D. RAID 0 only</label>
</form>
<form class="question-form">
  <h1 class="question">
    You have been given the task to define multiple AWS Data Pipeline schedules for different activities in the same pipeline. Which of the following would successfully accomplish this task?
  </h1>

  <label for="optionA">A. Creating multiple pipeline definition files</label>
  <label for="optionB">B. Defining multiple pipeline definitions in your schedule objects file and associating the desired schedule to the correct activity via its schedule field</label>
  <label for="optionC" class="correct-answer">C. Defining multiple schedule objects in your pipeline definition file and associating the desired schedule to the correct activity via its schedule field ✓✓</label>
  <label for="optionD">D. Defining multiple schedule objects in the schedule field</label>
</form>
<form class="question-form">
  <h1 class="question">
    A Solutions Architect is designing the storage layer for a recently purchased application. The application will be running on Amazon EC2 instances and has the following layers and requirements:
  </h1>
  <p>- Data layer: A POSIX file system shared across many systems.<br>
     - Service layer: Static file content that requires block storage with more than 100k IOPS.</p>

  <label for="optionA">A. Data layer - Amazon S3</label>
  <label for="optionB">B. Data layer - Amazon EC2 Ephemeral Storage</label>
  <label for="optionC" class="correct-answer">C. Data layer - Amazon EFS ✓✓</label>
  <label for="optionD" class="correct-answer">D. Service layer - Amazon EBS volumes with Provisioned IOPS ✓✓</label>
  <label for="optionE">E. Service layer - Amazon EC2 Ephemeral Storage</label>
</form>


<form class="question-form">
  <h1 class="question">
    If a single condition within an IAM policy includes multiple values for one key, it will be evaluated using a logical ______.
  </h1>

  <label for="optionA" class="correct-answer">A. OR ✓✓</label>
  <label for="optionB">B. NAND</label>
  <label for="optionC">C. NOR</label>
  <label for="optionD">D. AND</label>
</form>
<form class="question-form">
  <h1 class="question">
    A large global financial services company has multiple business units. The company wants to allow Developers to try new services, but there are multiple compliance requirements for different workloads. The Security team is concerned about the access strategy for on-premises and AWS implementations. They would like to enforce governance for AWS services used by business team for regulatory workloads, including Payment Card Industry (PCI) requirements.<br><br>
    Which solution will address the Security team's concerns and allow the Developers to try new services?
  </h1>

  <label for="optionA">A. Implement a strong identity and access management model that includes users, groups, and roles in various AWS accounts. Ensure that centralized AWS CloudTrail logging is enabled to detect anomalies. Build automation with AWS Lambda to tear down unapproved AWS resources for governance.</label>

  <label for="optionB" class="correct-answer">B. Build a multi-account strategy based on business units, environments, and specific regulatory requirements. Implement SAML-based federation across all AWS accounts with an on-premises identity store. Use AWS Organizations and build organizational units (OUs) structure based on regulations and service governance. Implement service control policies across OUs. ✓✓</label>

  <label for="optionC">C. Implement a multi-account strategy based on business units, environments, and specific regulatory requirements. Ensure that only PCI-compliant services are approved for use in the accounts. Build IAM policies to give access to only PCI-compliant services for governance.</label>

  <label for="optionD">D. Build one AWS account for the company for the strong security controls. Ensure that all the service limits are raised to meet company scalability requirements. Implement SAML federation with an on- premises identity store, and ensure that only approved services are used in the account.</label>
</form>
<form class="question-form">
  <h1 class="question">
    The Solutions Architect manages a serverless application that consists of multiple API gateways, AWS Lambda functions, Amazon S3 buckets, and Amazon DynamoDB tables. Customers say that a few application components slow while loading dynamic images, and some are timing out with the "504 Gateway Timeout" error. While troubleshooting the scenario, the Solutions Architect confirms that DynamoDB monitoring metrics are at acceptable levels.<br><br>
    Which of the following steps would be optimal for debugging these application issues? (Choose two.)
  </h1>

  <label for="optionA">A. Parse HTTP logs in Amazon API Gateway for HTTP errors to determine the root cause of the errors.</label>

  <label for="optionB" class="correct-answer">B. Parse Amazon CloudWatch Logs to determine processing times for requested images at specified intervals. ✓</label>

  <label for="optionC">C. Parse VPC Flow Logs to determine if there is packet loss between the Lambda function and S3.</label>

  <label for="optionD" class="correct-answer">D. Parse AWS X-Ray traces and analyze HTTP methods to determine the root cause of the HTTP errors. ✓</label>

  <label for="optionE">E. Parse S3 access logs to determine if objects being accessed are from specific IP addresses to narrow the scope to geographic latency issues.</label>
</form>
<form class="question-form">
  <h1 class="question">
    Can a user configure a custom health check with Auto Scaling?
  </h1>

  <label for="optionA">A. Yes, but the configured data will not be saved to Auto Scaling.</label>

  <label for="optionB">B. No, only an ELB health check can be configured with Auto Scaling.</label>

  <label for="optionC" class="correct-answer">C. Yes ✓</label>

  <label for="optionD">D. No</label>
</form>
<form class="question-form">
  <h1 class="question">
    A Solutions Architect has created an AWS CloudFormation template for a three-tier application that contains an Auto Scaling group of Amazon EC2 instances running a custom AMI.<br><br>
    The Solutions Architect wants to ensure that future updates to the custom AMI can be deployed to a running stack by first updating the template to refer to the new AMI, and then invoking UpdateStack to replace the EC2 instances with instances launched from the new AMI.<br><br>
    How can updates to the AMI be deployed to meet these requirements?
  </h1>

  <label for="optionA" class="correct-answer">A. Create a change set for a new version of the template, view the changes to the running EC2 instances to ensure that the AMI is correctly updated, and then execute the change set. ✓</label>

  <label for="optionB">B. Edit the AWS::AutoScaling::LaunchConfiguration resource in the template, changing its DeletionPolicy to Replace.</label>

  <label for="optionC">C. Edit the AWS::AutoScaling::LaunchConfiguration resource in the template, inserting an UpdatePolicy attribute.</label>

  <label for="optionD">D. Create a new stack from the updated template. Once it is successfully deployed, modify the DNS records to point to the new stack and delete the old stack.</label>
</form>
<form class="question-form">
  <h1 class="question">
    A web company is looking to implement an intrusion detection and prevention system into their deployed VPC. This platform should have the ability to scale to thousands of instances running inside of the VPC.<br><br>
    How should they architect their solution to achieve these goals?
  </h1>

  <label for="optionA">A. Configure servers running in the VPC using the host-based "route" commands to send all traffic through the platform to a scalable virtualized IDS/IPS.</label>

  <label for="optionB">B. Create a second VPC and route all traffic from the primary application VPC through the second VPC where the scalable virtualized IDS/IPS platform resides.</label>

  <label for="optionC">C. Configure an instance with monitoring software and the elastic network interface (ENI) set to promiscuous mode packet sniffing to see all traffic across the VPC.</label>

  <label for="optionD" class="correct-answer">✔ D. Configure each host with an agent that collects all network traffic and sends that traffic to the IDS/IPS platform for inspection.</label>
</form>
<form class="question-form">
  <h1 class="question">
    Out of the striping options available for the EBS volumes, which one has the following disadvantage:<br><br>
    "Doubles the amount of I/O required from the instance to EBS compared to RAID 0, because you're mirroring all writes to a pair of volumes, limiting how much you can stripe."
  </h1>

  <label for="optionA" class="correct-answer">✔ A. RAID 1</label>

  <label for="optionB">B. RAID 0</label>

  <label for="optionC">C. RAID 1+0 (RAID 10)</label>

  <label for="optionD">D. RAID 2</label>
</form>
<form class="question-form">
  <h1 class="question">
    You want to mount an Amazon EFS file system on an Amazon EC2 instance using DNS names.<br><br>
    Which of the following generic form of a mount target's DNS name must you use to mount the file system?
  </h1>

  <label for="optionA" class="correct-answer">✔ A. availability-zone.file-system-id.efs.aws-region.amazonaws.com</label>

  <label for="optionB">B. efs-system-id.availability-zone.file-aws-region.amazonaws.com</label>

  <label for="optionC">C. $file-system-id.$availability-zone.$efs.aws-region.$amazonaws.com</label>

  <label for="optionD">D. #aws-region.#availability-zone.#file-system-id.#efs.#amazonaws.com</label>
</form>
<form class="question-form">
  <h1 class="question">
    The AWS IT infrastructure that AWS provides, complies with the following IT security standards, including:
  </h1>

  <label for="optionA" class="correct-answer">✔ A. All of the above</label>

  <label for="optionB">B. FISMA, DIACAP, and FedRAMP</label>

  <label for="optionC">C. HIPAA, Cloud Security Alliance (CSA) and Motion Picture Association of America (MPAA)</label>

  <label for="optionD">D. PCI DSS Level 1, ISO 27001, ITAR and FIPS 140-2</label>

  <label for="optionE">E. SOC 1/SSAE 16/ISAE 3402 (formerly SAS 70 Type II), SOC 2 and SOC 3</label>
</form>
<form class="question-form">
  <h1 class="question">
    You are designing a social media site and are considering how to mitigate distributed denial-of-service (DDoS) attacks.<br>
    Which of the below are viable mitigation techniques? <strong>Choose 3 answers</strong>
  </h1>

  <label for="optionA">A. Add multiple elastic network Interfaces (ENIs) to each EC2 instance to increase the network bandwidth.</label>

  <label for="optionB" class="correct-answer">✔ B. Create processes and capabilities to quickly add and remove rules to the instance OS firewall.</label>

  <label for="optionC">C. Use Dedicated Instances to ensure that each instance has the maximum performance possible.</label>

  <label for="optionD" class="correct-answer">✔ D. Use an Amazon CloudFront distribution for both static and dynamic content.</label>

  <label for="optionE">E. Add alerts to Amazon CloudWatch to look for high Network In and CPU utilization.</label>

  <label for="optionF" class="correct-answer">✔ F. Use an Elastic Load Balancer with auto scaling groups at the web, app, and Amazon Relational Database Service (RDS) tiers.</label>
</form>
<form class="question-form">
  <h1 class="question">
    What is the maximum length for an instance profile name in AWS IAM?
  </h1>

  <label for="optionA">A. 512 characters</label>
  <label for="optionB" class="correct-answer">B. 128 characters ✓✓</label>
  <label for="optionC">C. 1024 characters</label>
  <label for="optionD">D. 64 characters</label>
</form>
<form class="question-form">
  <h1 class="question">
    In Amazon RDS for PostgreSQL, you can provision up to 3TB storage and 30,000 IOPS per database instance. For a workload with 50% writes and 50% reads running on a cr1.8xlarge instance, you can realize over 25,000 IOPS for PostgreSQL. However, by provisioning more than this limit, you may be able to achieve:
  </h1>

  <label for="optionA">A. higher latency and lower throughput.</label>
  <label for="optionB" class="correct-answer">B. lower latency and higher throughput ✓✓</label>
  <label for="optionC">C. higher throughput only.</label>
  <label for="optionD">D. higher latency only.</label>
</form>
<form class="question-form">
  <h1 class="question">
    A user is accessing an EC2 instance on the SSH port for IP 10.20.30.40/32. Which one is a secure way to configure that the instance can be accessed only from this IP?
  </h1>

  <label for="optionA">A. In the security group, open port 22 for IP 10.20.30.40</label>
  <label for="optionB">B. In the security group, open port 22 for IP 10.20.30.0</label>
  <label for="optionC" class="correct-answer">C. In the security group, open port 22 for IP 10.20.30.40/32 ✓✓</label>
  <label for="optionD">D. In the security group, open port 22 for IP 10.20.30.40/0</label>
</form>
<form class="question-form">
  <h1 class="question">
    How is AWS readily distinguished from other vendors in the traditional IT computing landscape?
  </h1>

  <label for="optionA" class="correct-answer">A. Secure. Flexible. Cost-effective. Scalable and elastic. Experienced ✓✓</label>
  <label for="optionB">B. Secure.elastic. Experienced</label>
  <label for="optionC">C. Experienced. Scalable and elastic. Secure. Cost-effective. Reliable</label>
  <label for="optionD">D. Flexible. Cost-effective. Dynamic. Secure. Experienced.</label>
</form>
<form class="question-form">
  <h1 class="question">
    Regarding Amazon SNS, you can send notification messages to mobile devices through any of the following supported push notification services, EXCEPT:
  </h1>

  <label for="optionA" class="correct-answer">A. Microsoft Windows Mobile Messaging (MWMM) ✓✓</label>
  <label for="optionB">B. Google Cloud Messaging for Android (GCM)</label>
  <label for="optionC">C. Amazon Device Messaging (ADM)</label>
  <label for="optionD">D. Apple Push Notification Service (APNS)</label>
</form>
<form class="question-form">
  <h1 class="question">
    Identify a true statement about using an IAM role to grant permissions to applications running on Amazon EC2 instances.
  </h1>

  <label for="optionA">A. When AWS credentials are rotated, developers have to update only the root Amazon EC2 instance that uses their credentials.</label>
  <label for="optionB">B. When AWS credentials are rotated, developers have to update only the Amazon EC2 instance on which the password policy was applied and which uses their credentials.</label>
  <label for="optionC" class="correct-answer">C. When AWS credentials are rotated, you don't have to manage credentials and you don't have to worry about long-term security risks. ✓✓</label>
  <label for="optionD">D. When AWS credentials are rotated, you must manage credentials and you should consider precautions for long-term security risks.</label>
</form>
<form class="question-form">
  <h1 class="question">
    In the context of AWS Cloud Hardware Security Module (HSM), does your application need to reside in the same VPC as the CloudHSM instance?
  </h1>

  <label for="optionA" class="correct-answer">
    A. No, but the server or instance on which your application and the HSM client is running must have network (IP) reachability to the HSM. ✓✓
  </label>
  <label for="optionB">B. Yes, always</label>
  <label for="optionC">C. No, but they must reside in the same Availability Zone.</label>
  <label for="optionD">D. No, but it should reside in same Availability Zone as the DB instance.</label>
</form>
<form class="question-form">
  <h1 class="question">
    You are the new IT architect in a company that operates a mobile sleep tracking application. <br><br>
    When activated at night, the mobile app is sending collected data points of 1 kilobyte every 5 minutes to your backend. <br><br>
    The backend takes care of authenticating the user and writing the data points into an Amazon DynamoDB table. <br><br>
    Every morning, you scan the table to extract and aggregate last night's data on a per user basis, and store the results in Amazon S3. Users are notified via Amazon SNS mobile push notifications that new data is available, which is parsed and visualized by the mobile app. Currently you have around 100k users who are mostly based out of North America. <br><br>
    You have been tasked to optimize the architecture of the backend system to lower cost. <br><br>
    What would you recommend? <strong>Choose 2 answers</strong>
  </h1>

  <label for="optionA">A. Have the mobile app access Amazon DynamoDB directly Instead of JSON files stored on Amazon S3.</label>
  <label for="optionB">B. Write data directly into an Amazon Redshift cluster replacing both Amazon DynamoDB and Amazon S3.</label>
  <label for="optionC" class="correct-answer">
    C. Introduce an Amazon SQS queue to buffer writes to the Amazon DynamoDB table and reduce provisioned write throughput. ✓✓
  </label>
  <label for="optionD" class="correct-answer">
    D. Introduce Amazon ElastiCache to cache reads from the Amazon DynamoDB table and reduce provisioned read throughput. ✓✓
  </label>
  <label for="optionE">E. Create a new Amazon DynamoDB table each day and drop the one for the previous day after its data is on Amazon S3.</label>
</form>
<form class="question-form">
  <h1 class="question">
    A company is migrating an application to AWS. It wants to use fully managed services as much as possible during the migration. The company needs to store large, important documents within the application with the following requirements: <br><br>
    - The data must be highly durable and available.<br>
    - The data must always be encrypted at rest and in transit.<br>
    - The encryption key must be managed by the company and rotated periodically.<br><br>
    Which of the following solutions should the Solutions Architect recommend?
  </h1>

  <label for="optionA">A. Deploy the storage gateway to AWS in file gateway mode. Use Amazon EBS volume encryption using an AWS KMS key to encrypt the storage gateway volumes.</label>

  <label for="optionB" class="correct-answer">
    B. Use Amazon S3 with a bucket policy to enforce HTTPS for connections to the bucket and to enforce server-side encryption and AWS KMS for object encryption. ✓✓
  </label>

  <label for="optionC">C. Use Amazon DynamoDB with SSL to connect to DynamoDB. Use an AWS KMS key to encrypt DynamoDB objects at rest.</label>

  <label for="optionD">D. Deploy instances with Amazon EBS volumes attached to store this data. Use EBS volume encryption using an AWS KMS key to encrypt the data.</label>
</form>
<form class="question-form">
  <h1 class="question">
    When using Numeric Conditions within IAM, short versions of the available comparators can be used instead of the more verbose versions. Which of the following is the short version of the Numeric Condition "<strong>NumericLessThanEquals</strong>"?
  </h1>

  <label for="optionA">A. nvvumlteq</label>

  <label for="optionB">B. xxnumlteql</label>

  <label for="optionC" class="correct-answer">
    C. numlteq ✓✓
  </label>
  <form class="question-form">
  <h1 class="question">
    Your company is storing millions of sensitive transactions across thousands of 100-GB files that must be encrypted in transit and at rest. Analysts concurrently depend on subsets of files, which can consume up to 5 TB of space, to generate simulations that can be used to steer business decisions. You are required to design an AWS solution that can cost effectively accommodate the long-term storage and in-flight subsets of data.
  </h1>

  <label for="optionA">A. Use HDFS on Amazon EMR, and run simulations on subsets in ephemeral drives on Amazon EC2.</label>

  <label for="optionB">B. Use HDFS on Amazon Elastic MapReduce (EMR), and run simulations on subsets in-memory on Amazon Elastic Compute Cloud (EC2).</label>

  <label for="optionC" class="correct-answer">
    C.Use Amazon Simple Storage Service (S3) with server-side encryption, and run simulations on subsets in ephemeral drives on Amazon EC2. ✓✓
  </label>

  <label for="optionD">D. Use Amazon DynamoDB on Amazon EC2.</label>

  <label for="optionE">E. Store the full data set in encrypted Amazon Elastic Block Store (EBS) volumes, and regularly capture snapshots that can be cloned to EC2 workstations.</label>
</form>
<form class="question-form">
  <h1 class="question">
    You are designing the network infrastructure for an application server in Amazon VPC. Users will access all the application instances from the Internet, as well as from an on-premises network.
    The on-premises network is connected to your VPC over an AWS Direct Connect link.
    How would you design routing to meet the above requirements?
  </h1>

  <label for="optionA">A. Configure a single routing table with two default routes: one to the Internet via an Internet gateway, the other to the on-premises network via the VPN gateway. Use this routing table across all subnets in your VPC.</label>

  <label for="optionB" class="correct-answer">
    B. Configure a single routing table with a default route via the Internet gateway.
    Propagate specific routes for the on-premises networks via BGP on the AWS Direct Connect customer router.
    Associate the routing table with all VPC subnets. ✓✓
  </label>

  <label for="optionC">C. Configure two routing tables: one that has a default route via the Internet gateway, and another that has a default route via the VPN gateway. Associate both routing tables with each VPC subnet.</label>

  <label for="optionD">D. Configure a single routing table with a default route via the Internet gateway. Propagate a default route via BGP on the AWS Direct Connect customer router. Associate the routing table with all VPC subnets.</label>
</form>
<form class="question-form">
  <h1 class="question">
    True or False: In Amazon ElastiCache replication groups of Redis, for performance tuning reasons, you can change the roles of the cache nodes within the replication group, with the primary and one of the replicas exchanging roles.
  </h1>

  <label for="optionA">A. True, however, you get lower performance.</label>

  <label for="optionB">B. FALSE</label>

  <label for="optionC" class="correct-answer">
    C. TRUE ✓✓
  </label>

  <label for="optionD">D. False, you must recreate the replication group to improve performance tuning.</label>
</form>
<form class="question-form">
  <h1 class="question">
    Which of the following is not included in the metrics sent from Billing to Amazon CloudWatch?
  </h1>

  <label for="optionA">A. Recurring fees for AWS products and services</label>

  <label for="optionB">B. Total AWS charges</label>

  <label for="optionC" class="correct-answer">
    C. One-time charges and refunds ✓✓
  </label>

  <label for="optionD">D. Usage charges for AWS products and services</label>
</form>
<form class="question-form">
  <h1 class="question">
    Once the user has set ElastiCache for an application and it is up and running, which services does Amazon <u>not</u> provide for the user:
  </h1>

  <label for="optionA">A. The ability for client programs to automatically identify all of the nodes in a cache cluster, and to initiate and maintain connections to all of these nodes</label>

  <label for="optionB">B. Automating common administrative tasks such as failure detection and recovery, and software patching</label>

  <label for="optionC" class="correct-answer">
    C. Providing default Time To Live (TTL) in the AWS ElastiCache Redis implementation for different types of data ✓✓
  </label>

  <label for="optionD">D. Providing detailed monitoring metrics associated with your Cache Nodes, enabling you to diagnose and react to issues very quickly</label>
</form>
<form class="question-form">
  <h1 class="question">
    A company has released a new version of a website to target an audience in Asia and South America. The website's media assets are hosted on Amazon S3 and have an Amazon CloudFront distribution to improve end-user performance. However, users are having a poor login experience because the authentication service is only available in the us-east-1 AWS Region.<br><br>
    <strong>How can the Solutions Architect improve the login experience and maintain high security and performance with minimal management overhead?</strong>
  </h1>

  <label for="optionA">
    A. Replicate the setup in each new geography and use Amazon Route 53 geo-based routing to route traffic to the AWS Region closest to the users.
  </label>

  <label for="optionB">
    B. Use an Amazon Route 53 weighted routing policy to route traffic to the CloudFront distribution. Use CloudFront cached HTTP methods to improve the user login experience.
  </label>

  <label for="optionC" class="correct-answer">
    C. Use Amazon Lambda@Edge attached to the CloudFront viewer request trigger to authenticate and authorize users by maintaining a secure cookie token with a session expiry to improve the user experience in multiple geographies. ✓✓
  </label>

  <label for="optionD">
    D. Replicate the setup in each geography and use Network Load Balancers to route traffic to the authentication service running in the closest region to users.
  </label>
</form>
<form class="question-form">
  <h1 class="question">
    A Solutions Architect is responsible for redesigning a legacy Java application to improve its availability, data durability, and scalability. Currently, the application runs on a single high-memory Amazon EC2 instance. It accepts HTTP requests from upstream clients, adds them to an in-memory queue, and responds with a 200 status. A separate application thread reads items from the queue, processes them, and persists the results to an Amazon RDS MySQL instance.<br><br>

    The processing time for each item takes 90 seconds on average, most of which is spent waiting on external service calls, but the application is written to process multiple items in parallel.<br><br>

    Traffic to this service is unpredictable. During periods of high load, items may sit in the internal queue for over an hour while the application processes the backlog. In addition, the current system has issues with availability and data loss if the single application node fails.<br><br>

    Clients that access this service cannot be modified. They expect to receive a response to each HTTP request they send within 10 seconds before they will time out and retry the request.<br><br>

    <strong>Which approach would improve the availability and durability of the system while decreasing the processing latency and minimizing costs?</strong>
  </h1>

  <label for="optionA">
    A. Update the application to use a Redis task queue instead of the in-memory queue. Build a Docker container image for the application. Create an Amazon ECS task definition that includes the application container and a separate container to host Redis. Deploy the new task definition as an ECS service using AWS Fargate and enable Auto Scaling.
  </label>

  <label for="optionB">
    B. Modify the application to use Amazon DynamoDB instead of Amazon RDS. Configure Auto Scaling for the DynamoDB table. Deploy the application within an Auto Scaling group with a scaling policy based on CPU utilization. Back the in-memory queue with a memory-mapped file to an instance store volume and periodically write that file to Amazon S3.
  </label>

  <label for="optionC" class="correct-answer">
    C. Create an Amazon API Gateway REST API that uses a service proxy to put items in an Amazon SQS queue. Extract the core processing code from the existing application and update it to pull items from Amazon SQS instead of an in-memory queue. Deploy the new processing application to smaller EC2 instances within an Auto Scaling group that scales dynamically based on the approximate number of messages in the Amazon SQS queue. ✓✓
  </label>

  <label for="optionD">
    D. Create an Amazon API Gateway REST API that uses Lambda proxy integration to pass requests to an AWS Lambda function. Migrate the core processing code to a Lambda function and write a wrapper class that provides a handler method that converts the proxy events to the internal application data model and invokes the processing module.
  </label>
</form>
<form class="question-form">
  <h1 class="question">
    When using string conditions within IAM, short versions of the available comparators can be used instead of the more verbose ones.<br><br>

    <strong>streqi is the short version of the _____ string condition.</strong>
  </h1>

  <label for="optionA" class="correct-answer">
    A. StringEqualsIgnoreCase ✓✓
  </label>

  <label for="optionB">
    B. StringNotEqualsIgnoreCase
  </label>

  <label for="optionC">
    C. StringLikeStringEquals
  </label>

  <label for="optionD">
    D. StringNotEquals
  </label>
</form>
<form class="question-form">
  <h1 class="question">
    A large company experienced a drastic increase in its monthly AWS spend. This is after Developers accidentally launched Amazon EC2 instances in unexpected regions. The company has established practices around least privileges for Developers and controls access to on-premises resources using Active Directory groups. The company now wants to control costs by restricting the level of access that Developers have to the AWS Management Console without impacting their productivity. The company would also like to allow Developers to launch Amazon EC2 in only one region, without limiting access to other services in any region.<br><br>
    
    <strong>How can this company achieve these new security requirements while minimizing the administrative burden on the Operations team?</strong>
  </h1>

  <label for="optionA">
    A. Set up SAML-based authentication tied to an IAM role that has an AdministrativeAccess managed policy attached to it. Attach a customer managed policy that denies access to Amazon EC2 in each region except for the one required.
  </label>

  <label for="optionB">
    B. Create an IAM user for each Developer and add them to the developer IAM group that has the PowerUserAccess managed policy attached to it. Attach a customer managed policy that allows the Developers access to Amazon EC2 only in the required region.
  </label>

  <label for="optionC">
    C. Set up SAML-based authentication tied to an IAM role that has a PowerUserAccess managed policy and a customer managed policy that deny all the Developers access to any AWS services except AWS Service Catalog. Within AWS Service Catalog, create a product containing only the EC2 resources in the approved region.
  </label>

  <label for="optionD" class="correct-answer">
    D. Set up SAML-based authentication tied to an IAM role that has the PowerUserAccess managed policy attached to it. Attach a customer managed policy that denies access to Amazon EC2 in each region except for the one required. ✓✓
  </label>
</form>
<form class="question-form">
  <h1 class="question">
    Dave is the main administrator in Example Corp., and he decides to use paths to help delineate the users in the company and set up a separate administrator group for each path-based division. Following is a subset of the full list of paths he plans to use:<br><br>
    • /marketing<br>
    • /sales<br>
    • /legal<br><br>
    
    Dave creates an administrator group for the marketing part of the company and calls it <strong>Marketing_Admin</strong>. He assigns it the <code>/marketing</code> path. The group's ARN is <code>arn:aws:iam::123456789012:group/marketing/Marketing_Admin</code>.<br><br>
    
    Dave assigns the following policy to the <strong>Marketing_Admin</strong> group that gives the group permission to use all IAM actions with all groups and users in the <code>/marketing</code> path. The policy also gives the <strong>Marketing_Admin</strong> group permission to perform any AWS S3 actions on the objects in the portion of the corporate bucket.<br><br>
    
    <pre>{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Deny",
      "Action": "iam:*",
      "Resource": [
        "arn:aws:iam::123456789012:group/marketing/*",
        "arn:aws:iam::123456789012:user/marketing/*"
      ]
    },
    {
      "Effect": "Allow",
      "Action": "s3:*",
      "Resource": "arn:aws:s3:::example_bucket/marketing/*"
    },
    {
      "Effect": "Allow",
      "Action": "s3:ListBucket*",
      "Resource": "arn:aws:s3:::example_bucket",
      "Condition": {
        "StringLike": {
          "s3:prefix": "marketing/*"
        }
      }
    }
  ]
}</pre>
    
    <strong>Does this policy allow the Marketing_Admin group to manage IAM users and groups in the /marketing path?</strong>
  </h1>

  <label for="optionA" class="correct-answer">
    A. False ✓✓
  </label>

  <label for="optionB">
    B. True
  </label>
</form>


  <label for="optionD">D. numeql</label>
</form>




 <form class="question-form">
  <h1 class="question">
    A company wants to migrate its content sharing web application hosted on Amazon EC2 to a serverless architecture.
  </h1>
  <p>Which solution will meet these requirements?</p>

  <label for="optionA">A. Use AWS CDK to define infrastructure. Use EC2 Image Builder to create AMIs for deployment.</label>
  <label for="optionB" class="correct-answer">B. Use AWS CloudFormation to deploy Amazon S3, Amazon API Gateway, AWS Lambda, and Amazon DynamoDB. ✓✓</label>
  <label for="optionC">C. Use AWS Elastic Beanstalk to deploy a Docker-based application.</label>
  <label for="optionD">D. Use AWS OpsWorks with custom Chef recipes to deploy the application and supporting resources.</label>
</form>

<form class="question-form">
  <h1 class="question">
    A company's application is currently deployed to a single AWS Region. The company wants to improve the application's availability by using multiple Regions.
  </h1>
  <p>Which combination of steps should a solutions architect take to migrate to a multi-Region architecture? (Choose three.)</p>

  <label for="optionA">A. Create a new DynamoDB table and configure synchronous replication between the tables.</label>
  <label for="optionB">B. Create new ALB and Auto Scaling group global resources in a backup Region.</label>
  <label for="optionC" class="correct-answer">C. Create new ALB and Auto Scaling group resources in the second Region. ✓✓</label>
  <label for="optionD" class="correct-answer">D. Create Amazon Route 53 records with a failover routing policy. ✓✓</label>
  <label for="optionE">E. Create Amazon Route 53 aliases for both Regions using a latency-based routing policy.</label>
  <label for="optionF" class="correct-answer">F. Convert the DynamoDB table to a global table. ✓✓</label>
</form>




   <form class="question-form">
  <h1 class="question">
    A DevOps engineer used an AWS CloudFormation custom resource...
  </h1>
  <p>Which action should the engineer take to ensure CloudFormation receives a successful response?</p>

  <label for="optionA">A. Ensure the Lambda function code has exited successfully.</label>
  <label for="optionB" class="correct-answer">B. Ensure the Lambda function code returns a response to the pre-signed URL. ✓✓</label>
  <label for="optionC">C. Ensure the Lambda function IAM role has cloudformation:UpdateStack...</label>
  <label for="optionD">D. Ensure the Lambda function IAM role has ds:ConnectDirectory...</label>
</form>

<form class="question-form">
  <h1 class="question">
    A company plans to stop using Amazon EC2 key pairs for SSH access...
  </h1>
  <p>Which combination of steps will allow secure and auditable access to the instances? (Choose two.)</p>

  <label for="optionA">A. Allow inbound access to TCP port 22...</label>
  <label for="optionB" class="correct-answer">B. Attach an IAM policy... ✓✓</label>
  <label for="optionC" class="correct-answer">C. Create a VPC endpoint for Systems Manager... ✓✓</label>
  <label for="optionD">D. Deploy a new EC2 instance...</label>
  <label for="optionE">E. Remove any default routes...</label>
</form>

<form class="question-form">
  <h1 class="question">
    A company runs an application with an Amazon EC2 and on-premises configuration...
  </h1>
  <p>Which combination of actions should the company take to enable patching of all servers? (Choose three.)</p>

  <label for="optionA" class="correct-answer">A. Add the physical machines... ✓✓</label>
  <label for="optionB" class="correct-answer">B. Attach an IAM role to the EC2 instances... ✓✓</label>
  <label for="optionC">C. Create IAM access keys...</label>
  <label for="optionD">D. Execute an AWS Systems Manager Automation document...</label>
  <label for="optionE">E. Use Amazon CloudWatch Events scheduled events...</label>
  <label for="optionF" class="correct-answer">F. Use AWS Systems Manager Maintenance Windows... ✓✓</label>
</form>

<form class="question-form">
  <h1 class="question">
    Which one of the following components should not influence an organization’s security policy?
  </h1>
  <p>Select the option that is least likely to shape a security policy.</p>

  <label for="optionA">A. Business objectives</label>
  <label for="optionB">B. Regulatory requirements</label>
  <label for="optionC">C. Risk</label>
  <label for="optionD">D. Cost–benefit analysis</label>
  <label for="optionE" class="correct-answer">E. Current firewall limitations ✓✓</label>
</form>


    <form class="question-form">
  <h1 class="question">
    A Solutions Architect is working with a company that is extremely sensitive to its IT costs and wishes to implement controls that will result in a predictable AWS spend each month.
  </h1>
  <p>Which combination of steps can help the company control and monitor its monthly AWS usage to achieve a cost that is as close as possible to the target amount? (Choose three.)</p>
  
  <label for="optionA">A. Implement an IAM policy that requires users to specify a 'workload' tag for cost allocation when launching Amazon EC2 instances.</label>
  <label for="optionB">B. Contact AWS Support and ask that they apply limits to the account so that users are not able to launch more than a certain number of instance types.</label>
  <label for="optionC" class="correct-answer">C. Purchase all upfront Reserved Instances that cover 100% of the account's expected Amazon EC2 usage. ✓✓</label>
  <label for="optionD">D. Place conditions in the users' IAM policies that limit the number of instances they are able to launch.</label>
  <label for="optionE" class="correct-answer">E. Define 'workload' as a cost allocation tag in the AWS Billing and Cost Management console. ✓✓</label>
  <label for="optionF" class="correct-answer">F. Set up AWS Budgets to alert and notify when a given workload is expected to exceed a defined cost. ✓✓</label>
</form>

    <!-- THIS IS A QUESTION WITHOUT THE WRAPPER, WHICH WILL NOW BE HANDLED -->
    <form class="question-form">
      <h1 class="question">Consider the following statements about the AAA architecture:</h1>
      <p>I. Authentication deals with the question “Who is the user?”</p>
      <p>II. Authorization addresses the question “What is the user allowed to do?”</p>
      <p>III. Accountability answers the question “What did the user do?”</p>
      <h1 class="question">Which of the following is correct?</h1>
      <label for="optionA">A. Only I is correct.</label>
      <label for="optionB">B. Only II is correct.</label>
      <label for="optionC">C. I, II, and III are correct.</label>
      <label for="optionD" class="correct-answer">D. I and II are correct. ✓✓</label>
      <label for="optionE">E. II and III are correct.</label>
    </form>


    <form class="question-form">
      <h1 class="question">Consider the following statements about the AAA architecture:</h1>
      <p>I. Authentication deals with the question “Who is the user?”</p>
      <p>II. Authorization addresses the question “What is the user allowed to do?”</p>
      <p>III. Accountability answers the question “What did the user do?”</p>
      <h1 class="question">Which of the following is correct?</h1>
      <label for="optionA">A. Only I is correct.</label>
      <label for="optionB">B. Only II is correct.</label>
      <label for="optionC">C. I, II, and III are correct.</label>
      <label for="optionD" class="correct-answer">D. I and II are correct. &#x2713;&#x2713;</label>
      <label for="optionE">E. II and III are correct.</label>
    </form>
    <form class="question-form">
      <h1 class="question">What is the difference between denial-of-service (DoS) and distributed denial-of-service
        (DDoS) attacks?</h1>
      <label for="optionA">A. DDoS attacks have many targets, whereas DoS attacks have only one each.</label>
      <label for="optionB">B. DDoS attacks target multiple networks, whereas DoS attacks target a single
        network.</label>
      <label for="optionC" class="correct-answer">C. DDoS attacks have many sources, whereas DoS attacks have only one
        each. &#x2713;&#x2713;</label>
      <label for="optionD">D. DDoS attacks target multiple layers of the OSI model and DoS attacks only one.</label>
      <label for="optionE">E. DDoS attacks are synonymous with DoS attacks</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following options is incorrect?</h1>
      <label for="optionA">A. A firewall is a security system aimed at isolating specific areas of the network and delimiting domains of trust.</label>
      <label for="optionB">B. Generally speaking, the web application firewall (WAF) is a specialized security element that acts as a full-reverse proxy, protecting applications that are accessed through HTTP.</label>
      <label for="optionC" class="correct-answer">C. Whereas intrusion prevention system (IPS) devices handle only copies of the packets and are mainly concerned with monitoring and alerting tasks, intrusion detection system (IDS) solutions are deployed inline in the traffic flow and have the inherent design goal of avoiding actual damage to systems. &#x2713;&#x2713;</label>
      <label for="optionD">D. Security information and event management (SIEM) solutions are designed to collect security-related logs as well as flow information generated by systems (at the host or the application level), networking devices, and dedicated defense elements such as firewalls, IPSs, IDSs, and antivirus software.</label>
    </form>



    <form class="question-form">
      <h1 class="question">In the standard shared responsibility model, AWS is responsible for which of the following options?</h1>
      <label for="optionA">A. Regions, availability zones, and data encryption</label>
      <label for="optionB">B. Hardware, firewall configuration, and hypervisor software</label>
      <label for="optionC" class="correct-answer">C. Hypervisor software, regions, and availability zones &#x2713;&#x2713;</label>
      <label for="optionD">D. Network traffic protection and identity and access management</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which AWS service allows you to generate compliance reports that enable you to evaluate the AWS security controls and posture?</h1>
      <label for="optionA">A. AWS Trusted Advisor</label>
      <label for="optionB">B. AWS Well-Architected Tool</label>
      <label for="optionC" class="correct-answer">C. AWS Artifact &#x2713;&#x2713;</label>
      <label for="optionD">D. Amazon Inspector</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following contains a definition that is not a pillar from the AWS Well-Architected Framework?</h1>
      <label for="optionA">A. Security and operational excellence</label>
      <label for="optionB">B. Reliability and performance efficiency</label>
      <label for="optionC" class="correct-answer">C. Cost optimization and availability &#x2713;&#x2713;</label>
      <label for="optionD">D. Security and performance efficiency</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following services provides a set of APIs that control access to your resources on the AWS Cloud?</h1>
      <label for="optionA">A. AWS AAA</label>
      <label for="optionB" class="correct-answer">B. AWS IAM &#x2713;&#x2713;</label>
      <label for="optionC">C. AWS Authenticator</label>
      <label for="optionD">D. AWS AD</label>
    </form>
    <form class="question-form">
      <h1 class="question">Regarding AWS IAM principals, which option is not correct?</h1>
      <label for="optionA">A. A principal is an IAM entity that has permission to interact with resources in the AWS Cloud.</label>
      <label for="optionB" class="correct-answer">B. They can only be permanent. &#x2713;&#x2713;</label>
      <label for="optionC">C. They can represent a human user, a resource, or an application.</label>
      <label for="optionD">D. They have three types: root users, IAM users, and roles.</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following is not a recommendation for protecting your root user credentials?</h1>
      <label for="optionA">A. Use a strong password to help protect account-level access to the management console.</label>
      <label for="optionB">B. Enable MFA on your AWS root user account.</label>
      <label for="optionC">C. Do not create an access key for programmatic access to your root user account unless such a procedure is mandatory.</label>
      <label for="optionD" class="correct-answer">D. If you must maintain an access key to your root user account, you should never rotate it using the AWS Console. &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">In AWS Config, which option is not correct?</h1>
      <label for="optionA">A. The main goal of AWS Config is to record configuration and the changes of the resources.</label>
      <label for="optionB">B. AWS Config Rules can decide if a change is good or bad and if it needs to execute an action.</label>
      <label for="optionC" class="correct-answer">C. AWS Config cannot integrate with external resources like on-premises servers and applications. &#x2713;&#x2713;</label>
      <label for="optionD">D. AWS Config can provide configuration history files, configuration snapshots, and configuration streams.</label>
    </form>
    <form class="question-form">
      <h1 class="question">AWS CloudTrail is the service in charge of keeping records of API calls to the AWS Cloud. Which option is not a type of AWS CloudTrail event?</h1>
      <label for="optionA">A. Management</label>
      <label for="optionB">B. Insights</label>
      <label for="optionC">C. Data</label>
      <label for="optionD" class="correct-answer">D. Control &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">In Amazon VPCs, which of the following is not correct?</h1>
      <label for="optionA">A. VPC is the acronym of Virtual Private Cloud.</label>
      <label for="optionB">B. VPCs do not extend beyond an AWS region.</label>
      <label for="optionC" class="correct-answer">C. You can deploy only private IP addresses from RFC 1918 within VPCs. &#x2713;&#x2713;</label>
      <label for="optionD">D. You can configure your VPC to not share hardware with other AWS accounts.</label>
    </form>
    <form class="question-form">
      <h1 class="question">In NAT gateways, which option is not correct?</h1>
      <label for="optionA">A. NAT gateways are always positioned in public subnets.</label>
      <label for="optionB">B. Route table configuration is usually required to direct traffic to these devices.</label>
      <label for="optionC" class="correct-answer">C. NAT gateways are highly available by default. &#x2713;&#x2713;</label>
      <label for="optionD">D. Amazon CloudWatch automatically monitors traffic flowing through NAT gateways</label>
    </form>
    <form class="question-form">
      <h1 class="question">In security groups, which option is not correct?</h1>
      <label for="optionA">A. Security groups only have allow (permit) rules.</label>
      <label for="optionB">B. The default security group allows all inbound communications from resources that are associated to the same security group.</label>
      <label for="optionC" class="correct-answer">C. You cannot have more than one security group associated to an instance’s ENI. &#x2713;&#x2713;</label>
      <label for="optionD">D. The default security group allows all outbound communications to any destination.</label>
    </form>
    <form class="question-form">
      <h1 class="question">In network ACLs, which option is not correct?</h1>
      <label for="optionA">A. They can be considered an additional layer of traffic filtering to security groups.</label>
      <label for="optionB">B. Network ACLs have allow and deny rules.</label>
      <label for="optionC" class="correct-answer">C. The default network ACL has only one inbound rule, denying all traffic from all protocols, all port ranges, from any source. &#x2713;&#x2713;</label>
      <label for="optionD">D. A subnet can be associated with only one network ACL at a time.</label>
    </form>
    <form class="question-form">
      <h1 class="question">In AWS KMS, which option is not correct?</h1>
      <label for="optionA">A. KMS can integrate with Amazon S3 and Amazon EBS.</label>
      <label for="optionB" class="correct-answer">B. KMS can be used to generate SSH access keys for Amazon EC2 instances. &#x2713;&#x2713;</label>
      <label for="optionC">C. KMS is considered multitenant, not a dedicated hardware security module.</label>
      <label for="optionD">D. KMS can be used to provide data-at-rest encryption for RDS, Aurora, DynamoDB, and Redshift databases</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which option is not correct in regard to AWS KMS customer master keys?</h1>
      <label for="optionA">A. A CMK is a 256-bit AES for symmetric keys.</label>
      <label for="optionB">B. A CMK has a key ID, an alias, and an ARN (Amazon Resource Name).</label>
      <label for="optionC" class="correct-answer">C. A CMK can also use IAM users, IAM groups, and IAM roles. . &#x2713;&#x2713;</label>
      <label for="optionD">D. A CMK has two policies roles: key administrators and key users</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following actions is not recommended when an Amazon EC2 instance is compromised by malware?</h1>
      <label for="optionA">A. Take a snapshot of the EBS volume at the time of the incident.</label>
      <label for="optionB" class="correct-answer">B. Change its security group accordingly and reattach any IAM role attached to the instance. &#x2713;&#x2713;</label>
      <label for="optionC">C. Tag the instance as compromised together with an AWS IAM policy that explicitly restricts all operations related to the instance, the incident response, and forensics teams.</label>
      <label for="optionD">D. When the incident forensics team wants to analyze the instance, they should deploy it into a totally isolated environment—ideally a private subnet.</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following actions is recommended when temporary credentials from an Amazon EC2 instance are inadvertently made public?</h1>
      <label for="optionA" class="correct-answer">A. You should assume that the access key was compromised and revoke it immediately. &#x2713;&#x2713;</label>
      <label for="optionB">B. You should try to locate where the key was exposed and inform AWS.</label>
      <label for="optionC">C. You should not reevaluate the IAM roles attached to the instance.</label>
      <label for="optionD">D. You should avoid rotating your key</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following options may not be considered a security automation trigger?</h1>
      <label for="optionA">A. Unsafe configurations from AWS Config or Amazon Inspector</label>
      <label for="optionB">B. AWS Security Hub findings</label>
      <label for="optionC" class="correct-answer">C. Systems Manager Automation documents &#x2713;&#x2713;</label>
      <label for="optionD">D. Event from Amazon CloudWatch Events</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following options may not be considered a security automation response task?</h1>
      <label for="optionA">A. An AWS Lambda function can use AWS APIs to change security groups or network ACLs.</label>
      <label for="optionB">B. A Systems Manager Automation document execution run.</label>
      <label for="optionC">C. Systems Manager Run Command can be used to execute commands to multiple hosts.</label>
      <label for="optionD" class="correct-answer">D. Apply a thorough forensic analysis in an isolated instance. &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">Which of the following options may not be considered a security troubleshooting tool for security in AWS Cloud environments?</h1>
      <label for="optionA">A. AWS CloudTrail</label>
      <label for="optionB">B. Amazon CloudWatch Logs</label>
      <label for="optionC" class="correct-answer">C. AWS Key Management Service &#x2713;&#x2713;</label>
      <label for="optionD">D. Amazon EventBridge</label>
    </form>
    <form class="question-form">
      <h1 class="question">Right after you correctly deploy VPC peering between two VPCs (A and B), inter-VPC traffic is still not happening. What is the most probable cause?</h1>
      <label for="optionA">A. The peering must be configured as transitive.</label>
      <label for="optionB" class="correct-answer">B. The route tables are not configured. &#x2713;&#x2713;</label>
      <label for="optionC">C. You need a shared VPC.</label>
      <label for="optionD">D. You need to configure a routing protocol</label>
    </form>
    <form class="question-form">
      <h1 class="question">A good mental exercise for your future cloud security design can start with the analysis of how AWS native security services and features (as well as third-party security solutions) can replace your traditional security controls. Which of the options is not a valid mapping between traditional security controls and potential AWS security controls?</h1>
      <label for="optionA">A. Network segregation (such as firewall rules and router access control lists) and security groups and network ACLs, Web Application Firewall (WAF)</label>
      <label for="optionB">B. Data encryption at rest and Amazon S3 server-side encryption, Amazon EBS encryption, Amazon RDS encryption, and other AWS KMS-enabled encryption features</label>
      <label for="optionC" class="correct-answer">C. Monitor intrusion and implementing security controls at the operating system level versus Amazon GuardDuty &#x2713;&#x2713;</label>
      <label for="optionD">D. Role-based access control (RBAC) versus AWS IAM, Active Directory integration through IAM groups, temporary security credentials, AWS Organizations</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company has two VPCs that are located in the us-west-2 Region within the same AWS account. The company needs to allow network traffic between these VPCs. Approximately 500 GB of data transfer will occur between the VPCs each month.</h1>
      <h1 class="question">What is the MOST cost-effective solution to connect these VPCs?</h1>
      <label for="optionA">A. Implement AWS Transit Gateway to connect the VPCs. Update the route tables of each VPC to use the transit gateway for inter-VPC communication.</label>
      <label for="optionB">B. Implement an AWS Site-to-Site VPN tunnel between the VPCs. Update the route tables of each VPC to use the VPN tunnel for inter-VPC communication.</label>
      <label for="optionC" class="correct-answer">C. Set up a VPC peering connection between the VPCs. Update the route tables of each VPC to use the VPC peering connection for inter-VPC communication. &#x2713;&#x2713;</label>
      <label for="optionD">D. Set up a 1 GB AWS Direct Connect connection between the VPCs. Update the route tables of each VPC to use the Direct Connect connection for inter-VPC communication.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company has a VPC in the us-west-1 Region and another VPC in the ap-southeast-2 Region. Network engineers set up an AWS Direct Connect connection from their data center to the us-east-1 Region. They create a private virtual interface (VIF) that references a Direct Connect gateway, which is then connected to virtual private gateways in both VPCs. When the setup is complete, the engineers cannot access resources in us-west-1 from ap-southeast-2.</h1>
      <h1 class="question">What should the network engineers do to resolve this issue?</h1>
      <label for="optionA">A. Add the subnet range for the VPCs in us-west-1 and ap-southeast-2 to the route tables for both VPCs. Add the Direct Connect gateway as a target.</label>
      <label for="optionB">B. Configure the Direct Connect gateway to route traffic between the VPCs in ap-southeast-2 and us-west-2.</label>
      <label for="optionC" class="correct-answer">C. Establish a VPC peering connection between the VPCs in ap-southeast-2 and us-west-2. Add the subnet ranges to the routing tables. &#x2713;&#x2713;</label>
      <label for="optionD">D. Create static routes in each VPC that point to the destination VPC with the virtual private gateway as the route target.</label>
    </form>

    <form class="question-form">
      <h1 class="question">A company needs to architect a hybrid DNS solution. This solution will use an Amazon Route 53 private hosted zone for the domain cloud.example.com for the resources stored within VPCs.</h1>
      <h1 class="question">The company has the following DNS resolution requirements:</h1>
      <ul>
        <li>On-premises systems should be able to resolve and connect to cloud.example.com.</li>
        <li>All VPCs should be able to resolve cloud.example.com.</li>
      </ul>
      <h1 class="question">There is already an AWS Direct Connect connection between the on-premises corporate network and AWS Transit Gateway.</h1>
      <h1 class="question">Which architecture should the company use to meet these requirements with the HIGHEST performance?</h1>
      <label for="optionA" class="correct-answer">A. Associate the private hosted zone to all the VPCs. Create a Route 53 inbound resolver in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver. &#x2713;&#x2713;</label>
      <label for="optionB">B. Associate the private hosted zone to all the VPCs. Deploy an Amazon EC2 conditional forwarder in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the conditional forwarder.</label>
      <label for="optionC">C. Associate the private hosted zone to the shared services VPC. Create a Route 53 outbound resolver in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the outbound resolver.</label>
      <label for="optionD">D. Associate the private hosted zone to the shared services VPC. Create a Route 53 inbound resolver in the shared services VPC. Attach the shared services VPC to the transit gateway and create forwarding rules in the on-premises DNS server for cloud.example.com that point to the inbound resolver.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company is providing weather data over a REST-based API to several customers. The API is hosted by Amazon API Gateway and is integrated with different AWS Lambda functions for each API operation. The company uses Amazon Route 53 for DNS and has created a resource record of weather.example.com. The company stores data for the API in Amazon DynamoDB tables. The company needs a solution that will give the API the ability to fail over to a different AWS Region.</h1>
      <h1 class="question">Which solution will meet these requirements?</h1>
      <label for="optionA">A. Deploy a new set of Lambda functions in a new Region. Update the API Gateway API to use an edge-optimized API endpoint with Lambda functions from both Regions as targets. Convert the DynamoDB tables to global tables.</label>
      <label for="optionB">B. Deploy a new API Gateway API and Lambda functions in another Region. Change the Route 53 DNS record to a multivalue answer. Add both API Gateway APIs to the answer. Enable target health monitoring. Convert the DynamoDB tables to global tables.</label>
      <label for="optionC" class="correct-answer">C. Deploy a new API Gateway API and Lambda functions in another Region. Change the Route 53 DNS record to a failover record. Enable target health monitoring. Convert the DynamoDB tables to global tables. &#x2713;&#x2713;</label>
      <label for="optionD">D. Deploy a new API Gateway API in a new Region. Change the Lambda functions to global functions. Change the Route 53 DNS record to a multivalue answer. Add both API Gateway APIs to the answer. Enable target health monitoring. Convert the DynamoDB tables to global tables.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company uses AWS Organizations with a single OU named Production to manage multiple accounts. All accounts are members of the Production OU. Administrators use deny list SCPs in the root of the organization to manage access to restricted services.</h1>
      <h1 class="question">The company recently acquired a new business unit and invited the new unit’s existing AWS account to the organization. Once onboarded, the administrators of the new business unit discovered that they are not able to update existing AWS Config rules to meet the company’s policies.</h1>
      <h1 class="question">Which option will allow administrators to make changes and continue to enforce the current policies without introducing additional long-term maintenance?</h1>
      <label for="optionA">A. Remove the organization’s root SCPs that limit access to AWS Config. Create AWS Service Catalog products for the company’s standard AWS Config rules and deploy them throughout the organization, including the new account.</label>
      <label for="optionB">B. Create a temporary OU named Onboarding for the new account. Apply an SCP to the Onboarding OU to allow AWS Config actions. Move the new account to the Production OU when adjustments to AWS Config are complete.</label>
      <label for="optionC">C. Convert the organization’s root SCPs from deny list SCPs to allow list SCPs to allow the required services only. Temporarily apply an SCP to the organization’s root that allows AWS Config actions for principals only in the new account.</label>
      <label for="optionD" class="correct-answer">D. Create a temporary OU named Onboarding for the new account. Apply an SCP to the Onboarding OU to allow AWS Config actions. Move the organization’s root SCP to the Production OU. Move the new account to the Production OU when adjustments to AWS Config are complete. &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company is running a two-tier web-based application in an on-premises data center. The application layer consists of a single server running a stateful application. The application connects to a PostgreSQL database running on a separate server. The application’s user base is expected to grow significantly, so the company is migrating the application and database to AWS. The solution will use Amazon Aurora PostgreSQL, Amazon EC2 Auto Scaling, and Elastic Load Balancing.</h1>
      <h1 class="question">Which solution will provide a consistent user experience that will allow the application and database tiers to scale?</h1>
      <label for="optionA">A. Enable Aurora Auto Scaling for Aurora Replicas. Use a Network Load Balancer with the least outstanding requests routing algorithm and sticky sessions enabled.</label>
      <label for="optionB">B. Enable Aurora Auto Scaling for Aurora writers. Use an Application Load Balancer with the round robin routing algorithm and sticky sessions enabled.</label>
      <label for="optionC" class="correct-answer">C. Enable Aurora Auto Scaling for Aurora Replicas. Use an Application Load Balancer with the round robin routing and sticky sessions enabled. &#x2713;&#x2713;</label>
      <label for="optionD">D. Enable Aurora Scaling for Aurora writers. Use a Network Load Balancer with the least outstanding requests routing algorithm and sticky sessions enabled</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company uses a service to collect metadata from applications that the company hosts on premises. Consumer devices such as TVs and internet radios access the applications. Many older devices do not support certain HTTP headers and exhibit errors when these headers are present in responses. The company has configured an on-premises load balancer to remove the unsupported headers from responses sent to older devices, which the company identified by the User-Agent headers.</h1>
      <h1 class="question">The company wants to migrate the service to AWS, adopt serverless technologies, and retain the ability to support the older devices. The company has already migrated the applications into a set of AWS Lambda functions.</h1>
      <h1 class="question">Which solution will meet these requirements?</h1>
      
      <label for="optionA">A. Create an Amazon CloudFront distribution for the metadata service. Create an Application Load Balancer (ALB). Configure the CloudFront distribution to forward requests to the ALB. Configure the ALB to invoke the correct Lambda function for each type of request. Create a CloudFront function to remove the problematic headers based on the value of the User-Agent header.</label>
      
      <label for="optionB">B. Create an Amazon API Gateway REST API for the metadata service. Configure API Gateway to invoke the correct Lambda function for each type of request. Modify the default gateway responses to remove the problematic headers based on the value of the User-Agent header.</label>
      
      <label for="optionC">C. Create an Amazon API Gateway HTTP API for the metadata service. Configure API Gateway to invoke the correct Lambda function for each type of request. Create a response mapping template to remove the problematic headers based on the value of the User-Agent. Associate the response data mapping with the HTTP API.</label>
      
      <label for="optionD" class="correct-answer">D. Create an Amazon CloudFront distribution for the metadata service. Create an Application Load Balancer (ALB). Configure the CloudFront distribution to forward requests to the ALB. Configure the ALB to invoke the correct Lambda function for each type of request. Create a Lambda@Edge function that will remove the problematic headers in response to viewer requests based on the value of the User-Agent header. &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">A retail company needs to provide a series of data files to another company, which is its business partner. These files are saved in an Amazon S3 bucket under Account A, which belongs to the retail company. The business partner company wants one of its IAM users, User_DataProcessor, to access the files from its own AWS account (Account B).</h1>
      <h1 class="question">Which combination of steps must the companies take so that User_DataProcessor can access the S3 bucket successfully? (Choose two.)</h1>
    
      <label for="optionA">A. Turn on the cross-origin resource sharing (CORS) feature for the S3 bucket in Account A.</label>
    
      <label for="optionB">B. In Account A, set the S3 bucket policy to the following:
        <pre>
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Principal": {
            "AWS": "arn:aws:iam::AccountB-ID:root"
          },
          "Action": "s3:GetObject",
          "Resource": "arn:aws:s3:::bucket-name/*"
        }
      ]
    }
        </pre>
      </label>
    
      <label for="optionC" class="correct-answer">C. In Account A, set the S3 bucket policy to the following:
        <pre>
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Principal": {
            "AWS": "arn:aws:iam::AccountB-ID:user/User_DataProcessor"
          },
          "Action": "s3:GetObject",
          "Resource": "arn:aws:s3:::bucket-name/*"
        }
      ]
    }
        </pre>
        &#x2713;&#x2713;
      </label>
    
      <label for="optionD">D. In Account B, set the permissions of User_DataProcessor to the following:
        <pre>
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Action": "s3:GetObject",
          "Resource": "arn:aws:s3:::bucket-name/*"
        }
      ]
    }
        </pre>
      </label>
    
      <label for="optionE" class="correct-answer">E. In Account B, set the permissions of User_DataProcessor to the following:
        <pre>
    {
      "Version": "2012-10-17",
      "Statement": [
        {
          "Effect": "Allow",
          "Action": "s3:GetObject",
          "Resource": "arn:aws:s3:::AccountA-ID:bucket-name/*"
        }
      ]
    }
        </pre>
        &#x2713;&#x2713;
      </label>
    </form>
    <form class="question-form">
      <h1 class="question">A company is running a traditional web application on Amazon EC2 instances. The company needs to refactor the application as microservices that run on containers. Separate versions of the application exist in two distinct environments: production and testing. Load for the application is variable, but the minimum load and the maximum load are known. A solutions architect needs to design the updated application with a serverless architecture that minimizes operational complexity.</h1>
      <h1 class="question">Which solution will meet these requirements MOST cost-effectively?</h1>
    
      <label for="optionA">A. Upload the container images to AWS Lambda as functions. Configure a concurrency limit for the associated Lambda functions to handle the expected peak load. Configure two separate Lambda integrations within Amazon API Gateway: one for production and one for testing.</label>
    
      <label for="optionB" class="correct-answer">B. Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Container Service (Amazon ECS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the ECS clusters. &#x2713;&#x2713;</label>
    
      <label for="optionC">C. Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Kubernetes Service (Amazon EKS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the EKS clusters.</label>
    
      <label for="optionD">D. Upload the container images to AWS Elastic Beanstalk. In Elastic Beanstalk, create separate environments and deployments for production and testing. Configure two separate Application Load Balancers to direct traffic to the Elastic Beanstalk deployments.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company has a multi-tier web application that runs on a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB). The instances are in an Auto Scaling group. The ALB and the Auto Scaling group are replicated in a backup AWS Region. The minimum value and the maximum value for the Auto Scaling group are set to zero. An Amazon RDS Multi-AZ DB instance stores the application’s data. The DB instance has a read replica in the backup Region. The application presents an endpoint to end users by using an Amazon Route 53 record.</h1>
      <h1 class="question">The company needs to reduce its RTO to less than 15 minutes by giving the application the ability to automatically fail over to the backup Region. The company does not have a large enough budget for an active-active strategy.</h1>
      <h1 class="question">What should a solutions architect recommend to meet these requirements?</h1>
    
      <label for="optionA">A. Reconfigure the application’s Route 53 record with a latency-based routing policy that load balances traffic between the two ALBs. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Create an Amazon CloudWatch alarm that is based on the HTTPCode_Target_5XX_Count metric for the ALB in the primary Region. Configure the CloudWatch alarm to invoke the Lambda function.</label>
    
      <label for="optionB" class="correct-answer">B. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Configure Route 53 with a health check that monitors the web application and sends an Amazon Simple Notification Service (Amazon SNS) notification to the Lambda function when the health check status is unhealthy. Update the application’s Route 53 record with a failover policy that routes traffic to the ALB in the backup Region when a health check failure occurs. &#x2713;&#x2713;</label>
    
      <label for="optionC">C. Configure the Auto Scaling group in the backup Region to have the same values as the Auto Scaling group in the primary Region. Reconfigure the application’s Route 53 record with a latency-based routing policy that load balances traffic between the two ALBs. Remove the read replica. Replace the read replica with a standalone RDS DB instance. Configure Cross-Region Replication between the RDS DB instances by using snapshots and Amazon S3.</label>
    
      <label for="optionD">D. Configure an endpoint in AWS Global Accelerator with the two ALBs as equal weighted targets. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Create an Amazon CloudWatch alarm that is based on the HTTPCode_Target_5XX_Count metric for the ALB in the primary Region. Configure the CloudWatch alarm to invoke the Lambda function.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company is hosting a critical application on a single Amazon EC2 instance. The application uses an Amazon ElastiCache for Redis single-node cluster for an in-memory data store. The application uses an Amazon RDS for MariaDB DB instance for a relational database. For the application to function, each piece of the infrastructure must be healthy and must be in an active state.</h1>
      <h1 class="question">A solutions architect needs to improve the application's architecture so that the infrastructure can automatically recover from failure with the least possible downtime.</h1>
      <h1 class="question">Which combination of steps will meet these requirements? (Choose three.)</h1>
      <label for="optionA" class="correct-answer">A. Use an Elastic Load Balancer to distribute traffic across multiple EC2 instances. Ensure that the EC2 instances are part of an Auto Scaling group that has a minimum capacity of two instances. &#x2713;&#x2713;</label>
      <label for="optionB">B. Use an Elastic Load Balancer to distribute traffic across multiple EC2 instances. Ensure that the EC2 instances are configured in unlimited mode.</label>
      <label for="optionC">C. Modify the DB instance to create a read replica in the same Availability Zone. Promote the read replica to be the primary DB instance in failure scenarios.</label>
      <label for="optionD" class="correct-answer">D. Modify the DB instance to create a Multi-AZ deployment that extends across two Availability Zones. &#x2713;&#x2713;</label>
      <label for="optionE">E. Create a replication group for the ElastiCache for Redis cluster. Configure the cluster to use an Auto Scaling group that has a minimum capacity of two instances.</label>
      <label for="optionF" class="correct-answer">F. Create a replication group for the ElastiCache for Redis cluster. Enable Multi-AZ on the cluster. &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">A retail company is operating its ecommerce application on AWS. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The company uses an Amazon RDS DB instance as the database backend. Amazon CloudFront is configured with one origin that points to the ALB. Static content is cached. Amazon Route 53 is used to host all public zones.</h1>
      <h1 class="question">After an update of the application, the ALB occasionally returns a 502 status code (Bad Gateway) error. The root cause is malformed HTTP headers that are returned to the ALB. The webpage returns successfully when a solutions architect reloads the webpage immediately after the error occurs.</h1>
      <h1 class="question">While the company is working on the problem, the solutions architect needs to provide a custom error page instead of the standard ALB error page to visitors.</h1>
      <h1 class="question">Which combination of steps will meet this requirement with the LEAST amount of operational overhead? (Choose two.)</h1>
    
      <label for="optionA" class="correct-answer">A. Create an Amazon S3 bucket. Configure the S3 bucket to host a static webpage. Upload the custom error pages to Amazon S3. &#x2713;&#x2713;</label>
    
      <label for="optionB">B. Create an Amazon CloudWatch alarm to invoke an AWS Lambda function if the ALB health check response Target.FailedHealthChecks is greater than 0. Configure the Lambda function to modify the forwarding rule at the ALB to point to a publicly accessible web server.</label>
    
      <label for="optionC">C. Modify the existing Amazon Route 53 records by adding health checks. Configure a fallback target if the health check fails. Modify DNS records to point to a publicly accessible webpage.</label>
    
      <label for="optionD">D. Create an Amazon CloudWatch alarm to invoke an AWS Lambda function if the ALB health check response Elb.InternalError is greater than 0. Configure the Lambda function to modify the forwarding rule at the ALB to point to a public accessible web server.</label>
    
      <label for="optionE" class="correct-answer">E. Add a custom error response by configuring a CloudFront custom error page. Modify DNS records to point to a publicly accessible web page. &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company has a mobile application that makes HTTP API calls to an Application Load Balancer (ALB). The ALB routes requests to an AWS Lambda function. Many different versions of the application are in use at any given time, including versions that are in testing by a subset of users. The version of the application is defined in the user-agent header that is sent with all requests to the API.</h1>
      <h1 class="question">After a series of recent changes to the API, the company has observed issues with the application. The company needs to gather a metric for each API operation by response code for each version of the application that is in use. A DevOps engineer has modified the Lambda function to extract the API operation name, version information from the user-agent header and response code.</h1>
      <h1 class="question">Which additional set of actions should the DevOps engineer take to gather the required metrics?</h1>
      <label for="optionA" class="correct-answer">A. Modify the Lambda function to write the API operation name, response code, and version number as a log line to an Amazon CloudWatch Logs log group. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric. &#x2713;&#x2713;</label>
      <label for="optionB">B. Modify the Lambda function to write the API operation name, response code, and version number as a log line to an Amazon CloudWatch Logs log group. Configure a CloudWatch Logs Insights query to populate CloudWatch metrics from the log lines. Specify response code and application version as dimensions for the metric.</label>
      <label for="optionC">C. Configure the ALB access logs to write to an Amazon CloudWatch Logs log group. Modify the Lambda function to respond to the ALB with the API operation name, response code, and version number as response metadata. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric.</label>
      <label for="optionD">D. Configure AWS X-Ray integration on the Lambda function. Modify the Lambda function to create an X-Ray subsegment with the API operation name, response code, and version number. Configure X-Ray insights to extract an aggregated metric for each API operation name and to publish the metric to Amazon CloudWatch. Specify response code and application version as dimensions for the metric.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company provides an application to customers. The application has an Amazon API Gateway REST API that invokes an AWS Lambda function. On initialization, the Lambda function loads a large amount of data from an Amazon DynamoDB table. The data load process results in long cold-start times of 8-10 seconds. The DynamoDB table has DynamoDB Accelerator (DAX) configured.</h1>
      <h1 class="question">Customers report that the application intermittently takes a long time to respond to requests. The application receives thousands of requests throughout the day. In the middle of the day, the application experiences 10 times more requests than at any other time of the day. Near the end of the day, the application's request volume decreases to 10% of its normal total.</h1>
      <h1 class="question">A DevOps engineer needs to reduce the latency of the Lambda function at all times of the day.</h1>
      <h1 class="question">Which solution will meet these requirements?</h1>
      <label for="optionA">A. Configure provisioned concurrency on the Lambda function with a concurrency value of 1. Delete the DAX cluster for the DynamoDB table.</label>
      <label for="optionB">B. Configure reserved concurrency on the Lambda function with a concurrency value of 0.</label>
      <label for="optionC" class="correct-answer">C. Configure provisioned concurrency on the Lambda function. Configure AWS Application Auto Scaling on the Lambda function with provisioned concurrency values set to a minimum of 1 and a maximum of 100. &#x2713;&#x2713;</label>
      <label for="optionD">D. Configure reserved concurrency on the Lambda function. Configure AWS Application Auto Scaling on the API Gateway API with a reserved concurrency maximum value of 100.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company is adopting AWS CodeDeploy to automate its application deployments for a Java-Apache Tomcat application with an Apache Webserver. The development team started with a proof of concept, created a deployment group for a developer environment, and performed functional tests within the application. After completion, the team will create additional deployment groups for staging and production.</h1>
      <h1 class="question">The current log level is configured within the Apache settings, but the team wants to change this configuration dynamically when the deployment occurs, so that they can set different log level configurations depending on the deployment group without having a different application revision for each group.</h1>
      <h1 class="question">How can these requirements be met with the LEAST management overhead and without requiring different script versions for each deployment group?</h1>
    
      <label for="optionA">A. Tag the Amazon EC2 instances depending on the deployment group. Then place a script into the application revision that calls the metadata service and the EC2 API to identify which deployment group the instance is part of. Use this information to configure the log level settings. Reference the script as part of the AfterInstall lifecycle hook in the appspec.yml file.</label>
      <label for="optionB" class="correct-answer">B. Create a script that uses the CodeDeploy environment variable DEPLOYMENT_GROUP_NAME to identify which deployment group the instance is part of. Use this information to configure the log level settings. Reference this script as part of the BeforeInstall lifecycle hook in the appspec.yml file. &#x2713;&#x2713;</label>
      <label for="optionC">C. Create a CodeDeploy custom environment variable for each environment. Then place a script into the application revision that checks this environment variable to identify which deployment group the instance is part of. Use this information to configure the log level settings. Reference this script as part of the ValidateService lifecycle hook in the appspec.yml file.</label>
      <label for="optionD">D. Create a script that uses the CodeDeploy environment variable DEPLOYMENT_GROUP_ID to identify which deployment group the instance is part of to configure the log level settings. Reference this script as part of the Install lifecycle hook in the appspec.yml file.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company requires its developers to tag all Amazon Elastic Block Store (Amazon EBS) volumes in an account to indicate a desired backup frequency. This requirement includes EBS volumes that do not require backups. The company uses custom tags named Backup_Frequency that have values of none, daily, or weekly that correspond to the desired backup frequency. An audit finds that developers are occasionally not tagging the EBS volumes.</h1>
      <h1 class="question">A DevOps engineer needs to ensure that all EBS volumes always have the Backup_Frequency tag so that the company can perform backups at least weekly unless a different value is specified.</h1>
      <h1 class="question">Which solution will meet these requirements?</h1>
    
      <label for="optionA">A. Set up AWS Config in the account. Create a custom rule that returns a compliance failure for all Amazon EC2 resources that do not have a Backup_Frequency tag applied. Configure a remediation action that uses a custom AWS Systems Manager Automation runbook to apply the Backup_Frequency tag with a value of weekly.</label>
    
      <label for="optionB" class="correct-answer">B. Set up AWS Config in the account. Use a managed rule that returns a compliance failure for EC2::Volume resources that do not have a Backup_Frequency tag applied. Configure a remediation action that uses a custom AWS Systems Manager Automation runbook to apply the Backup_Frequency tag with a value of weekly. &#x2713;&#x2713;</label>
    
      <label for="optionC">C. Turn on AWS CloudTrail in the account. Create an Amazon EventBridge rule that reacts to EBS CreateVolume events. Configure a custom AWS Systems Manager Automation runbook to apply the Backup_Frequency tag with a value of weekly. Specify the runbook as the target of the rule.</label>
    
      <label for="optionD">D. Turn on AWS CloudTrail in the account. Create an Amazon EventBridge rule that reacts to EBS CreateVolume events or EBS ModifyVolume events. Configure a custom AWS Systems Manager Automation runbook to apply the Backup_Frequency tag with a value of weekly. Specify the runbook as the target of the rule.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company is using an Amazon Aurora cluster as the data store for its application. The Aurora cluster is configured with a single DB instance. The application performs read and write operations on the database by using the cluster's instance endpoint.</h1>
      <h1 class="question">The company has scheduled an update to be applied to the cluster during an upcoming maintenance window. The cluster must remain available with the least possible interruption during the maintenance window.</h1>
      <h1 class="question">What should a DevOps engineer do to meet these requirements?</h1>
      <label for="optionA" class="correct-answer">A. Add a reader instance to the Aurora cluster. Update the application to use the Aurora cluster endpoint for write operations. Update the Aurora cluster's reader endpoint for reads. &#x2713;&#x2713;</label>
      <label for="optionB">B. Add a reader instance to the Aurora cluster. Create a custom ANY endpoint for the cluster. Update the application to use the Aurora cluster's custom ANY endpoint for read and write operations.</label>
      <label for="optionC">C. Turn on the Multi-AZ option on the Aurora cluster. Update the application to use the Aurora cluster endpoint for write operations. Update the Aurora cluster’s reader endpoint for reads.</label>
      <label for="optionD">D. Turn on the Multi-AZ option on the Aurora cluster. Create a custom ANY endpoint for the cluster. Update the application to use the Aurora cluster's custom ANY endpoint for read and write operations</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company must encrypt all AMIs that the company shares across accounts. A DevOps engineer has access to a source account where an unencrypted custom AMI has been built. The DevOps engineer also has access to a target account where an Amazon EC2 Auto Scaling group will launch EC2 instances from the AMI. The DevOps engineer must share the AMI with the target account.</h1>
      <h1 class="question">The company has created an AWS Key Management Service (AWS KMS) key in the source account.</h1>
      <h1 class="question">Which additional steps should the DevOps engineer perform to meet the requirements? (Choose three.)</h1>
    
      <label for="optionA" class="correct-answer">A. In the source account, copy the unencrypted AMI to an encrypted AMI. Specify the KMS key in the copy action. &#x2713;&#x2713;</label>
    
      <label for="optionB">B. In the source account, copy the unencrypted AMI to an encrypted AMI. Specify the default Amazon Elastic Block Store (Amazon EBS) encryption key in the copy action.</label>
    
      <label for="optionC">C. In the source account, create a KMS grant that delegates permissions to the Auto Scaling group service-linked role in the target account.</label>
    
      <label for="optionD" class="correct-answer">D. In the source account, modify the key policy to give the target account permissions to create a grant. In the target account, create a KMS grant that delegates permissions to the Auto Scaling group service-linked role. &#x2713;&#x2713;</label>
    
      <label for="optionE">E. In the source account, share the unencrypted AMI with the target account.</label>
    
      <label for="optionF" class="correct-answer">F. In the source account, share the encrypted AMI with the target account. &#x2713;&#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company uses AWS CodePipeline pipelines to automate releases of its application. A typical pipeline consists of three stages: build, test, and deployment. The company has been using a separate AWS CodeBuild project to run scripts for each stage. However, the company now wants to use AWS CodeDeploy to handle the deployment stage of the pipelines.</h1>
      <h1 class="question">The company has packaged the application as an RPM package and must deploy the application to a fleet of Amazon EC2 instances. The EC2 instances are in an EC2 Auto Scaling group and are launched from a common AMI.</h1>
      <h1 class="question">Which combination of steps should a DevOps engineer perform to meet these requirements? (Choose two.)</h1>
    
      <label for="optionA" class="correct-answer">A. Create a new version of the common AMI with the CodeDeploy agent installed. Update the IAM role of the EC2 instances to allow access to CodeDeploy. &#x2713;</label>
      <label for="optionB">B. Create a new version of the common AMI with the CodeDeploy agent installed. Create an AppSpec file that contains application deployment scripts and grants access to CodeDeploy.</label>
      <label for="optionC">C. Create an application in CodeDeploy. Configure an in-place deployment type. Specify the Auto Scaling group as the deployment target. Add a step to the CodePipeline pipeline to use EC2 Image Builder to create a new AMI. Configure CodeDeploy to deploy the newly created AMI.</label>
      <label for="optionD" class="correct-answer">D. Create an application in CodeDeploy. Configure an in-place deployment type. Specify the Auto Scaling group as the deployment target. Update the CodePipeline pipeline to use the CodeDeploy action to deploy the application. &#x2713;</label>
      <label for="optionE">E. Create an application in CodeDeploy. Configure an in-place deployment type. Specify the EC2 instances that are launched from the common AMI as the deployment target. Update the CodePipeline pipeline to use the CodeDeploy action to deploy the application.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company’s security team requires that all external Application Load Balancers (ALBs) and Amazon API Gateway APIs are associated with AWS WAF web ACLs. The company has hundreds of AWS accounts, all of which are included in a single organization in AWS Organizations. The company has configured AWS Config for the organization. During an audit, the company finds some externally facing ALBs that are not associated with AWS WAF web ACLs.</h1>
      <h1 class="question">Which combination of steps should a DevOps engineer take to prevent future violations? (Choose two.)</h1>
    
      <label for="optionA" class="correct-answer">A. Delegate AWS Firewall Manager to a security account. &#x2713;</label>
      <label for="optionB">B. Delegate Amazon GuardDuty to a security account.</label>
      <label for="optionC" class="correct-answer">C. Create an AWS Firewall Manager policy to attach AWS WAF web ACLs to any newly created ALBs and API Gateway APIs. &#x2713;</label>
      <label for="optionD">D. Create an Amazon GuardDuty policy to attach AWS WAF web ACLs to any newly created ALBs and API Gateway APIs.</label>
      <label for="optionE">E. Configure an AWS Config managed rule to attach AWS WAF web ACLs to any newly created ALBs and API Gateway APIs.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company uses AWS Key Management Service (AWS KMS) keys and manual key rotation to meet regulatory compliance requirements. The security team wants to be notified when any keys have not been rotated after 90 days.</h1>
      <h1 class="question">Which solution will accomplish this?</h1>
    
      <label for="optionA">A. Configure AWS KMS to publish to an Amazon Simple Notification Service (Amazon SNS) topic when keys are more than 90 days old.</label>
      <label for="optionB">B. Configure an Amazon EventBridge event to launch an AWS Lambda function to call the AWS Trusted Advisor API and publish to an Amazon Simple Notification Service (Amazon SNS) topic.</label>
      <label for="optionC" class="correct-answer">C. Develop an AWS Config custom rule that publishes to an Amazon Simple Notification Service (Amazon SNS) topic when keys are more than 90 days old. &#x2713;</label>
      <label for="optionD">D. Configure AWS Security Hub to publish to an Amazon Simple Notification Service (Amazon SNS) topic when keys are more than 90 days old.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A security review has identified that an AWS CodeBuild project is downloading a database population script from an Amazon S3 bucket using an unauthenticated request. The security team does not allow unauthenticated requests to S3 buckets for this project.</h1>
      <h1 class="question">How can this issue be corrected in the MOST secure manner?</h1>
    
      <label for="optionA">A. Add the bucket name to the AllowedBuckets section of the CodeBuild project settings. Update the build spec to use the AWS CLI to download the database population script.</label>
      <label for="optionB">B. Modify the S3 bucket settings to enable HTTPS basic authentication and specify a token. Update the build spec to use cURL to pass the token and download the database population script.</label>
      <label for="optionC" class="correct-answer">C. Remove unauthenticated access from the S3 bucket with a bucket policy. Modify the service role for the CodeBuild project to include Amazon S3 access. Use the AWS CLI to download the database population script. &#x2713;</label>
      <label for="optionD">D. Remove unauthenticated access from the S3 bucket with a bucket policy. Use the AWS CLI to download the database population script using an IAM access key and a secret access key.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company wants to ensure that their EC2 instances are secure. They want to be notified if any new vulnerabilities are discovered on their instances, and they also want an audit trail of all login activities on the instances.</h1>
      <h1 class="question">Which solution will meet these requirements?</h1>
    
      <label for="optionA">A. Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Amazon Kinesis Agent to capture system logs and deliver them to Amazon S3.</label>
      <label for="optionB">B. Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Systems Manager Agent to capture system logs and view login activity in the CloudTrail console.</label>
      <label for="optionC">C. Configure Amazon CloudWatch to detect vulnerabilities on the EC2 instances. Install the AWS Config daemon to capture system logs and view them in the AWS Config console.</label>
      <label for="optionD" class="correct-answer">D. Configure Amazon Inspector to detect vulnerabilities on the EC2 instances. Install the Amazon CloudWatch Agent to capture system logs and record them via Amazon CloudWatch Logs. &#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company has many applications. Different teams in the company developed the applications by using multiple languages and frameworks. The applications run on premises and on different servers with different operating systems. Each team has its own release protocol and process. The company wants to reduce the complexity of the release and maintenance of these applications. The company is migrating its technology stacks, including these applications, to AWS. The company wants centralized control of source code, a consistent and automatic delivery pipeline, and as few maintenance tasks as possible on the underlying infrastructure.</h1>
      <h1 class="question">What should a DevOps engineer do to meet these requirements?</h1>
    
      <label for="optionA">A. Create one AWS CodeCommit repository for all applications. Put each application's code in different branch. Merge the branches, and use AWS CodeBuild to build the applications. Use AWS CodeDeploy to deploy the applications to one centralized application server.</label>
      <label for="optionB">B. Create one AWS CodeCommit repository for each of the applications. Use AWS CodeBuild to build the applications one at a time. Use AWS CodeDeploy to deploy the applications to one centralized application server.</label>
      <label for="optionC">C. Create one AWS CodeCommit repository for each of the applications. Use AWS CodeBuild to build the applications one at a time to create one AMI for each server. Use AWS CloudFormation StackSets to automatically provision and decommission Amazon EC2 fleets by using these AMIs.</label>
      <label for="optionD" class="correct-answer">D. Create one AWS CodeCommit repository for each of the applications. Use AWS CodeBuild to build one Docker image for each application in Amazon Elastic Container Registry (Amazon ECR). Use AWS CodeDeploy to deploy the applications to Amazon Elastic Container Service (Amazon ECS) on infrastructure that AWS Fargate manages. &#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">A DevOps engineer is developing an application for a company. The application needs to persist files to Amazon S3. The application needs to upload files with different security classifications that the company defines. These classifications include confidential, private, and public. Files that have a confidential classification must not be viewable by anyone other than the user who uploaded them. The application uses the IAM role of the user to call the S3 API operations.</h1>
      <h1 class="question">The DevOps engineer has modified the application to add a DataClassification tag with the value of confidential and an Owner tag with the uploading user's ID to each confidential object that is uploaded to Amazon S3. Which set of additional steps must the DevOps engineer take to meet the company's requirements?</h1>
    
      <label for="optionA">A. Modify the S3 bucket's ACL to grant bucket-owner-read access to the uploading user's IAM role. Create an IAM policy that grants s3:GetObject operations on the S3 bucket when aws:ResourceTag/DataClassification equals confidential, and s3:ExistingObjectTag/Owner equals ${aws:userid}. Attach the policy to the IAM roles for users who require access to the S3 bucket.</label>
      
      <label for="optionB" class="correct-answer">B. Modify the S3 bucket policy to allow the s3:GetObject action when aws:ResourceTag/DataClassification equals confidential, and s3:ExistingObjectTag/Owner equals ${aws:userid}. Create an IAM policy that grants s3:GetObject operations on the S3 bucket. Attach the policy to the IAM roles for users who require access to the S3 bucket. &#x2713;</label>
      
      <label for="optionC">C. Modify the S3 bucket policy to allow the s3:GetObject action when aws:ResourceTag/DataClassification equals confidential, and aws:RequestTag/Owner equals ${aws:userid}. Create an IAM policy that grants s3:GetObject operations on the S3 bucket. Attach the policy to the IAM roles for users who require access to the S3 bucket.</label>
      
      <label for="optionD">D. Modify the S3 bucket's ACL to grant authenticated-read access when aws:ResourceTag/DataClassification equals confidential, and s3:ExistingObjectTag/Owner equals ${aws:userid}. Create an IAM policy that grants s3:GetObject operations on the S3 bucket. Attach the policy to the IAM roles for users who require access to the S3 bucket.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A company has developed an AWS Lambda function that handles orders received through an API. The company is using AWS CodeDeploy to deploy the Lambda function as the final stage of a CI/CD pipeline.</h1>
      <h1 class="question">A DevOps Engineer has noticed there are intermittent failures of the ordering API for a few seconds after deployment. After some investigation, the DevOps Engineer believes the failures are due to database changes not having fully propagated before the Lambda function begins executing.</h1>
      <h1 class="question">How should the DevOps Engineer overcome this?</h1>
    
      <label for="optionA" class="correct-answer">A. Add a BeforeAllowTraffic hook to the AppSpec file that tests and waits for any necessary database changes before traffic can flow to the new version of the Lambda function. &#x2713;</label>
    
      <label for="optionB">B. Add an AfterAllowTraffic hook to the AppSpec file that forces traffic to wait for any pending database changes before allowing the new version of the Lambda function to respond.</label>
    
      <label for="optionC">C. Add a BeforeInstall hook to the AppSpec file that tests and waits for any necessary database changes before deploying the new version of the Lambda function.</label>
    
      <label for="optionD">D. Add a ValidateService hook to the AppSpec file that inspects incoming traffic and rejects the payload if dependent services, such as the database, are not yet ready.</label>
    </form>
    <form class="question-form">
      <h1 class="question">A software company wants to automate the build process for a project where the code is stored in GitHub. When the repository is updated, source code should be compiled, tested, and pushed to Amazon S3.</h1>
      <h1 class="question">Which combination of steps would address these requirements? (Choose three.)</h1>
    
      <label for="optionA" class="correct-answer">A. Add a buildspec.yml file to the source code with build instructions. &#x2713;</label>
      <label for="optionB" class="correct-answer">B. Configure a GitHub webhook to trigger a build every time a code change is pushed to the repository. &#x2713;</label>
      <label for="optionC" class="correct-answer">C. Create an AWS CodeBuild project with GitHub as the source repository. &#x2713;</label>
      <label for="optionD">D. Create an AWS CodeDeploy application with the Amazon EC2/On-Premises compute platform.</label>
      <label for="optionE">E. Create an AWS OpsWorks deployment with the install dependencies command.</label>
      <label for="optionF">F. Provision an Amazon EC2 instance to perform the build.</label>
    </form>
    <form class="question-form">
      <h1 class="question">An online retail company based in the United States plans to expand its operations to Europe and Asia in the next six months. Its product currently runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. All data is stored in an Amazon Aurora database instance.</h1>
      <h1 class="question">When the product is deployed in multiple regions, the company wants a single product catalog across all regions, but for compliance purposes, its customer information and purchases must be kept in each region.</h1>
      <h1 class="question">How should the company meet these requirements with the LEAST amount of application changes?</h1>
    
      <label for="optionA">A. Use Amazon Redshift for the product catalog and Amazon DynamoDB tables for the customer information and purchases.</label>
      <label for="optionB">B. Use Amazon DynamoDB global tables for the product catalog and regional tables for the customer information and purchases.</label>
      <label for="optionC" class="correct-answer">C. Use Aurora with read replicas for the product catalog and additional local Aurora instances in each region for the customer information and purchases. &#x2713;</label>
      <label for="optionD">D. Use Aurora for the product catalog and Amazon DynamoDB global tables for the customer information and purchases.</label>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company wants to ensure that their EC2 instances are secure. They want to be notified if any new vulnerabilities are discovered on their instances, and they also want an audit trail of all login activities on the instances.
      </h1>
      <h1 class="question">Which solution will meet these requirements?</h1>
    
      <label for="optionA">
        A. Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Amazon Kinesis Agent to capture system logs and deliver them to Amazon S3.
      </label>
    
      <label for="optionB">
        B. Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Systems Manager Agent to capture system logs and view login activity in the CloudTrail console.
      </label>
    
      <label for="optionC">
        C. Configure Amazon CloudWatch to detect vulnerabilities on the EC2 instances. Install the AWS Config daemon to capture system logs and view them in the AWS Config console.
      </label>
    
      <label for="optionD" class="correct-answer">
        D. Configure Amazon Inspector to detect vulnerabilities on the EC2 instances. Install the Amazon CloudWatch Agent to capture system logs and record them via Amazon CloudWatch Logs. &#x2713;
      </label>
    </form>
    <form class="question-form">
      <h1 class="question">A DevOps Engineer needs to back up sensitive Amazon S3 objects that are stored within an S3 bucket with a private bucket policy using the S3 cross-region replication functionality. The objects need to be copied to a target bucket in a different AWS Region and account. Which actions should be performed to enable this replication? (Choose three.)</h1>
    
      <label for="optionA" class="correct-answer">A. Create a replication IAM role in the source account. &#x2713;</label><br>
      <label for="optionB">B. Create a replication IAM role in the target account.</label><br>
      <label for="optionC">C. Add statements to the source bucket policy allowing the replication IAM role to replicate objects.</label><br>
      <label for="optionD" class="correct-answer">D. Add statements to the target bucket policy allowing the replication IAM role to replicate objects. &#x2713;</label><br>
      <label for="optionE" class="correct-answer">E. Create a replication rule in the source bucket to enable the replication. &#x2713;</label><br>
      <label for="optionF">F. Create a replication rule in the target bucket to enable the replication.</label><br>
    </form>
    <form class="question-form">
      <h1 class="question">A company is using Amazon EC2 for various workloads. Company policy requires that instances be managed centrally to standardize configurations. These configurations include standard logging, metrics, security assessments, and weekly patching.</h1>
      <h1 class="question">How can the company meet these requirements? (Choose three.)</h1>
    
      <label for="optionA" class="correct-answer">A. Use AWS Config to ensure all EC2 instances are managed by AWS Systems Manager. &#x2713;</label><br>
      <label for="optionB">B. Use AWS Config to ensure all EC2 instances are managed by Amazon Inspector.</label><br>
      <label for="optionC" class="correct-answer">C. Use AWS Systems Manager to install and manage Amazon Inspector, Systems Manager Patch Manager, and the Amazon CloudWatch agent on all instances. &#x2713;</label><br>
      <label for="optionD">D. Use Amazon Inspector to install and manage AWS Systems Manager, Systems Manager Patch Manager, and the Amazon CloudWatch agent on all instances.</label><br>
      <label for="optionE">E. Use AWS Systems Manager maintenance windows with Systems Manager Run Command to schedule Systems Manager Patch Manager tasks. Use the Amazon CloudWatch agent to schedule Amazon Inspector assessment runs.</label><br>
      <label for="optionF" class="correct-answer">F. Use AWS Systems Manager maintenance windows with Systems Manager Run Command to schedule Systems Manager Patch Manager tasks. Use Amazon CloudWatch Events to schedule Amazon Inspector assessment runs. &#x2713;</label>
    </form>
    <form class="question-form">
      <h1 class="question">
        A business has an application that consists of five independent AWS Lambda functions. The DevOps Engineer has built a CI/CD pipeline using AWS CodePipeline and AWS CodeBuild that builds, tests, packages, and deploys each Lambda function in sequence. The pipeline uses an Amazon CloudWatch Events rule to ensure the pipeline execution starts as quickly as possible after a change is made to the application source code.
      </h1>
      <h1 class="question">
        After working with the pipeline for a few months, the DevOps Engineer has noticed the pipeline takes too long to complete. What should the DevOps Engineer implement to BEST improve the speed of the pipeline?
      </h1>
    
      <label for="optionA">A. Modify the CodeBuild projects within the pipeline to use a compute type with more available network throughput.</label><br>
      <label for="optionB">B. Create a custom CodeBuild execution environment that includes a symmetric multiprocessing configuration to run the builds in parallel.</label><br>
      <label for="optionC" class="correct-answer">C. Modify the CodePipeline configuration to execute actions for each Lambda function in parallel by specifying the same runOrder. &#x2713;</label><br>
      <label for="optionD">D. Modify each CodeBuild project to run within a VPC and use dedicated instances to increase throughput.</label><br>
    </form>

    <form class="question-form">
      <h1 class="question">
        A company is creating a software solution that executes a specific parallel-processing mechanism. The software can scale to tens of servers in some special scenarios. This solution uses a proprietary library that is license-based, requiring that each individual server have a single, dedicated license installed. The company has 200 licenses and is planning to run 200 server nodes concurrently at most.
      </h1>
      <h1 class="question">
        The company has requested the following features:
        <ul>
          <li>A mechanism to automate the use of the licenses at scale.</li>
          <li>Creation of a dashboard to use in the future to verify which licenses are available at any moment.</li>
        </ul>
      </h1>
      <h1 class="question">
        What is the MOST effective way to accomplish these requirements?
      </h1>
    
      <label for="optionA">A. Upload the licenses to a private Amazon S3 bucket. Create an AWS CloudFormation template with a Mappings section for the licenses. In the template, create an Auto Scaling group to launch the servers. In the user data script, acquire an available license from the Mappings section. Create an Auto Scaling lifecycle hook, then use it to update the mapping after the instance is terminated.</label><br>
    
      <label for="optionB">B. Upload the licenses to a private Amazon S3 bucket. Populate an Amazon SQS queue with the list of licenses stored in S3. Create an AWS CloudFormation template that uses an Auto Scaling group to launch the servers. In the user data script acquire an available license from SQS. Create an Auto Scaling lifecycle hook, then use it to put the license back in SQS after the instance is terminated.</label><br>
    
      <label for="optionC" class="correct-answer">C. Upload the licenses to an Amazon DynamoDB table. Create an AWS CloudFormation template that uses an Auto Scaling group to launch the servers. In the user data script, acquire an available license from the DynamoDB table. Create an Auto Scaling lifecycle hook, then use it to update the mapping after the instance is terminated . &#x2713;</label><br>
    
      <label for="optionD">D. Upload the licenses to an Amazon DynamoDB table. Create an AWS CLI script to launch the servers by using the parameter --count, with min:max instances to launch. In the user data script, acquire an available license from the DynamoDB table. Monitor each instance and, in case of failure, replace the instance, then manually update the DynamoDB table.</label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A DevOps Engineer administers an application that manages video files for a video production company. The application runs on Amazon EC2 instances behind an ELB Application Load Balancer. The instances run in an Auto Scaling group across multiple Availability Zones. Data is stored in an Amazon RDS PostgreSQL Multi-AZ DB instance, and the video files are stored in an Amazon S3 bucket. On a typical day, 50 GB of new video are added to the S3 bucket. The Engineer must implement a multi-region disaster recovery plan with the least data loss and the lowest recovery times. The current application infrastructure is already described using AWS CloudFormation.
      </h1>
      <h1 class="question">
        Which deployment option should the Engineer choose to meet the uptime and recovery objectives for the system?
      </h1>
    
      <label for="optionA">A. Launch the application from the CloudFormation template in the second region, which sets the capacity of the Auto Scaling group to 1.</label><br>
    
      <label for="optionB" class="correct-answer">
        B. Create an Amazon RDS read replica in the second region. In the second region, enable cross-region replication between the original S3 bucket and a new S3 bucket. To fail over, promote the read replica as master. Update the CloudFormation stack and increase the capacity of the Auto Scaling group. &#x2713;
      </label><br>
    
      <label for="optionC">C. Launch the application from the CloudFormation template in the second region, which sets the capacity of the Auto Scaling group to 1. Create a scheduled task to take daily Amazon RDS cross-region snapshots to the second region. In the second region, enable cross-region replication between the original S3 bucket and Amazon Glacier. In a disaster, launch a new application stack in the second region and restore the database from the most recent snapshot.</label><br>
    
      <label for="optionD">D. Launch the application from the CloudFormation template in the second region, which sets the capacity of the Auto Scaling group to 1. Use Amazon CloudWatch Events to schedule a nightly task to take a snapshot of the database, copy the snapshot to the second region, and replace the DB instance in the second region from the snapshot. In the second region, enable cross-region replication between the original S3 bucket and a new S3 bucket. To fail over, increase the capacity of the Auto Scaling group.</label><br>
    
      <label for="optionE">E. Use Amazon CloudWatch Events to schedule a nightly task to take a snapshot of the database and copy the snapshot to the second region. Create an AWS Lambda function that copies each object to a new S3 bucket in the second region in response to S3 event notifications. In the second region, launch the application from the CloudFormation template and restore the database from the most recent snapshot.</label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company has multiple AWS accounts in an organization in AWS Organizations that has all features enabled. The company’s DevOps administrator needs to improve security across all the company's AWS accounts. The administrator needs to identify the top users and roles in use across all accounts.
      </h1>
      <h1 class="question">
        Which solution will meet these requirements with the MOST operational efficiency?
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Create a new organization trail in AWS CloudTrail. Configure the trail to send log events to Amazon CloudWatch Logs. Create a CloudWatch Contributor Insights rule for the userIdentity.arn log field. View the results in CloudWatch Contributor Insights. &#x2713;
      </label><br>
    
      <label for="optionB">
        B. Create an unused access analysis for the organization by using AWS Identity and Access Management Access Analyzer. Review the analyzer results and determine if each finding has the intended level of permissions required for the workload.
      </label><br>
    
      <label for="optionC">
        C. Create a new organization trail in AWS CloudTrail. Create a table in Amazon Athena that uses partition projection. Load the Athena table with CloudTrail data. Query the Athena table to find the top users and roles.
      </label><br>
    
      <label for="optionD">
        D. Generate a Service access report for each account by using Organizations. From the results, pull the last accessed date and last accessed by account fields to find the top users and roles.
      </label><br>
    </form>

    <form class="question-form">
      <h1 class="question">
        A company manages 500 AWS accounts that are in an organization in AWS Organizations. The company discovers many unattached Amazon Elastic Block Store (Amazon EBS) volumes in all the accounts. The company wants to automatically tag the unattached EBS volumes for investigation.
      </h1>
      <h1 class="question">
        A DevOps engineer needs to deploy an AWS Lambda function to all the AWS accounts. The Lambda function must run every 30 minutes to tag all the EBS volumes that have been unattached for a period of 7 days or more.
      </h1>
      <h1 class="question">
        Which solution will meet these requirements in the MOST operationally efficient manner?
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Configure a delegated administrator account for the organization. Create an AWS CloudFormation template that contains the Lambda function and an Amazon EventBridge scheduled rule to invoke the Lambda function every 30 minutes. Use CloudFormation StackSets to deploy the CloudFormation template from the delegated administrator account to all the member accounts in the organization.. &#x2713;
      </label><br>
    
      <label for="optionB">
        B. Create a cross-account IAM role in the organization's member accounts. Attach the AWSLambda_FullAccess policy and the AWSCloudFormationFullAccess policy to the role. Create an AWS CloudFormation template that contains the Lambda function and an Amazon EventBridge scheduled rule to invoke the Lambda function every 30 minutes. Create a custom script in the organization’s management account that assumes the role and deploys the CloudFormation template to the member accounts.
      </label><br>
    
      <label for="optionC">
        C. AM role in the organization's member accounts. Attach the AWSLambda_FullAccess policy and the AWSCloudFormationFullAccess policy to the role. Create an AWS CloudFormation template that contains the Lambda function a 
      </label><br>
    
      <label for="optionD">
        D. Create a cross-account IAM role in the organization's member accounts. Attach the AmazonS3FullAccess policy and the AWSCodeDeployDeployerAccess policy to the role. Use AWS CodeDeploy to assume the role to deploy the Lambda function from the organization's management account. Configure an Amazon EventBridge scheduled rule in the member accounts to invoke the Lambda function every 30 minutes.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A DevOps engineer is planning to deploy a Ruby-based application to production. The application needs to interact with an Amazon RDS for MySQL database and should have automatic scaling and high availability. The stored data in the database is critical and should persist regardless of the state of the application stack.
      </h1>
      <h1 class="question">
        The DevOps engineer needs to set up an automated deployment strategy for the application with automatic rollbacks. The solution also must alert the application team when a deployment fails.
      </h1>
      <h1 class="question">
        Which combination of steps will meet these requirements? (Choose three.)
      </h1>
    
      <label for="optionA">
        A. Deploy the application on AWS Elastic Beanstalk. Deploy an Amazon RDS for MySQL DB instance as part of the Elastic Beanstalk configuration.
      </label><br>
    
      <label for="optionB" class="correct-answer">
        B. Deploy the application on AWS Elastic Beanstalk. Deploy a separate Amazon RDS for MySQL DB instance outside of Elastic Beanstalk. &#x2713;
      </label><br>
    
      <label for="optionC" class="correct-answer">
        C. Configure a notification email address that alerts the application team in the AWS Elastic Beanstalk configuration. &#x2713;
      </label><br>
    
      <label for="optionD">
        D. Configure an Amazon EventBridge (Amazon CloudWatch Events) rule to monitor AWS Health events. Use an Amazon Simple Notification Service (Amazon SNS) topic as a target to alert the application team.
      </label><br>
    
      <label for="optionE" class="correct-answer">
        E. Use the immutable deployment method to deploy new application versions. &#x2713;
      </label><br>
    
      <label for="optionF">
        F. Use the rolling deployment method to deploy new application versions.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        An ecommerce company is looking for ways to deploy an application on AWS that satisfies the following requirements:
      </h1>
      <ul>
        <li>Has a simple and automated application deployment process.</li>
        <li>Has minimal deployment costs while ensuring that at least half of the instances are available to receive end-user requests.</li>
        <li>If the application fails, an automated healing mechanism will replace the affected instances.</li>
      </ul>
      <h1 class="question">
        Which deployment strategy will meet these requirements?
      </h1>
    
      <label for="optionA">
        A. Create an AWS Elastic Beanstalk environment and configure it to use Auto Scaling and an Elastic Load Balancer. Use rolling deployments with a batch size of 50%.
      </label><br>
    
      <label for="optionB">
        B. Create an AWS OpsWorks stack. Configure the application layer to use rolling deployments as a deployment strategy. Add an Elastic Load Balancing layer. Enable auto healing on the application layer.
      </label><br>
    
      <label for="optionC" class="correct-answer">
        C. Use AWS CodeDeploy with Auto Scaling and an Elastic Load Balancer. Use the CodeDeployDefault.HalfAtATime deployment strategy. Enable an Elastic Load Balancing health check to report the status of the application, and set the Auto Scaling health check to ELB. &#x2713;
      </label><br>
    
      <label for="optionD">
        D. Use AWS CodeDeploy with Auto Scaling and an Elastic Load Balancer. Use a blue/green deployment strategy. Enable an Elastic Load Balancing health check to report the status of the application, and set the Auto Scaling health check to ELB.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company wants to ensure that their EC2 instances are secure. They want to be notified if any new vulnerabilities are discovered on their instances, and they also want an audit trail of all login activities on the instances.
      </h1>
      <h1 class="question">
        Which solution will meet these requirements?
      </h1>
    
      <label for="optionA">
        A. Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Amazon Kinesis Agent to capture system logs and deliver them to Amazon S3.
      </label><br>
    
      <label for="optionB">
        B. Use AWS Systems Manager to detect vulnerabilities on the EC2 instances. Install the Systems Manager Agent to capture system logs and view login activity in the CloudTrail console.
      </label><br>
    
      <label for="optionC">
        C. Configure Amazon CloudWatch to detect vulnerabilities on the EC2 instances. Install the AWS Config daemon to capture system logs and view them in the AWS Config console.
      </label><br>
    
      <label for="optionD" class="correct-answer">
        D. Configure Amazon Inspector to detect vulnerabilities on the EC2 instances. Install the Amazon CloudWatch Agent to capture system logs and record them via Amazon CloudWatch Logs. &#x2713;
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        An online retail company based in the United States plans to expand its operations to Europe and Asia in the next six months. Its product currently runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones. All data is stored in an Amazon Aurora database instance.
      </h1>
      <h1 class="question">
        When the product is deployed in multiple regions, the company wants a single product catalog across all regions, but for compliance purposes, its customer information and purchases must be kept in each region.
      </h1>
      <h1 class="question">
        How should the company meet these requirements with the LEAST amount of application changes?
      </h1>
    
      <label for="optionA">
        A. Use Amazon Redshift for the product catalog and Amazon DynamoDB tables for the customer information and purchases.
      </label><br>
    
      <label for="optionB" class="correct-answer">
        B. Use Amazon DynamoDB global tables for the product catalog and regional tables for the customer information and purchases. &#x2713;
      </label><br>
    
      <label for="optionC">
        C. Use Aurora with read replicas for the product catalog and additional local Aurora instances in each region for the customer information and purchases.
      </label><br>
    
      <label for="optionD">
        D. Use Aurora for the product catalog and Amazon DynamoDB global tables for the customer information and purchases.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company has a mobile application that makes HTTP API calls to an Application Load Balancer (ALB). The ALB routes requests to an AWS Lambda function. Many different versions of the application are in use at any given time, including versions that are in testing by a subset of users. The version of the application is defined in the user-agent header that is sent with all requests to the API.
      </h1>
      <h1 class="question">
        After a series of recent changes to the API, the company has observed issues with the application. The company needs to gather a metric for each API operation by response code for each version of the application that is in use. A DevOps engineer has modified the Lambda function to extract the API operation name, version information from the user-agent header and response code.
      </h1>
      <h1 class="question">
        Which additional set of actions should the DevOps engineer take to gather the required metrics?
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Modify the Lambda function to write the API operation name, response code, and version number as a log line to an Amazon CloudWatch Logs log group. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric. &#x2713;
      </label><br>
    
      <label for="optionB">
        B. Modify the Lambda function to write the API operation name, response code, and version number as a log line to an Amazon CloudWatch Logs log group. Configure a CloudWatch Logs Insights query to populate CloudWatch metrics from the log lines. Specify response code and application version as dimensions for the metric.
      </label><br>
    
      <label for="optionC">
        C. Configure the ALB access logs to write to an Amazon CloudWatch Logs log group. Modify the Lambda function to respond to the ALB with the API operation name, response code, and version number as response metadata. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric.
      </label><br>
    
      <label for="optionD">
        D. Configure AWS X-Ray integration on the Lambda function. Modify the Lambda function to create an X-Ray subsegment with the API operation name, response code, and version number. Configure X-Ray insights to extract an aggregated metric for each API operation name and to publish the metric to Amazon CloudWatch. Specify response code and application version as dimensions for the metric.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company has a mobile application that makes HTTP API calls to an Application Load Balancer (ALB). The ALB routes requests to an AWS Lambda function. Many different versions of the application are in use at any given time, including versions that are in testing by a subset of users. The version of the application is defined in the user-agent header that is sent with all requests to the API.
      </h1>
      <h1 class="question">
        After a series of recent changes to the API, the company has observed issues with the application. The company needs to gather a metric for each API operation by response code for each version of the application that is in use. A DevOps engineer has modified the Lambda function to extract the API operation name, version information from the user-agent header and response code.
      </h1>
      <h1 class="question">
        Which additional set of actions should the DevOps engineer take to gather the required metrics?
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Modify the Lambda function to write the API operation name, response code, and version number as a log line to an Amazon CloudWatch Logs log group. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric. &#x2713;
      </label><br>
    
      <label for="optionB">
        B. Modify the Lambda function to write the API operation name, response code, and version number as a log line to an Amazon CloudWatch Logs log group. Configure a CloudWatch Logs Insights query to populate CloudWatch metrics from the log lines. Specify response code and application version as dimensions for the metric.
      </label><br>
    
      <label for="optionC">
        C. Configure the ALB access logs to write to an Amazon CloudWatch Logs log group. Modify the Lambda function to respond to the ALB with the API operation name, response code, and version number as response metadata. Configure a CloudWatch Logs metric filter that increments a metric for each API operation name. Specify response code and application version as dimensions for the metric.
      </label><br>
    
      <label for="optionD">
        D. Configure AWS X-Ray integration on the Lambda function. Modify the Lambda function to create an X-Ray subsegment with the API operation name, response code, and version number. Configure X-Ray insights to extract an aggregated metric for each API operation name and to publish the metric to Amazon CloudWatch. Specify response code and application version as dimensions for the metric.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company uses AWS Organizations to manage its AWS accounts. The organization root has a child OU named Department. The Department OU has a child OU named Engineering. The default FullAWSAccess policy is attached to the root, the Department OU, and the Engineering OU.
      </h1>
      <h1 class="question">
        The company has many AWS accounts in the Engineering OU. Each account has an administrative IAM role with the AdministratorAccess IAM policy attached. The default FullAWSAccess policy is also attached to each account.
      </h1>
      <h1 class="question">
        A DevOps engineer plans to remove the FullAWSAccess policy from the Department OU. The DevOps engineer will replace the policy with a policy that contains an Allow statement for all Amazon EC2 API operations.
      </h1>
      <h1 class="question">
        What will happen to the permissions of the administrative IAM roles as a result of this change?
      </h1>
    
      <label for="optionA">
        A. All API actions on all resources will be allowed.
      </label><br>
    
      <label for="optionB" class="correct-answer">
        B. All API actions on EC2 resources will be allowed. All other API actions will be denied. &#x2713;
      </label><br>
    
      <label for="optionC">
        C. All API actions on all resources will be denied.
      </label><br>
    
      <label for="optionD">
        D. All API actions on EC2 resources will be denied. All other API actions will be allowed.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company wants to deploy a workload on several hundred Amazon EC2 instances. The company will provision the EC2 instances in an Auto Scaling group by using a launch template.
      </h1>
      <h1 class="question">
        The workload will pull files from an Amazon S3 bucket, process the data, and put the results into a different S3 bucket. The EC2 instances must have least-privilege permissions and must use temporary security credentials.
      </h1>
      <h1 class="question">
        Which combination of steps will meet these requirements? (Select TWO.)
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Create an IAM role that has the appropriate permissions for S3 buckets. Add the IAM role to an instance profile. &#x2713;
      </label><br>
    
      <label for="optionB" class="correct-answer">
        B. Update the launch template to include the IAM instance profile. &#x2713;
      </label><br>
    
      <label for="optionC">
        C. Create an IAM user that has the appropriate permissions for Amazon S3. Generate a secret key and token.
      </label><br>
    
      <label for="optionD">
        D. Create a trust anchor and profile. Attach the IAM role to the profile.
      </label><br>
    
      <label for="optionE">
        E. Update the launch template. Modify the user data to use the new secret key and token.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company is using an Amazon Aurora cluster as the data store for its application. The Aurora cluster is configured with a single DB instance. The application performs read and write operations on the database by using the cluster's instance endpoint.
      </h1>
      <h1 class="question">
        The company has scheduled an update to be applied to the cluster during an upcoming maintenance window. The cluster must remain available with the least possible interruption during the maintenance window.
      </h1>
      <h1 class="question">
        What should a DevOps engineer do to meet these requirements?
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Add a reader instance to the Aurora cluster. Update the application to use the Aurora cluster endpoint for write operations. Update the Aurora cluster's reader endpoint for reads. &#x2713;
      </label><br>
    
      <label for="optionB">
        B. Add a reader instance to the Aurora cluster. Create a custom ANY endpoint for the cluster. Update the application to use the Aurora cluster's custom ANY endpoint for read and write operations.
      </label><br>
    
      <label for="optionC">
        C. Turn on the Multi-AZ option on the Aurora cluster. Update the application to use the Aurora cluster endpoint for write operations. Update the Aurora cluster's reader endpoint for reads.
      </label><br>
    
      <label for="optionD">
        D. Turn on the Multi-AZ option on the Aurora cluster. Create a custom ANY endpoint for the cluster. Update the application to use the Aurora cluster's custom ANY endpoint for read and write operations.
      </label><br>
    </form>

    
    <form class="question-form">
      <h1 class="question">
        A DevOps engineer has created an AWS CloudFormation template that deploys an application on Amazon EC2 instances. The EC2 instances run Amazon Linux. The application is deployed to the EC2 instances by using shell scripts that contain user data. The EC2 instances have an IAM instance profile that has an IAM role with the AmazonSSMManagedInstanceCore managed policy attached.
      </h1>
      <h1 class="question">
        The DevOps engineer has modified the user data in the CloudFormation template to install a new version of the application. The engineer has also applied the stack update. However, the application was not updated on the running EC2 instances. The engineer needs to ensure that the changes to the application are installed on the running EC2 instances.
      </h1>
      <h1 class="question">
        Which combination of steps will meet these requirements? (Choose two.)
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Refactor the user data command to use an AWS Systems Manager document (SSM document). Use Systems Manager State Manager to create an association between the SSM document and the EC2 instances. &#x2713;
      </label><br>
    
      <label for="optionB" class="correct-answer">
        B. Refactor the user data commands to use the cfn-init helper script. Update the user data to install and configure the cfn-hup and cfn-init helper scripts to monitor and apply the metadata changes. &#x2713;
      </label><br>
    
      <label for="optionC">
        C. Configure an EC2 launch template for the EC2 instances. Create a new EC2 Auto Scaling group. Associate the Auto Scaling group with the EC2 launch template. Use the AutoScalingScheduledAction update policy for the Auto Scaling group.
      </label><br>
    
      <label for="optionD">
        D. Refactor the user data commands to use an AWS Systems Manager document (SSM document). Add an AWS CLI command in the user data to use Systems Manager Run Command to apply the SSM document to the EC2 instances.
      </label><br>
    
      <label for="optionE">
        E. commands to use an AWS Systems Manager document (SSM document). Add an AWS CLI command in the user data to use Systems Manager Run Command to apply the SSM document to the EC2 i.
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company uses several AWS CloudFormation stacks to handle the deployment of a suite of applications. The leader of the company's application development team notices that the stack deployments fail with permission errors when some team members try to deploy the stacks. However, other team members can deploy the stacks successfully.
      </h1>
      <h1 class="question">
        The team members access the account by assuming a role that has a specific set of permissions that are necessary for the job responsibilities of the team members. All team members have permissions to perform operations on the stacks.
      </h1>
      <h1 class="question">
        Which combination of steps will ensure consistent deployment of the stacks MOST securely? (Choose three.)
      </h1>
    
      <label for="optionA" class="correct-answer">
        A. Create a service role that has a composite principal that contains each service that needs the necessary permissions. Configure the role to allow the sts:AssumeRole action. &#x2713;
      </label><br>
    
      <label for="optionB" class="correct-answer">
        B. Create a service role that has cloudformation.amazonaws.com as the service principal. Configure the role to allow the sts:AssumeRole action. &#x2713;
      </label><br>
    
      <label for="optionC">
        C. For each required set of permissions, add a separate policy to the role to allow those permissions. Add the ARN of each CloudFormation stack in the resource field of each policy.
      </label><br>
    
      <label for="optionD">
        D. For each required set of permissions, add a separate policy to the role to allow those permissions. Add the ARN of each service that needs the permissions in the resource field of the corresponding policy.
      </label><br>
    
      <label for="optionE" class="correct-answer">
        E. Update each stack to use the service role. &#x2713;
      </label><br>
    
      <label for="optionF" class="correct-answer">
        F. Add a policy to each member role to allow the iam:PassRole action. Set the policy's resource field to the ARN of the service role. &#x2713;
      </label><br>
    </form>
    <form class="question-form">
      <h1 class="question">
        A company wants to migrate its content sharing web application hosted on Amazon EC2 to a serverless architecture. The company currently deploys changes to its application by creating a new Auto Scaling group of EC2 instances and a new Elastic Load Balancer, and then shifting the traffic away using an Amazon Route 53 weighted routing policy.
      </h1>
      <h1 class="question">
        For its new serverless application, the company is planning to use Amazon API Gateway and AWS Lambda. The company will need to update its deployment processes to work with the new application. It will also need to retain the ability to test new features on a small number of users before rolling the features out to the entire user base.
      </h1>
      <h1 class="question">
        Which deployment strategy will meet these requirements?
      </h1>
    
      <label for="optionA">
        A. Use AWS CDK to deploy API Gateway and Lambda functions. When code needs to be changed, update the AWS CloudFormation stack and deploy the new version of the APIs and Lambda functions. Use a Route 53 failover routing policy for the canary release strategy.
      </label><br>
    
      <label for="optionB" class="correct-answer">
        B. Use AWS CloudFormation to deploy API Gateway and Lambda functions using Lambda function versions. When code needs to be changed, update the CloudFormation stack with the new Lambda code and update the API versions using a canary release strategy. Promote the new version when testing is complete. &#x2713;
      </label><br>
    
      <label for="optionC">
        C. Use AWS Elastic Beanstalk to deploy API Gateway and Lambda functions. When code needs to be changed, deploy a new version of the API and Lambda functions. Shift traffic gradually using an Elastic Beanstalk blue/green deployment.
      </label><br>
    
      <label for="optionD">
        D. Use AWS OpsWorks to deploy API Gateway in the service layer and Lambda functions in a custom layer. When code needs to be changed, use OpsWorks to perform a blue/green deployment and shift traffic gradually.
      </label><br>
    </form>
    <form class="question-form">
  <h1 class="question">
    A company needs to architect a hybrid DNS solution. This solution will use an Amazon Route 53 private hosted zone for the domain <code>cloud.example.com</code> for the resources stored within VPCs.
  </h1>
  <h1 class="question">
    The company has the following DNS resolution requirements:
    <ul>
      <li>On-premises systems should be able to resolve and connect to <code>cloud.example.com</code>.</li>
      <li>All VPCs should be able to resolve <code>cloud.example.com</code>.</li>
      <li>There is already an AWS Direct Connect connection between the on-premises corporate network and AWS Transit Gateway.</li>
    </ul>
  </h1>
  <h1 class="question">
    Which architecture should the company use to meet these requirements with the <strong>HIGHEST performance</strong>?
  </h1>

  <label for="optionA" class="correct-answer">
    A. Associate the private hosted zone to all the VPCs. Create a Route 53 inbound resolver in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for <code>cloud.example.com</code> that point to the inbound resolver. &#x2713;
  </label><br>

  <label for="optionB">
    B. Associate the private hosted zone to all the VPCs. Deploy an Amazon EC2 conditional forwarder in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for <code>cloud.example.com</code> that point to the conditional forwarder.
  </label><br>

  <label for="optionC">
    C. Associate the private hosted zone to the shared services VPC. Create a Route 53 outbound resolver in the shared services VPC. Attach all VPCs to the transit gateway and create forwarding rules in the on-premises DNS server for <code>cloud.example.com</code> that point to the outbound resolver.
  </label><br>

  <label for="optionD">
    D. Associate the private hosted zone to the shared services VPC. Create a Route 53 inbound resolver in the shared services VPC. Attach the shared services VPC to the transit gateway and create forwarding rules in the on-premises DNS server for <code>cloud.example.com</code> that point to the inbound resolver.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company is providing weather data over a REST-based API to several customers. The API is hosted by Amazon API Gateway and is integrated with different AWS Lambda functions for each API operation.
  </h1>
  <h1 class="question">
    The company uses Amazon Route 53 for DNS and has created a resource record of <code>weather.example.com</code>. The company stores data for the API in Amazon DynamoDB tables.
  </h1>
  <h1 class="question">
    The company needs a solution that will give the API the ability to fail over to a different AWS Region.
  </h1>
  <h1 class="question">
    Which solution will meet these requirements?
  </h1>

  <label for="optionA">
    A. Deploy a new set of Lambda functions in a new Region. Update the API Gateway API to use an edge-optimized API endpoint with Lambda functions from both Regions as targets. Convert the DynamoDB tables to global tables.
  </label><br>

  <label for="optionB">
    B. Deploy a new API Gateway API and Lambda functions in another Region. Change the Route 53 DNS record to a multivalue answer. Add both API Gateway APIs to the answer. Enable target health monitoring. Convert the DynamoDB tables to global tables.
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Deploy a new API Gateway API and Lambda functions in another Region. Change the Route 53 DNS record to a failover record. Enable target health monitoring. Convert the DynamoDB tables to global tables. &#x2713;
  </label><br>

  <label for="optionD">
    D. Deploy a new API Gateway API in a new Region. Change the Lambda functions to global functions. Change the Route 53 DNS record to a multivalue answer. Add both API Gateway APIs to the answer. Enable target health monitoring. Convert the DynamoDB tables to global tables.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company uses AWS Organizations with a single OU named <strong>Production</strong> to manage multiple accounts. All accounts are members of the Production OU. Administrators use deny list SCPs in the root of the organization to manage access to restricted services.
  </h1>
  <h1 class="question">
    The company recently acquired a new business unit and invited the new unit’s existing AWS account to the organization. Once onboarded, the administrators of the new business unit discovered that they are not able to update existing AWS Config rules to meet the company’s policies.
  </h1>
  <h1 class="question">
    Which option will allow administrators to make changes and continue to enforce the current policies without introducing additional long-term maintenance?
  </h1>

  <label for="optionA">
    A. Remove the organization’s root SCPs that limit access to AWS Config. Create AWS Service Catalog products for the company’s standard AWS Config rules and deploy them throughout the organization, including the new account.
  </label><br>

  <label for="optionB" class="correct-answer">
    B. Create a temporary OU named Onboarding for the new account. Apply an SCP to the Onboarding OU to allow AWS Config actions. Move the organization’s root SCP to the Production OU. Move the new account to the Production OU when adjustments to AWS Config are complete.;
  </label><br>

  <label for="optionC">
    C. Convert the organization’s root SCPs from deny list SCPs to allow list SCPs to allow the required services only. Temporarily apply an SCP to the organization’s root that allows AWS Config actions for principals only in the new account.
  </label><br>

  <label for="optionD">
    D. Create oot SCPs from deny list SCPs to allow list SCPs to allow the required services only. Temporarily apply an SCP to the organization’s root that allows AWS Config actions for principals only in the new ac complete.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company is running a two-tier web-based application in an on-premises data center. The application layer consists of a single server running a stateful application. The application connects to a PostgreSQL database running on a separate server.
  </h1>
  <h1 class="question">
    The application’s user base is expected to grow significantly, so the company is migrating the application and database to AWS. The solution will use Amazon Aurora PostgreSQL, Amazon EC2 Auto Scaling, and Elastic Load Balancing.
  </h1>
  <h1 class="question">
    Which solution will provide a consistent user experience that will allow the application and database tiers to scale?
  </h1>

  <label for="optionA">
    A. Enable Aurora Auto Scaling for Aurora Replicas. Use a Network Load Balancer with the least outstanding requests routing algorithm and sticky sessions enabled.
  </label><br>

  <label for="optionB">
    B. Enable Aurora Auto Scaling for Aurora writers. Use an Application Load Balancer with the round robin routing algorithm and sticky sessions enabled.
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Enable Aurora Auto Scaling for Aurora Replicas. Use an Application Load Balancer with the round robin routing and sticky sessions enabled. &#x2713;
  </label><br>

  <label for="optionD">
    D. Enable Aurora Scaling for Aurora writers. Use a Network Load Balancer with the least outstanding requests routing algorithm and sticky sessions enabled.
  </label><br>
</form>


<form class="question-form">
  <h1 class="question">
    A company uses a service to collect metadata from applications that the company hosts on premises. Consumer devices such as TVs and internet radios access the applications. Many older devices do not support certain HTTP headers and exhibit errors when these headers are present in responses.
  </h1>
  <h1 class="question">
    The company has configured an on-premises load balancer to remove the unsupported headers from responses sent to older devices, which the company identified by the <code>User-Agent</code> headers.
  </h1>
  <h1 class="question">
    The company wants to migrate the service to AWS, adopt serverless technologies, and retain the ability to support the older devices. The company has already migrated the applications into a set of AWS Lambda functions.
  </h1>
  <h1 class="question">
    Which solution will meet these requirements?
  </h1>

  <label for="optionA">
    A. ateway HTTP API for the metadata service. Configure API Gateway to invoke the correct Lambda function for each type of request. Create a response mapping template to remove the problr.
  </label><br>

  <label for="optionB">
    B. Create an Amazon API Gateway REST API for the metadata service. Configure API Gateway to invoke the correct Lambda function for each type of request. Modify the default gateway responses to remove the problematic headers based on the value of the <code>User-Agent</code> header.
  </label><br>

  <label for="optionC">
    C. Create an Amazon API Gateway HTTP API for the metadata service. Configure API Gateway to invoke the correct Lambda function for each type of request. Create a response mapping template to remove the problematic headers based on the value of the <code>User-Agent</code>. Associate the response data mapping with the HTTP API.
  </label><br>

  <label for="optionD" class="correct-answer">
    D. Create an Amazon CloudFront distribution for the metadata service. Create an Application Load Balancer (ALB). Configure the CloudFront distribution to forward requests to the ALB. Configure the ALB to invoke the correct Lambda function for each type of request. Create a CloudFront function to remove the problematic headers based on the value of the <code>User-Agent</code> header.;
  </label><br>
</form>

<form class="question-form">
  <h1 class="question">
    A retail company needs to provide a series of data files to another company, which is its business partner. These files are saved in an Amazon S3 bucket under Account A, which belongs to the retail company.
  </h1>
  <h1 class="question">
    The business partner company wants one of its IAM users, <code>User_DataProcessor</code>, to access the files from its own AWS account (Account B).
  </h1>
  <h1 class="question">
    Which combination of steps must the companies take so that <code>User_DataProcessor</code> can access the S3 bucket successfully? <strong>(Choose two.)</strong>
  </h1>

  <label for="optionA">
    A. Turn on the cross-origin resource sharing (CORS) feature for the S3 bucket in Account A.
  </label><br>

  <label for="optionB" class="correct-answer">
    B. In Account A, set the S3 bucket policy to the following:<br>
    <pre>{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::AccountB-ID:user/User_DataProcessor"
      },
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::bucket-name/*"
    }
  ]
}</pre> &#x2713;
  </label><br>

  <label for="optionC">
    C. In Account A, set the S3 bucket policy to the following:<br>
    <pre>{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Deny",
      "Principal": "*",
      "Action": "s3:*",
      "Resource": "*"
    }
  ]
}</pre>
  </label><br>

  <label for="optionD" class="correct-answer">
    D. In Account B, set the permissions of <code>User_DataProcessor</code> to the following:<br>
    <pre>{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::bucket-name/*"
    }
  ]
}</pre> &#x2713;
  </label><br>

  <label for="optionE">
    E. In Account B, set the permissions of <code>User_DataProcessor</code> to the following:<br>
    <pre>{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Deny",
      "Action": "s3:*",
      "Resource": "*"
    }
  ]
}</pre>
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company is running a traditional web application on Amazon EC2 instances. The company needs to refactor the application as microservices that run on containers. Separate versions of the application exist in two distinct environments: <strong>production</strong> and <strong>testing</strong>.
  </h1>
  <h1 class="question">
    Load for the application is variable, but the minimum load and the maximum load are known. A solutions architect needs to design the updated application with a <strong>serverless architecture</strong> that <strong>minimizes operational complexity</strong>.
  </h1>
  <h1 class="question">
    Which solution will meet these requirements <strong>MOST cost-effectively</strong>?
  </h1>

  <label for="optionA" class="correct-answer">
    A.  Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Container Service (Amazon ECS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the ECS clusters.
  </label><br>

  <label for="optionB">
    B. Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Kubernetes Service (Amazon EKS) clusters with the Fargate launch type to handle
  </label><br>

  <label for="optionC">
    C. Upload the container images to Amazon Elastic Container Registry (Amazon ECR). Configure two auto scaled Amazon Elastic Kubernetes Service (Amazon EKS) clusters with the Fargate launch type to handle the expected load. Deploy tasks from the ECR images. Configure two separate Application Load Balancers to direct traffic to the EKS clusters.
  </label><br>

  <label for="optionD">
    D. Upload the container images to AWS Elastic Beanstalk. In Elastic Beanstalk, create separate environments and deployments for production and testing. Configure two separate Application Load Balancers to direct traffic to the Elastic Beanstalk deployments.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company has a multi-tier web application that runs on a fleet of Amazon EC2 instances behind an Application Load Balancer (ALB). The instances are in an Auto Scaling group. The ALB and the Auto Scaling group are replicated in a backup AWS Region. The minimum and maximum values for the Auto Scaling group in the backup Region are set to zero.
  </h1>
  <h1 class="question">
    An Amazon RDS Multi-AZ DB instance stores the application's data. The DB instance has a read replica in the backup Region. The application presents an endpoint to end users by using an Amazon Route 53 record.
  </h1>
  <h1 class="question">
    The company needs to reduce its <strong>RTO to less than 15 minutes</strong> by giving the application the ability to <strong>automatically fail over</strong> to the backup Region. The company does <strong>not</strong> have the budget for an active-active strategy.
  </h1>
  <h1 class="question">
    What should a solutions architect recommend to meet these requirements?
  </h1>

  <label for="optionA">
    A. Reconfigure the application’s Route 53 record with a latency-based routing policy that load balances traffic between the two ALBs. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Create an Amazon CloudWatch alarm that is based on the HTTPCode_Target_5XX_Count metric for the ALB in the primary Region. Configure the CloudWatch alarm to invoke the Lambda function.
  </label><br>

  <label for="optionB" class="correct-answer">
    B. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Configure Route 53 with a health check that monitors the web application and sends an Amazon Simple Notification Service (Amazon SNS) notification to the Lambda function when the health check status is unhealthy. Update the application’s Route 53 record with a failover policy that routes traffic to the ALB in the backup Region when a health check failure occurs. &#x2713;
  </label><br>

  <label for="optionC">
    C. Configure the Auto Scaling group in the backup Region to have the same values as the Auto Scaling group in the primary Region. Reconfigure the application’s Route 53 record with a latency-based routing policy that load balances traffic between the two ALBs. Remove the read replica. Replace the read replica with a standalone RDS DB instance. Configure Cross-Region Replication between the RDS DB instances by using snapshots and Amazon S3.
  </label><br>

  <label for="optionD">
    D. Configure an endpoint in AWS Global Accelerator with the two ALBs as equal weighted targets. Create an AWS Lambda function in the backup Region to promote the read replica and modify the Auto Scaling group values. Create an Amazon CloudWatch alarm that is based on the HTTPCode_Target_5XX_Count metric for the ALB in the primary Region. Configure the CloudWatch alarm to invoke the Lambda function.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company is hosting a critical application on a single Amazon EC2 instance. The application uses an Amazon ElastiCache for Redis single-node cluster for an in-memory data store. The application uses an Amazon RDS for MariaDB DB instance for a relational database. For the application to function, each piece of the infrastructure must be healthy and in an active state.
  </h1>
  <h1 class="question">
    A solutions architect needs to improve the application's architecture so that the infrastructure can automatically recover from failure with the least possible downtime.
  </h1>
  <h1 class="question">
    Which combination of steps will meet these requirements? (Choose <strong>three</strong>.)
  </h1>

  <label for="optionA" class="correct-answer">
    A. Use an Elastic Load Balancer to distribute traffic across multiple EC2 instances. Ensure that the EC2 instances are part of an Auto Scaling group that has a minimum capacity of two instances. &#x2713;
  </label><br>

  <label for="optionB">
    B. Use an Elastic Load Balancer to distribute traffic across multiple EC2 instances. Ensure that the EC2 instances are configured in unlimited mode.
  </label><br>

  <label for="optionC">
    C. Modify the DB instance to create a read replica in the same Availability Zone. Promote the read replica to be the primary DB instance in failure scenarios.
  </label><br>

  <label for="optionD" class="correct-answer">
    D. Modify the DB instance to create a Multi-AZ deployment that extends across two Availability Zones. &#x2713;
  </label><br>

  <label for="optionE">
    E. Create a replication group for the ElastiCache for Redis cluster. Configure the cluster to use an Auto Scaling group that has a minimum capacity of two instances.
  </label><br>

  <label for="optionF" class="correct-answer">
    F. Create a replication group for the ElastiCache for Redis cluster. Enable Multi-AZ on the cluster. &#x2713;
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A retail company is operating its ecommerce application on AWS. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The company uses an Amazon RDS DB instance as the database backend. Amazon CloudFront is configured with one origin that points to the ALB. Static content is cached. Amazon Route 53 is used to host all public zones.
  </h1>
  <h1 class="question">
    After an update of the application, the ALB occasionally returns a 502 status code (Bad Gateway) error. The root cause is malformed HTTP headers that are returned to the ALB. The webpage returns successfully when a solutions architect reloads the webpage immediately after the error occurs.
  </h1>
  <h1 class="question">
    While the company is working on the problem, the solutions architect needs to provide a custom error page instead of the standard ALB error page to visitors.
  </h1>
  <h1 class="question">
    Which combination of steps will meet this requirement with the <strong>LEAST amount of operational overhead</strong>? (Choose <strong>two</strong>.)
  </h1>

  <label for="optionA" class="correct-answer">
    A. Create an Amazon S3 bucket. Configure the S3 bucket to host a static webpage. Upload the custom error pages to Amazon S3. &#x2713;
  </label><br>

  <label for="optionB">
    B. Create an Amazon CloudWatch alarm to invoke an AWS Lambda function if the ALB health check response Target.FailedHealthChecks is greater than 0. Configure the Lambda function to modify the forwarding rule at the ALB to point to a publicly accessible web server.
  </label><br>

  <label for="optionC">
    C. Modify the existing Amazon Route 53 records by adding health checks. Configure a fallback target if the health check fails. Modify DNS records to point to a publicly accessible webpage.
  </label><br>

  <label for="optionD">
    D. Create an Amazon CloudWatch alarm to invoke an AWS Lambda function if the ALB health check response Elb.InternalError is greater than 0. Configure the Lambda function to modify the forwarding rule at the ALB to point to a public accessible web server.
  </label><br>

  <label for="optionE" class="correct-answer">
    E. Add a custom error response by configuring a CloudFront custom error page. Modify DNS records to point to a publicly accessible web page. &#x2713;
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A retail company is operating its ecommerce application on AWS. The application runs on Amazon EC2 instances behind an Application Load Balancer (ALB). The company uses an Amazon RDS DB instance as the database backend. Amazon CloudFront is configured with one origin that points to the ALB. Static content is cached. Amazon Route 53 is used to host all public zones.
  </h1>
  <h1 class="question">
    After an update of the application, the ALB occasionally returns a 502 status code (Bad Gateway) error. The root cause is malformed HTTP headers that are returned to the ALB. The webpage returns successfully when a solutions architect reloads the webpage immediately after the error occurs.
  </h1>
  <h1 class="question">
    While the company is working on the problem, the solutions architect needs to provide a custom error page instead of the standard ALB error page to visitors.
  </h1>
  <h1 class="question">
    Which combination of steps will meet this requirement with the <strong>LEAST amount of operational overhead</strong>? (Choose <strong>two</strong>.)
  </h1>

  <label for="optionA" class="correct-answer">
    A. Create an Amazon S3 bucket. Configure the S3 bucket to host a static webpage. Upload the custom error pages to Amazon S3. &#x2713;
  </label><br>

  <label for="optionB">
    B. Create an Amazon CloudWatch alarm to invoke an AWS Lambda function if the ALB health check response Target.FailedHealthChecks is greater than 0. Configure the Lambda function to modify the forwarding rule at the ALB to point to a publicly accessible web server.
  </label><br>

  <label for="optionC">
    C. Modify the existing Amazon Route 53 records by adding health checks. Configure a fallback target if the health check fails. Modify DNS records to point to a publicly accessible webpage.
  </label><br>

  <label for="optionD">
    D. Create an Amazon CloudWatch alarm to invoke an AWS Lambda function if the ALB health check response Elb.InternalError is greater than 0. Configure the Lambda function to modify the forwarding rule at the ALB to point to a publicly accessible web server.
  </label><br>

  <label for="optionE" class="correct-answer">
    E. Add a custom error response by configuring a CloudFront custom error page. Modify DNS records to point to a publicly accessible web page. &#x2713;
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company hosts a three-tier ecommerce application on a fleet of Amazon EC2 instances. The instances run in an Auto Scaling group behind an Application Load Balancer (ALB). All ecommerce data is stored in an Amazon RDS for MariaDB Multi-AZ DB instance.
  </h1>
  <h1 class="question">
    The company wants to optimize customer session management during transactions. The application must store session data durably.
  </h1>
  <h1 class="question">
    Which solutions will meet these requirements? (Choose <strong>two</strong>.)
  </h1>

  <label for="optionA">
    A. Turn on the sticky sessions feature (session affinity) on the ALB.
  </label><br>

  <label for="optionB" class="correct-answer">
    B. Use an Amazon DynamoDB table to store customer session information. &#x2713;
  </label><br>

  <label for="optionC">
    C. Deploy an Amazon Cognito user pool to manage user session information.
  </label><br>

  <label for="optionD" class="correct-answer">
    D. Deploy an Amazon ElastiCache for Redis cluster to store customer session information. &#x2713;
  </label><br>

  <label for="optionE">
    E. Use AWS Systems Manager Application Manager in the application to manage user session information.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company has a few AWS accounts for development and wants to move its production application to AWS.
  </h1>
  <h1 class="question">
    The company needs to enforce Amazon Elastic Block Store (Amazon EBS) encryption at rest in current production accounts and future production accounts only. The company needs a solution that includes built-in blueprints and guardrails.
  </h1>
  <h1 class="question">
    Which combination of steps will meet these requirements? (Choose <strong>three</strong>.)
  </h1>

  <label for="optionA">
    A. Use AWS CloudFormation StackSets to deploy AWS Config rules on production accounts.
  </label><br>

  <label for="optionB">
    B. Create a new AWS Control Tower landing zone in an existing developer account. Create OUs for accounts. Add production and development accounts to production and development OUs, respectively.
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Create a new AWS Control Tower landing zone in the company's management account. Add production and development accounts to production and development OUs, respectively. &#x2713;
  </label><br>

  <label for="optionD" class="correct-answer">
    D. Invite existing accounts to join the organization in AWS Organizations. Create SCPs to ensure compliance. &#x2713;
  </label><br>

  <label for="optionE">
    E. Create a guardrail from the management account to detect EBS encryption.
  </label><br>

  <label for="optionF" class="correct-answer">
    F. Create a guardrail for the production OU to detect EBS encryption. &#x2713;
  </label><br>
</form>


<form class="question-form">
  <h1 class="question">
    A company has developed a web application. The company is hosting the application on a group of Amazon EC2 instances behind an Application Load Balancer.
  </h1>
  <h1 class="question">
    The company wants to improve the security posture of the application and plans to use AWS WAF web ACLs. The solution must not adversely affect legitimate traffic to the application.
  </h1>
  <h1 class="question">
    How should a solutions architect configure the web ACLs to meet these requirements?
  </h1>

  <label for="optionA" class="correct-answer">
    A. Set the action of the web ACL rules to Count. Enable AWS WAF logging. Analyze the requests for false positives. Modify the rules to avoid any false positives. Over time, change the action of the web ACL rules from Count to Block. &#x2713;
  </label><br>

  <label for="optionB">
    B. Use only rate-based rules in the web ACLs, and set the throttle limit as high as possible. Temporarily block all requests that exceed the limit. Define nested rules to narrow the scope of the rate tracking.
  </label><br>

  <label for="optionC">
    C. Set the action of the web ACL rules to Block. Use only AWS managed rule groups in the web ACLs. Evaluate the rule groups by using Amazon CloudWatch metrics with AWS WAF sampled requests or AWS WAF logs.
  </label><br>

  <label for="optionD">
    D. Use only custom rule groups in the web ACLs, and set the action to Allow. Enable AWS WAF logging. Analyze the requests for false positives. Modify the rules to avoid any false positives. Over time, change the action of the web ACL rules from Allow to Block.
  </label><br>
</form>

<form class="question-form">
  <h1 class="question">
    Your company policies require encryption of sensitive data at rest.
  </h1>
  <h1 class="question">
    You are considering the possible options for protecting data while storing it at rest on an EBS data volume, attached to an EC2 instance.
  </h1>
  <h1 class="question">
    Which of these options would allow you to encrypt your data at rest? (Choose three.)
  </h1>

  <label for="optionA" class="correct-answer">
    A. Implement third party volume encryption tools &#x2713;
  </label><br>

  <label for="optionB">
    B. Implement SSL/TLS for all services running on the server
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Encrypt data inside your applications before storing it on EBS &#x2713;
  </label><br>

  <label for="optionD" class="correct-answer">
    D. Encrypt data using native data encryption drivers at the file system level &#x2713;
  </label><br>

  <label for="optionE">
    E. Do nothing as EBS volumes are encrypted by default
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A customer is deploying an SSL-enabled web application to AWS and would like to implement a separation of roles between the EC2 service administrators that are entitled to log in to instances and make API calls, and the security officers who will maintain and have exclusive access to the application's X.509 certificate that contains the private key.
  </h1>

  <label for="optionA">
    A. Upload the certificate on an S3 bucket owned by the security officers and accessible only by EC2 Role of the web servers.
  </label><br>

  <label for="optionB">
    B. Configure the web servers to retrieve the certificate upon boot from a CloudHSM managed by the security officers.
  </label><br>

  <label for="optionC">
    C. Configure system permissions on the web servers to restrict access to the certificate only to the authority security officers.
  </label><br>

  <label for="optionD" class="correct-answer">
    D. Configure IAM policies authorizing access to the certificate store only to the security officers and terminate SSL on an ELB. &#x2713;
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    You have recently joined a startup company building sensors to measure street noise and air quality in urban areas.
  </h1>
  <h1 class="question">
    The company has been running a pilot deployment of around 100 sensors for 3 months. Each sensor uploads 1KB of sensor data every minute to a backend hosted on AWS.
  </h1>
  <h1 class="question">
    During the pilot, you measured a peak of 10 IOPS on the database, and you stored an average of 3GB of sensor data per month in the database.
  </h1>
  <h1 class="question">
    The current deployment consists of a load-balanced auto-scaled ingestion layer using EC2 instances and a PostgreSQL RDS database with 500GB standard storage.
  </h1>
  <h1 class="question">
    The pilot is considered a success and your CEO has managed to get the attention of some potential investors. The business plan requires a deployment of at least 100K sensors, which needs to be supported by the backend. You also need to store sensor data for at least two years to be able to compare year-over-year improvements.
  </h1>
  <h1 class="question">
    To secure funding, you have to make sure that the platform meets these requirements and leaves room for further scaling.
    <br><br>
    Which setup will meet the requirements?
  </h1>

  <label for="optionA">
    A. Add an SQS queue to the ingestion layer to buffer writes to the RDS instance.
  </label><br>

  <label for="optionB" class="correct-answer">
    B. Ingest data into a DynamoDB table and move old data to a Redshift cluster. &#x2713;
  </label><br>

  <label for="optionC">
    C. Replace the RDS instance with a 6-node Redshift cluster with 96TB of storage.
  </label><br>

  <label for="optionD">
    D. Keep the current architecture but upgrade RDS storage to 3TB and 10K provisioned IOPS.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A web company is looking to implement an intrusion detection and prevention system into their deployed VPC.
  </h1>
  <h1 class="question">
    This platform should have the ability to scale to thousands of instances running inside of the VPC.
  </h1>
  <h1 class="question">
    How should they architect their solution to achieve these goals?
  </h1>

  <label for="optionA">
    A. Configure an instance with monitoring software and the elastic network interface (ENI) set to promiscuous mode packet sniffing to see all traffic across the VPC.
  </label><br>

  <label for="optionB">
    B. Create a second VPC and route all traffic from the primary application VPC through the second VPC where the scalable virtualized IDS/IPS platform resides.
  </label><br>

  <label for="optionC">
    C. Configure servers running in the VPC using the host-based 'route' commands to send all traffic through the platform to a scalable virtualized IDS/IPS.
  </label><br>

  <label for="optionD" class="correct-answer">
    D. Configure each host with an agent that collects all network traffic and sends that traffic to the IDS/IPS platform for inspection. &#x2713;
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company is storing data on Amazon Simple Storage Service (S3). The company's security policy mandates that data is encrypted at rest.
  </h1>
  <h1 class="question">
    Which of the following methods can achieve this? (Choose three.)
  </h1>

  <label for="optionA" class="correct-answer">
    A. Use Amazon S3 server-side encryption with AWS Key Management Service managed keys. &#x2713;
  </label><br>

  <label for="optionB" class="correct-answer">
    B. Use Amazon S3 server-side encryption with customer-provided keys. &#x2713;
  </label><br>

  <label for="optionC">
    C. Use Amazon S3 server-side encryption with EC2 key pair.
  </label><br>

  <label for="optionD">
    D. Use Amazon S3 bucket policies to restrict access to the data at rest.
  </label><br>

  <label for="optionE" class="correct-answer">
    E. Encrypt the data on the client-side before ingesting to Amazon S3 using their own master key. &#x2713;
  </label><br>

  <label for="optionF">
    F. Use SSL to encrypt the data while in transit to Amazon S3.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    Your firm has uploaded a large amount of aerial image data to S3. In the past, in your on-premises environment, you used a dedicated group of servers to often process this data and used Rabbit MQ — an open-source messaging system — to get job information to the servers.
  </h1>
  <h1 class="question">
    Once processed, the data would go to tape and be shipped offsite. Your manager told you to stay with the current design, and leverage AWS archival storage and messaging services to minimize cost.
  </h1>
  <h1 class="question">
    Which is correct?
  </h1>

  <label for="optionA">
    A. Use SQS for passing job messages, use CloudWatch alarms to terminate EC2 worker instances when they become idle. Once data is processed, change the storage class of the S3 objects to Reduced Redundancy Storage.
  </label><br>

  <label for="optionB">
    B. Setup Auto-Scaled workers triggered by queue depth that use spot instances to process messages in SOS. Once data is processed, change the storage class of the S3 objects to Reduced Redundancy Storage.
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Setup Auto-Scaled workers triggered by queue depth that use spot instances to process messages in SQS. Once data is processed, change the storage class of the S3 objects to Glacier. &#x2713;
  </label><br>

  <label for="optionD">
    D. Use SNS to pass job messages, use CloudWatch alarms to terminate spot worker instances when they become idle. Once data is processed, change the storage class of the S3 object to Glacier.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    You've been hired to enhance the overall security posture for a very large e-commerce site.
  </h1>
  <h1 class="question">
    They have a well-architected multi-tier application running in a VPC that uses ELBs in front of both the web and the app tier, with static assets served directly from S3.
  </h1>
  <h1 class="question">
    They are using a combination of RDS and DynamoDB for their dynamic data and then archiving nightly into S3 for further processing with EMR.
  </h1>
  <h1 class="question">
    They are concerned because they found questionable log entries and suspect someone is attempting to gain unauthorized access.
  </h1>
  <h1 class="question">
    Which approach provides a cost-effective, scalable mitigation to this kind of attack?
  </h1>

  <label for="optionA">
    A. Recommend that they lease space at a DirectConnect partner location and establish a 1G DirectConnect connection to their VPC. They would then establish Internet connectivity into their space, filter the traffic in a hardware Web Application Firewall (WAF), and then pass the traffic through the DirectConnect connection into their application running in their VPC.
  </label><br>

  <label for="optionB">
    B. Add previously identified hostile source IPs as an explicit INBOUND DENY NACL to the web tier subnet.
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Add a WAF tier by creating a new ELB and an Auto Scaling group of EC2 instances running a host-based WAF. They would redirect Route 53 to resolve to the new WAF tier ELB. The WAF tier would then pass the traffic to the current web tier. The web tier Security Groups would be updated to only allow traffic from the WAF tier Security Group. &#x2713;
  </label><br>

  <label for="optionD">
    D. Remove all but TLS 1.2 from the web tier ELB and enable Advanced Protocol Filtering. This will enable the ELB itself to perform WAF functionality.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    Your company is in the process of developing a next-generation pet collar that collects biometric information to assist families with promoting healthy lifestyles for their pets.
  </h1>
  <h1 class="question">
    Each collar will push 30KB of biometric data in JSON format every 2 seconds to a collection platform that will process and analyze the data, providing health trending information back to the pet owners and veterinarians via a web portal.
  </h1>
  <h1 class="question">
    Management has tasked you to architect the collection platform ensuring the following requirements are met:
    <ul>
      <li>Provide the ability for real-time analytics of the inbound biometric data</li>
      <li>Ensure processing of the biometric data is highly durable, elastic, and parallel</li>
      <li>The results of the analytic processing should be persisted for data mining</li>
    </ul>
    Which architecture outlined below will meet the initial requirements for the collection platform?
  </h1>

  <label for="optionA">
    A. Utilize S3 to collect the inbound sensor data, analyze the data from S3 with a daily scheduled Data Pipeline, and save the results to a Redshift cluster.
  </label><br>

  <label for="optionB" class="correct-answer">
    B. Utilize Amazon Kinesis to collect the inbound sensor data, analyze the data with Kinesis clients, and save the results to a Redshift cluster using EMR. &#x2713;
  </label><br>

  <label for="optionC">
    C. Utilize SQS to collect the inbound sensor data, analyze the data from SQS with Amazon Kinesis, and save the results to a Microsoft SQL Server RDS instance.
  </label><br>

  <label for="optionD">
    D. Utilize EMR to collect the inbound sensor data, analyze the data from EMR with Amazon Kinesis, and save the results to DynamoDB.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    You are designing Internet connectivity for your VPC. The web servers must be available on the Internet.
  </h1>
  <h1 class="question">
    The application must have a highly available architecture.
  </h1>
  <h1 class="question">
    Which alternatives should you consider? (Choose two.)
  </h1>

  <label for="optionA">
    A. Configure a NAT instance in your VPC. Create a default route via the NAT instance and associate it with all subnets. Configure a DNS A record that points to the NAT instance public IP address.
  </label><br>

  <label for="optionB">
    B. Configure a CloudFront distribution and configure the origin to point to the private IP addresses of your web servers. Configure a Route 53 CNAME record to your CloudFront distribution.
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Place all your web servers behind ELB. Configure a Route 53 CNAME to point to the ELB DNS name. &#x2713;
  </label><br>

  <label for="optionD" class="correct-answer">
    D. Assign EIPs to all web servers. Configure a Route 53 record set with all EIPs, with health checks and DNS failover. &#x2713;
  </label><br>

  <label for="optionE">
    E. Configure ELB with an EIP. Place all your web servers behind ELB. Configure a Route 53 A record that points to the EIP.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    Your team has a Tomcat-based Java application you need to deploy into development, test, and production environments. After some research, you opt to use
    Elastic Beanstalk due to its tight integration with your developer tools and RDS due to its ease of management.
  </h1>
  <h1 class="question">
    Your QA team lead points out that you need to roll a sanitized set of production data into your environment on a nightly basis. Similarly, other software teams in your organization want access to that same restored data via their EC2 instances in your VPC.
  </h1>
  <h1 class="question">
    The optimal setup for persistence and security that meets the above requirements would be the following:
  </h1>

  <label for="optionA">
    A. Create your RDS instance as part of your Elastic Beanstalk definition and alter its security group to allow access to it from hosts in your application subnets.
  </label><br>

  <label for="optionB">
    B. Create your RDS instance separately and add its IP address to your application's DB connection strings in your code. Alter its security group to allow access to it from hosts within your VPC's IP address block.
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Create your RDS instance separately and pass its DNS name to your app's DB connection string as an environment variable. Create a security group for client machines and add it as a valid source for DB traffic to the security group of the RDS instance itself. &#x2713;
  </label><br>

  <label for="optionD">
    D. Create your RDS instance separately and pass its DNS name to your app's DB connection string as an environment variable. Alter its security group to allow access to it from hosts in your application subnets.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    You're trying to delete an SSL certificate from the IAM certificate store, and you're getting the message:
    <br><br>
    "<code>Certificate: &lt;certificate-id&gt; is being used by CloudFront.</code>"
  </h1>
  <h1 class="question">
    Which of the following statements is probably the reason why you are getting this error?
  </h1>

  <label for="optionA">
    A. Before you can delete an SSL certificate you need to set up HTTPS on your server.
  </label><br>

  <label for="optionB">
    B. Before you can delete an SSL certificate, you need to set up the appropriate access level in IAM.
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Before you can delete an SSL certificate, you need to either rotate SSL certificates or revert from using a custom SSL certificate to using the default CloudFront certificate. &#x2713;
  </label><br>

  <label for="optionD">
    D. You can't delete SSL certificates. You need to request it from AWS.
  </label><br>
</form>
    <form class="question-form">
  <h1 class="question">
    A company is migrating to the cloud. It wants to evaluate the configurations of virtual machines in its existing data center environment to ensure that it can size new Amazon EC2 instances accurately. 
    <br><br>
    The company wants to collect metrics, such as CPU, memory, and disk utilization, and it needs an inventory of what processes are running on each instance. 
    <br><br>
    The company would also like to monitor network connections to map communications between servers.
    <br><br>
    Which would enable the collection of this data MOST cost effectively?
  </h1>

  <label for="optionA" class="correct-answer">
    A. Use AWS Application Discovery Service and deploy the data collection agent to each virtual machine in the data center. &#x2713;
  </label><br>

  <label for="optionB">
    B. Configure the Amazon CloudWatch agent on all servers within the local environment and publish metrics to Amazon CloudWatch Logs.
  </label><br>

  <label for="optionC">
    C. Use AWS Application Discovery Service and enable agentless discovery in the existing virtualization environment.
  </label><br>

  <label for="optionD">
    D. Enable AWS Application Discovery Service in the AWS Management Console and configure the corporate firewall to allow scans over a VPN.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    The _____ service is targeted at organizations with multiple users or systems that use AWS products such as Amazon EC2, Amazon SimpleDB, and the AWS Management Console.
  </h1>

  <label for="optionA">
    A. Amazon RDS
  </label><br>

  <label for="optionB">
    B. AWS Integrity Management
  </label><br>

  <label for="optionC" class="correct-answer">
    C. AWS Identity and Access Management &#x2713;
  </label><br>

  <label for="optionD">
    D. Amazon EMR
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    To get started using AWS Direct Connect, in which of the following steps do you configure Border Gateway Protocol (BGP)?
  </h1>

  <label for="optionA">
    A. Complete the Cross Connect
  </label><br>

  <label for="optionB">
    B. Configure Redundant Connections with AWS Direct Connect
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Create a Virtual Interface &#x2713;
  </label><br>

  <label for="optionD">
    D. Download Router Configuration
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company wants to allow its Marketing team to perform SQL queries on customer records to identify market segments. The data is spread across hundreds of files. The records must be encrypted in transit and at rest. The Team Manager must have the ability to manage users and groups, but no team members should have access to services or resources not required for the SQL queries. Additionally, Administrators need to audit the queries made and receive notifications when a query violates rules defined by the Security team.
  </h1>
  <h1 class="question">
    AWS Organizations has been used to create a new account and an AWS IAM user with administrator permissions for the Team Manager. Which design meets these requirements?
  </h1>

  <label for="optionA">
    A. Apply a service control policy (SCP) that denies to all services except IAM, Amazon DynamoDB, and AWS CloudTrail. Store customer records in DynamoDB and train users to execute queries using the AWS CLI. Enable DynamoDB streams to track the queries that are issued and use an AWS Lambda function for real-time monitoring and alerting.
  </label><br>

  <label for="optionB">
    B. Apply a service control policy (SCP) that allows to IAM, Amazon Athena, Amazon S3, and AWS CloudTrail. Store customer records as files in Amazon S3 and train users to leverage the Amazon S3 Select feature and execute queries using the AWS CLI. Enable S3 object-level logging and analyze CloudTrail events to audit and alarm on queries against personal data.
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Apply a service control policy (SCP) that denies access to all services except IAM, Amazon Athena, Amazon S3, and AWS CloudTrail. Store customer record files in Amazon S3 and train users to execute queries using the CLI via Athena. Analyze CloudTrail events to audit and alarm on queries against personal data. &#x2713;
  </label><br>

  <label for="optionD">
    D. Apply a service control policy (SCP) that allows access to IAM, Amazon RDS, and AWS CloudTrail. Load customer records in Amazon RDS MySQL and train users to execute queries using the AWS CLI. Stream the query logs to Amazon CloudWatch Logs from the RDS database instance. Use a subscription filter with AWS Lambda functions to audit and alarm on queries against personal data.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    Which of the following is NOT an advantage of using AWS Direct Connect?
  </h1>

  <label for="optionA" class="correct-answer">
    A. AWS Direct Connect provides users access to public and private resources by using two different connections while maintaining network separation between the public and private environments. &#x2713;
  </label><br>

  <label for="optionB">
    B. AWS Direct Connect provides a more consistent network experience than Internet-based connections.
  </label><br>

  <label for="optionC">
    C. AWS Direct Connect makes it easy to establish a dedicated network connection from your premises to AWS.
  </label><br>

  <label for="optionD">
    D. AWS Direct Connect reduces your network costs.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    You create a VPN connection, and your VPN device supports Border Gateway Protocol (BGP).  
    Which of the following should be specified to configure the VPN connection?
  </h1>

  <label for="optionA">
    A. Classless routing
  </label><br>

  <label for="optionB">
    B. Classfull routing
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Dynamic routing &#x2713;
  </label><br>

  <label for="optionD">
    D. Static routing
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A company runs a three-tier application in AWS. Users report that the application performance can vary greatly depending on the time of day and functionality being accessed. The application includes the following components:
    <ul>
      <li>Eight t2.large front-end web servers that serve static content and proxy dynamic content from the application tier.</li>
      <li>Four t2.large application servers.</li>
      <li>One db.m4.large Amazon RDS MySQL Multi-AZ DB instance.</li>
    </ul>
    Operations has determined that the web and application tiers are network constrained.  
    Which of the following should cost effectively improve application performance? (Choose two.)
  </h1>

  <label for="optionA">
    A. Replace web and app tiers with t2.xlarge instances
  </label><br>

  <label for="optionB" class="correct-answer">
    B. Use AWS Auto Scaling and m4.large instances for the web and application tiers &#x2713;
  </label><br>

  <label for="optionC">
    C. Convert the MySQL RDS instance to a self-managed MySQL cluster on Amazon EC2
  </label><br>

  <label for="optionD" class="correct-answer">
    D. Create an Amazon CloudFront distribution to cache content &#x2713;
  </label><br>

  <label for="optionE">
    E. Increase the size of the Amazon RDS instance to db.m4.xlarge
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A large company has increased its utilization of AWS over time in an unmanaged way. As such, they have a large number of independent AWS accounts across different business units, projects, and environments. The company has created a Cloud Center of Excellence team, which is responsible for managing all aspects of the AWS Cloud, including their AWS accounts.  
    Which of the following should the Cloud Center of Excellence team do to BEST address their requirements in a centralized way? (Select two.)
  </h1>

  <label for="optionA">
    A. Control all AWS account root user credentials. Assign AWS IAM users in the account of each user who needs to access AWS resources. Follow the policy of least privilege in assigning permissions to each user.
  </label><br>

  <label for="optionB">
    B. Tag all AWS resources with details about the business unit, project, and environment. Send all AWS Cost and Usage reports to a central Amazon S3 bucket, and use tools such as Amazon Athena and Amazon QuickSight to collect billing details by business unit.
  </label><br>

  <label for="optionC">
    C. Use the AWS Marketplace to choose and deploy a Cost Management tool. Tag all AWS resources with details about the business unit, project, and environment. Send all AWS Cost and Usage reports for the AWS accounts to this tool for analysis.
  </label><br>

  <label for="optionD" class="correct-answer">
    D. Set up AWS Organizations. Enable consolidated billing, and link all existing AWS accounts to a master billing account. Tag all AWS resources with details about the business unit, project and environment.  
    Analyze Cost and Usage reports using tools such as Amazon Athena and Amazon QuickSight to collect billing details by business unit. &#x2713;
  </label><br>

  <label for="optionE" class="correct-answer">
    E. Using a master AWS account, create IAM users within the master account. Define IAM roles in the other AWS accounts, which cover each of the required functions in the account. Follow the policy of least privilege in assigning permissions to each role, then enable the IAM users to assume the roles that they need to use. &#x2713;
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    Your website is serving on-demand training videos to your workforce. Videos are uploaded monthly in high resolution MP4 format. Your workforce is distributed globally, often on the move and using company-provided tablets that require the HTTP Live Streaming (HLS) protocol to watch a video. Your company has no video transcoding expertise and if required you may need to pay for a consultant.  
    How do you implement the most cost-efficient architecture without compromising high availability and quality of video delivery?
  </h1>

  <label for="optionA">
    A. Elastic Transcoder to transcode original high-resolution MP4 videos to HLS. EBS volumes to host videos and EBS snapshots to incrementally backup original files after a few days. CloudFront to serve HLS transcoded videos from EC2.
  </label><br>

  <label for="optionB" class="correct-answer">
    B. Elastic Transcoder to transcode original high-resolution MP4 videos to HLS. S3 to host videos with Lifecycle Management to archive original files to Glacier after a few days. CloudFront to serve HLS transcoded videos from S3. &#x2713;
  </label><br>

  <label for="optionC">
    C. A video transcoding pipeline running on EC2 using SQS to distribute tasks and Auto Scaling to adjust the number of nodes depending on the length of the queue. S3 to host videos with Lifecycle Management to archive all files to Glacier after a few days. CloudFront to serve HLS transcoded videos from Glacier.
  </label><br>

  <label for="optionD">
    D. A video transcoding pipeline running on EC2 using SQS to distribute tasks and Auto Scaling to adjust the number of nodes depending on the length of the queue. EBS volumes to host videos and EBS snapshots to incrementally backup original files after a few days. CloudFront to serve HLS transcoded videos from EC2.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    Your startup wants to implement an order fulfillment process for selling a personalized gadget that needs an average of 3-4 days to produce with some orders taking up to 6 months.
    You expect 10 orders per day on your first day, 1000 orders per day after 6 months and 10,000 orders after 12 months. Orders coming in are checked for consistency, then dispatched to your manufacturing plant for production, quality control, packaging, shipment and payment processing.
    If the product does not meet the quality standards at any stage of the process, employees may force the process to repeat a step. Customers are notified via email about order status and any critical issues with their orders such as payment failure.
    Your base architecture includes AWS Elastic Beanstalk for your website with an RDS MySQL instance for customer data and orders.
    How can you implement the order fulfillment process while making sure that the emails are delivered reliably?
  </h1>

  <label for="optionA">
    A. Add a business process management application to your Elastic Beanstalk app servers and re-use the RDS database for tracking order status. Use one of the Elastic Beanstalk instances to send emails to customers.
  </label><br>

  <label for="optionB" class="correct-answer">
    B. Use SWF with an Auto Scaling group of activity workers and a decider instance in another Auto Scaling group with min/max=1. Use SES to send emails to customers. &#x2713;
  </label><br>

  <label for="optionC">
    C. Use an SQS queue to manage all process tasks. Use an Auto Scaling group of EC2 instances that poll the tasks and execute them. Use SES to send emails to customers.
  </label><br>

  <label for="optionD">
    D. Use SWF with an Auto Scaling group of activity workers and a decider instance in another Auto Scaling group with min/max=1. Use the decider instance to send emails to customers.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    Your team has a Tomcat-based Java application you need to deploy into development, test, and production environments. After some research, you opt to use Elastic Beanstalk due to its tight integration with your developer tools and RDS due to its ease of management.
    Your QA team lead points out that you need to roll a sanitized set of production data into your environment on a nightly basis. Similarly, other software teams in your org want access to that same restored data via their EC2 instances in your VPC.
    The optimal setup for persistence and security that meets the above requirements would be the following:
  </h1>

  <label for="optionA">
    A. Create your RDS instance separately and add its IP address to your application's DB connection strings in your code. Alter its security group to allow access to it from hosts within your VPC's IP address block.
  </label><br>

  <label for="optionB">
    B. Create your RDS instance separately and pass its DNS name to your's DB connection string as an environment variable. Alter its security group to allow access to it from hosts in your application subnets.
  </label><br>

  <label for="optionC">
    C. Create your RDS instance as part of your Elastic Beanstalk definition and alter its security group to allow access to it from hosts in your application subnets.
  </label><br>

  <label for="optionD" class="correct-answer">
    D. Create your RDS instance separately and pass its DNS name to your app's DB connection string as an environment variable. Create a security group for client machines and add it as a valid source for DB traffic to the security group of the RDS instance itself. &#x2713;
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    You have a website which requires international presence and consequently you have set it up as follows. It is hosted on 30 EC2 instances. It is in 15 regions around the globe. Each region has 2 instances. All the instances are in a public hosted zone.
    Which of the following is the best way to configure your site to maintain availability with minimum downtime if one of the 15 regions was to lose network connectivity for an extended period? (Choose 2 answers)
  </h1>

  <label for="optionA" class="correct-answer">
    A. Create a Route 53 Latency Based Routing Record set that resolves to an Elastic Load Balancer in each region and has the Evaluate Target Health flag set to true. &#x2713;
  </label><br>

  <label for="optionB" class="correct-answer">
    B. Create a Route 53 failover routing policy and configure an active-passive failover. &#x2713;
  </label><br>

  <label for="optionC">
    C. Create a Route 53 Failover Routing Policy and assign each resource record set a unique identifier and a relative weight.
  </label><br>

  <label for="optionD">
    D. Create a Route 53 Geolocation Routing Policy that resolves to an Elastic Load Balancer in each region and has the Evaluate Target Health flag set to false.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    You require the ability to analyze a customer's clickstream data on a website, so they can do behavioral analysis. Your customer needs to know what sequence of pages and ads their customer clicked on. This data will be used in real time to modify the page layouts as customers click through the site, to increase stickiness and advertising click-through.<br><br>
    Which option meets the requirements for capturing and analyzing this data?
  </h1>

  <label for="optionA">
    A. Log clicks in weblogs by URL, store to Amazon S3, and then analyze with Elastic MapReduce.
  </label><br>

  <label for="optionB">
    B. Publish web clicks by session to an Amazon SQS queue; then periodically drain these events to Amazon RDS and analyze with SQL.
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Push web clicks by session to Amazon Kinesis, then analyze behavior using Kinesis workers. &#x2713;
  </label><br>

  <label for="optionD">
    D. Write click events directly to Amazon Redshift, and then analyze with SQL.
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A user wants to configure AutoScaling which scales up when the CPU utilization is above 70% and scales down when the CPU utilization is below 30%. How can the user configure AutoScaling for the above mentioned condition?
  </h1>

  <label for="optionA">
    A. Configure ELB to notify AutoScaling on load increase or decrease
  </label><br>

  <label for="optionB">
    B. Use AutoScaling with a schedule
  </label><br>

  <label for="optionC">
    C. Use AutoScaling by manually modifying the desired capacity during a condition
  </label><br>

  <label for="optionD" class="correct-answer">
    D. Use dynamic AutoScaling with a policy &#x2713;
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    You want to use AWS CodeDeploy to deploy an application to Amazon EC2 instances running within an Amazon Virtual Private Cloud (VPC).<br>
    What criterion must be met for this to be possible?
  </h1>

  <label for="optionA">
    A. The AWS CodeDeploy agent installed on the Amazon EC2 instances must be able to access only the public AWS CodeDeploy endpoint.
  </label><br>

  <label for="optionB">
    B. The AWS CodeDeploy agent installed on the Amazon EC2 instances must be able to access only the public Amazon S3 service endpoint.
  </label><br>

  <label for="optionC" class="correct-answer">
    C. The AWS CodeDeploy agent installed on the Amazon EC2 instances must be able to access the public AWS CodeDeploy and Amazon S3 service endpoints &#x2713;
  </label><br>

  <label for="optionD">
    D. It is not currently possible to use AWS CodeDeploy to deploy an application to Amazon EC2 instances running within an Amazon Virtual Private Cloud (VPC.)
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    You have subscribed to the AWS Business and Enterprise support plan.<br>
    Your business has a backlog of problems, and you need about 20 of your IAM users to open technical support cases.<br>
    How many users can open technical support cases under the AWS Business and Enterprise support plan?
  </h1>

  <label for="optionA">
    A. 5 users
  </label><br>

  <label for="optionB">
    B. 10 users
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Unlimited &#x2713;
  </label><br>

  <label for="optionD">
    D. 1 user
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    A user has created a VPC with two subnets: one public and one private.<br>
    The user is planning to run the patch update for the instances in the private subnet.<br>
    How can the instances in the private subnet connect to the internet?
  </h1>

  <label for="optionA">
    A. The private subnet can never connect to the internet
  </label><br>

  <label for="optionB" class="correct-answer">
    B. Use NAT with an elastic IP &#x2713;
  </label><br>

  <label for="optionC">
    C. Use the internet gateway with a private IP
  </label><br>

  <label for="optionD">
    D. Allow outbound traffic in the security group for port 80 to allow internet updates
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    When I/O performance is more important than fault tolerance, which of the following configurations should be used?
  </h1>

  <label for="optionA">
    A. SPAN 10
  </label><br>

  <label for="optionB">
    B. RAID 1
  </label><br>

  <label for="optionC" class="correct-answer">
    C. RAID 0 &#x2713;
  </label><br>

  <label for="optionD">
    D. NFS 1
  </label><br>
</form>
<form class="question-form">
  <h1 class="question">
    An organization is setting up an application on AWS to have both High Availability (HA) and Disaster Recovery (DR). The organization wants to have both Recovery Point Objective (RPO) and Recovery Time Objective (RTO) of 10 minutes. Which of the below mentioned service configurations does <strong>not</strong> help the organization achieve the said RPO and RTO?
  </h1>

  <label for="optionA">
    A. Take a snapshot of the data every 10 minutes and copy it to the other region.
  </label><br>

  <label for="optionB">
    B. Use an elastic IP to assign to a running instance and use Route 53 to map the user's domain with that IP.
  </label><br>

  <label for="optionC" class="correct-answer">
    C. Create ELB with multi-region routing to allow automated failover when required. &#x2713;
  </label><br>

  <label for="optionD">
    D. Use an AMI copy to keep the AMI available in other regions.
  </label><br>
</form>


  </div>
  <button class="scroll-top" id="scrollTop">↑</button>

  <!-- ========================================================= -->
  <!-- ===== START OF THE NEW, CORRECTED JAVASCRIPT SCRIPT ===== -->
  <!-- ========================================================= -->
  <script>
    document.addEventListener("DOMContentLoaded", function () {
      
      // --- DEDUPLICATION LOGIC ---
      const seenQuestions = new Map();
      
      // This selector finds ALL possible question containers, whether they are
      // a .question-block div or a .question-form that is NOT inside a .question-block.
      const allQuestionContainers = document.querySelectorAll(".question-block, form.question-form:not(.question-block .question-form)");

      allQuestionContainers.forEach(container => {
        const questionElement = container.querySelector(".question");
        if (!questionElement) return; // Skip if no question text is found

        const questionText = questionElement.textContent.trim();

        if (seenQuestions.has(questionText)) {
          container.remove(); // Remove the duplicate container
        } else {
          seenQuestions.set(questionText, container); // Store the first one we see
        }
      });


      // --- SCROLL TO TOP BUTTON LOGIC ---
      const scrollTopBtn = document.getElementById('scrollTop');
      window.addEventListener('scroll', function () {
        scrollTopBtn.style.display = (window.pageYOffset > 300) ? 'block' : 'none';
      });
      scrollTopBtn.addEventListener('click', function () {
        window.scrollTo({ top: 0, behavior: 'smooth' });
      });


      // --- SEARCH LOGIC ---
      const searchInput = document.getElementById('search');
      const clearSearchBtn = document.getElementById('clear-search');
      
      // Get the list of unique containers that survived deduplication
      const finalQuestionContainers = Array.from(seenQuestions.values());

      function performSearch() {
        const query = searchInput.value.toLowerCase().trim();
        finalQuestionContainers.forEach(container => {
          const questionText = container.querySelector('.question').textContent.toLowerCase();
          
          // Show if the text includes the query, hide otherwise
          container.style.display = questionText.includes(query) ? 'block' : 'none';
        });
      }

      searchInput.addEventListener('input', performSearch);

      clearSearchBtn.addEventListener('click', function () {
        searchInput.value = '';
        performSearch(); // Re-run search with empty query to show all
        searchInput.focus();
      });
    });
  </script>
  <!-- ======================================================= -->
  <!-- ===== END OF THE NEW, CORRECTED JAVASCRIPT SCRIPT ===== -->
  <!-- ======================================================= -->
</body>

</html>